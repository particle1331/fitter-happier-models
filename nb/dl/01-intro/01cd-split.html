

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Train-validation split &mdash; OK Transformer</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=c854b03d" />

  
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../_static/scripts/sphinx-book-theme.js"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
      <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
      <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
      <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Appendix: Weak supervision" href="01e-appendix-weaksup.html" />
    <link rel="prev" title="Experiments" href="01cc-experiments.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../intro.html">
            
              <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="01-intro.html">Introduction to Neural Networks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01a-fcnn.html">Fully-connected NNs (MLPs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="01b-linear.html">Linear classification</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="01c-lossmin.html">Machine learning theory</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="01ca-bias-variance.html">Bias-variance decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="01cb-regularization.html">Regularization</a></li>
<li class="toctree-l3"><a class="reference internal" href="01cc-experiments.html">Experiments</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Train-validation split</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="01e-appendix-weaksup.html">Appendix: Weak supervision</a></li>
<li class="toctree-l2"><a class="reference internal" href="01ec-depth.html">Appendix: Expressivity and Depth</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../02-optim/02-optim.html">Gradient Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00-backprop/00-backprop.html">Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03-cnn/03-cnn.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-sequence-models/04-intro.html">Language modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05-rnns/05-intro.html">Recurrent Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07-attention.html">Attention and Transformers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../intro.html">Project name not set</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../intro.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="01-intro.html">Introduction to Neural Networks</a></li>
          <li class="breadcrumb-item"><a href="01c-lossmin.html">Machine learning theory</a></li>
      <li class="breadcrumb-item active">Train-validation split</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/nb/dl/01-intro/01cd-split.ipynb" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="train-validation-split">
<h1>Train-validation split<a class="headerlink" href="#train-validation-split" title="Link to this heading">ÔÉÅ</a></h1>
<p>How do we know if we are overfitting or underfitting? Note that we do not have access to the
ground truth function <span class="math notranslate nohighlight">\(f\)</span> (otherwise there is no point in doing ML) or the expected model
<span class="math notranslate nohighlight">\(\bar{f}\)</span> (too expensive to estimate). How do we select algorithm or hyperparameters?
This
can be done simply by reserving a subset of the dataset called the <strong>validation set</strong> for
estimating the true risk. The validation performance is used for choosing hyperparameters and tweaking the model class. Recall that the training dataset is used to minimize the empirical risk. In terms of train and validation loss:</p>
<ul class="simple">
<li><p>Overfitting is characterized by significant <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathcal{D}_{\text{train}}}(\boldsymbol{\Theta}) \ll \mathcal{L}_{\mathcal{D}_{\text{val}}}(\boldsymbol{\Theta})\)</span>.</p></li>
<li><p>Underfitting is characterized by <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathcal{D}_{\text{train}}}(\boldsymbol{\Theta})\)</span> not decreasing low enough (<a class="reference internal" href="#train-valid-curve"><span class="std std-numref">Fig. 14</span></a>).</p></li>
</ul>
<p>The training and validation curves are generated by <span class="math notranslate nohighlight">\((t, \mathcal{L}_{\mathcal{D}_{\text{train}}}(\boldsymbol{\Theta}^t))\)</span> and <span class="math notranslate nohighlight">\((t, \mathcal{L}_{\mathcal{D}_{\text{val}}}(\boldsymbol{\Theta}^t))\)</span> for steps <span class="math notranslate nohighlight">\(t\)</span> during training (<a class="reference internal" href="#train-valid-curve"><span class="std std-numref">Fig. 14</span></a>). The model only sees the train set during training. Meanwhile, the model is evaluated on the same validation set getting controlled results. Note that modifying training hyperparameters between runs means that the validation set is now being overfitted. Techniques such as <a class="reference external" href="https://machinelearningmastery.com/k-fold-cross-validation/">k-fold cross-validation</a> or mitigates this, but can be expensive for training large models.
Training ends with a final set of parameters <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}.\)</span></p>
<p>Finally, a separate <strong>test set</strong> is used to report the final performance. The loss
on the test set <span class="math notranslate nohighlight">\(\mathcal{L}_{\mathcal{D}_{\text{test}}}(\hat{\boldsymbol{\Theta}})\)</span> acts as the final estimate of the true risk of the trained model. It is best practice that the test evaluation is done exactly once. Note that the training, validation, and test sets are chosen to be disjoint.</p>
<p><strong>Remarks.</strong> Regularization tends to flatten out the classical U-shape validation curve that occurs before epoch-wise double descent (<a class="reference internal" href="01ca-bias-variance.html#double-descent-epochs"><span class="std std-numref">Fig. 10</span></a>) where the model overfits. Assuming the model is sufficiently complex so that there is little bias, underfitting can indicate a problem with the optimizer (e.g. learning rate). We will see in the next chapter that training loss curves stuck to values away from zero may indicate a problem with the optimizer (stuck in a plateau, or bad local optima).</p>
<br>
<figure class="align-center" id="train-valid-curve">
<a class="reference internal image-reference" href="../../../_images/01-train-valid-curve.png"><img alt="../../../_images/01-train-valid-curve.png" src="../../../_images/01-train-valid-curve.png" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Train and validation loss curves during training. Gap in train curve can indicate bias
or a problem with the optimizer.
Source: <a class="reference external" href="https://cs182sp21.github.io/static/slides/lec-3.pdf">[CS182-lec3]</a></span><a class="headerlink" href="#train-valid-curve" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="canonical-loss">
<a class="reference internal image-reference" href="../../../_images/01-canonical-loss.png"><img alt="../../../_images/01-canonical-loss.png" src="../../../_images/01-canonical-loss.png" style="width: 85%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Canonical train-validation loss curves. Source: <span id="id1">[<a class="reference internal" href="../../../intro.html#id31" title="Fran√ßois Chollet. Deep Learning with Python, Second Edition. Manning, 2021. ISBN 9781617296864.">Cho21</a>]</span></span><a class="headerlink" href="#canonical-loss" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Remark.</strong> A commonly used technique is <strong>early stopping</strong> which stops training once the validation curves stops improving after a set number of steps. One consequence of epoch-wise double descent is that early stopping only helps in the relatively narrow parameter regime of critically parameterized models (<a class="reference internal" href="01ca-bias-variance.html#double-descent-epochs"><span class="std std-numref">Fig. 10</span></a>)! In fact, practical experience shows that early stopping results in overfitting the validation set (<a class="reference internal" href="#early-stopping-bad"><span class="std std-numref">Fig. 16</span></a>).</p>
<br>
<figure class="align-default" id="early-stopping-bad">
<a class="reference internal image-reference" href="../../../_images/01-early-stopping-bad.png"><img alt="../../../_images/01-early-stopping-bad.png" src="../../../_images/01-early-stopping-bad.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Top Kaggle GMs recommending against the use of early stopping. Source: <a class="reference external" href="https://www.youtube.com/watch?v=NCGkBseUSdM">[video]</a></span><a class="headerlink" href="#early-stopping-bad" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nb/dl/01-intro"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="01cc-experiments.html" class="btn btn-neutral float-left" title="Experiments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="01e-appendix-weaksup.html" class="btn btn-neutral float-right" title="Appendix: Weak supervision" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>