
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Blending and Stacking &#8212; 𝗜𝗻𝗲𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗡𝗲𝘁𝘄𝗼𝗿𝗸𝘀</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../_static/pone.0237978.g001.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Model Tuning with Optuna" href="optuna.html" />
    <link rel="prev" title="Modelling with Pipelines" href="house-prices.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/pone.0237978.g001.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">𝗜𝗻𝗲𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗡𝗲𝘁𝘄𝗼𝗿𝗸𝘀</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  FUNDAMENTALS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="house-prices.html">
   Modelling with Pipelines
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Blending and Stacking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optuna.html">
   Model Tuning with Optuna
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="missing.html">
   Handling Missing Values
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="backpropagation.html">
   Backpropagation on DAGs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/01-tensorflow-nn.html">
   TensorFlow Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/02-tensorflow-mechanics.html">
   Mechanics of TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/03-tensorflow-activations.html">
   Activation Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/04-tensorflow-optim-init.html">
   Initialization and Optimization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODEL DEPLOYMENT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/production-code.html">
   Packaging Production Code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/model-serving-api.html">
   Prediction Serving REST API
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/fundamentals/blending-stacking.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/particle1331/inefficient-networks"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/particle1331/inefficient-networks/issues/new?title=Issue%20on%20page%20%2Fnotebooks/fundamentals/blending-stacking.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/particle1331/inefficient-networks/master?urlpath=tree/docs/notebooks/fundamentals/blending-stacking.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#movie-reviews-dataset">
   Movie Reviews Dataset
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-test-split">
     Train and test split
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stackingclassifier-class">
   <code class="docutils literal notranslate">
    <span class="pre">
     StackingClassifier
    </span>
   </code>
   Class
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#blending-prediction-probabilities">
     Blending prediction probabilities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-blending-coefficients-that-optimize-auc">
     Finding blending coefficients that optimize AUC
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#blender-as-final-stacker">
     Blender as final stacker
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xgboost-classifier-as-final-stacker">
     XGBoost classifier as final stacker
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parallelizing-model-training">
   Parallelizing Model Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-workers-to-stackingclassifier-using-joblib-parallel">
     Adding workers to
     <code class="docutils literal notranslate">
      <span class="pre">
       StackingClassifier
      </span>
     </code>
     using
     <code class="docutils literal notranslate">
      <span class="pre">
       joblib.Parallel
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#defining-models-to-stack">
     Defining models to stack
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-training-times-between-serial-and-parallel">
     Comparing training times between serial and parallel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing-consistency-of-parallel-and-serial-predictions">
     Testing consistency of parallel and serial predictions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#checking-side-effect-on-data">
     Checking side-effect on data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parallelized-model-training">
     Parallelized model training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-improvements">
     Further improvements
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Blending and Stacking</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#movie-reviews-dataset">
   Movie Reviews Dataset
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-test-split">
     Train and test split
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stackingclassifier-class">
   <code class="docutils literal notranslate">
    <span class="pre">
     StackingClassifier
    </span>
   </code>
   Class
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#blending-prediction-probabilities">
     Blending prediction probabilities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finding-blending-coefficients-that-optimize-auc">
     Finding blending coefficients that optimize AUC
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#blender-as-final-stacker">
     Blender as final stacker
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xgboost-classifier-as-final-stacker">
     XGBoost classifier as final stacker
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parallelizing-model-training">
   Parallelizing Model Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-workers-to-stackingclassifier-using-joblib-parallel">
     Adding workers to
     <code class="docutils literal notranslate">
      <span class="pre">
       StackingClassifier
      </span>
     </code>
     using
     <code class="docutils literal notranslate">
      <span class="pre">
       joblib.Parallel
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#defining-models-to-stack">
     Defining models to stack
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-training-times-between-serial-and-parallel">
     Comparing training times between serial and parallel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing-consistency-of-parallel-and-serial-predictions">
     Testing consistency of parallel and serial predictions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#checking-side-effect-on-data">
     Checking side-effect on data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parallelized-model-training">
     Parallelized model training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-improvements">
     Further improvements
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="blending-and-stacking">
<h1>Blending and Stacking<a class="headerlink" href="#blending-and-stacking" title="Permalink to this headline">¶</a></h1>
<p><img alt="Status" src="https://img.shields.io/static/v1.svg?label=Status&amp;message=Updating&amp;color=blue" /></p>
<p>TODO: make package based + use utils functions</p>
<p>In this notebook, we will implement two ensembling methods: <strong>stacking</strong> and <strong>blending</strong>. Ensembling techniques combine multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms. In other words, instead of getting predictions from a selected single best model, we use multiple models and combine their predictions. This makes sense since different models can be good or bad on different parts of the data. Combining models means that shortcomings of single models get balanced out. Stacking and blending ensembles a diverse group of strong learners that are trained on the same task.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span><span class="p">,</span> <span class="n">linear_model</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">decomposition</span><span class="p">,</span> <span class="n">ensemble</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">,</span> <span class="n">clone</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span><span class="p">,</span> <span class="n">reduce</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">set_matplotlib_formats</span>
<span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">,</span> <span class="s1">&#39;pdf&#39;</span><span class="p">)</span> <span class="c1"># &lt;!&gt;</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># config</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">NUM_FOLDS</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/jq/9vsvd9252_349lsng_5gc_jw0000gn/T/ipykernel_21792/1498771717.py:23: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`
  set_matplotlib_formats(&#39;svg&#39;, &#39;pdf&#39;) # &lt;!&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="movie-reviews-dataset">
<h2>Movie Reviews Dataset<a class="headerlink" href="#movie-reviews-dataset" title="Permalink to this headline">¶</a></h2>
<p>The dataset consists of 50,000 IMDB movie reviews, specially selected for sentiment analysis. The sentiment of reviews is binary, with rating &lt; 5 results in a sentiment score of 0, and rating ≥ 7 resulting in a sentiment score of 1. No individual movie has more than 30 reviews. Note that movies should be separated via group <span class="math notranslate nohighlight">\(k\)</span>-fold so that two reviews of the same movie are all either in the train and test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;../../input/kumarmanoj-bag-of-words-meets-bags-of-popcorn&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_DIR</span> <span class="o">/</span> <span class="s1">&#39;labeledTrainData.tsv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sentiment</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5814_8</td>
      <td>1</td>
      <td>With all this stuff going down at the moment w...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2381_9</td>
      <td>1</td>
      <td>\The Classic War of the Worlds\" by Timothy Hi...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7759_3</td>
      <td>0</td>
      <td>The film starts with a manager (Nicholas Bell)...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3630_4</td>
      <td>0</td>
      <td>It must be assumed that those who praised this...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9495_8</td>
      <td>1</td>
      <td>Superbly trashy and wondrously unpretentious 8...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="section" id="train-and-test-split">
<h3>Train and test split<a class="headerlink" href="#train-and-test-split" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">values</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;review&#39;</span><span class="p">]]</span>

<span class="n">y_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">values</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[[</span><span class="s1">&#39;review&#39;</span><span class="p">]]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(20000, 1) (20000,)
(5000, 1) (5000,)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="stackingclassifier-class">
<h2><code class="docutils literal notranslate"><span class="pre">StackingClassifier</span></code> Class<a class="headerlink" href="#stackingclassifier-class" title="Permalink to this headline">¶</a></h2>
<p>We define a class that automates training and prediction of stacked models. Several models can be trained on the training set whose predict probabilities can be used as <strong>metafeatures</strong> to train a <strong>metamodel</strong>. This process can be iterated to several more levels. To avoid creating metafeatures that further amplifies overfitting in the training dataset, the metafeatures are generated by out-of-fold (OOF) training and prediction of the models on the features of the previous level. This requires defining cross-validation folds. Note that the <strong>same folds</strong> will be used to generate metafeatures at deeper levels.</p>
<div class="figure align-default" id="stacking">
<a class="reference internal image-reference" href="../../_images/stacking.png"><img alt="../../_images/stacking.png" src="../../_images/stacking.png" style="width: 40em;" /></a>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Stacking with <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation. For each input <span class="math notranslate nohighlight">\({\mathbf{x}^\prime}^{[i]}\)</span> has <span class="math notranslate nohighlight">\(T\)</span> features corresponding to predictions of each base model. Note line 10 should be: “<strong>for</strong> <span class="math notranslate nohighlight">\(i \leftarrow 1\)</span> to <span class="math notranslate nohighlight">\(n = |\mathcal{D}_k|\)</span> <strong>do</strong>”. That is, predictions are made on the fold <span class="math notranslate nohighlight">\(\mathcal{D}_k\)</span> that is not part of the model’s training set. <span id="id1">[<a class="reference internal" href="../../intro.html#id9" title="Sebastian Raschka. STAT 451 – Introduction to Machine Learning and Statistical Pattern Classification (Fall 2020). 2020. URL: https://github.com/rasbt/stat451-machine-learning-fs20/.">Ras20</a>]</span></span><a class="headerlink" href="#stacking" title="Permalink to this image">¶</a></p>
</div>
<p>After generating metafeatures, the models will be retrained on its complete respective training set. This increases accuracy of prediction during inference. Note that prediction on the test set simulates conditions when the model was trained with the test set essentially acting like an extra validation fold.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Alternatively, we could make predictions on the test dataset using each base model immediately after it gets fitted on each fold. In our case, this would generate five sets of predictions for each model in the stack (trained on 5 different datasets). Then, we would average the predictions per model to generate our metafeatures.</p>
<p>One benefit to this is that it is less time consuming than the current approach since we won’t have to retrain each model on the full training dataset. However, the test metafeatures are likely more accurate in the first approach since each base model was trained on the full training dataset (as opposed to 80% of the training dataset five times).</p>
</div>
<div class="figure align-default" id="stacking-inference">
<a class="reference internal image-reference" href="../../_images/stacking-inference.png"><img alt="../../_images/stacking-inference.png" src="../../_images/stacking-inference.png" style="width: 30em;" /></a>
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Stacking at test time. It is assumed that each model has been retrained on its respective complete feature set. <span id="id2">[<a class="reference internal" href="../../intro.html#id9" title="Sebastian Raschka. STAT 451 – Introduction to Machine Learning and Statistical Pattern Classification (Fall 2020). 2020. URL: https://github.com/rasbt/stat451-machine-learning-fs20/.">Ras20</a>]</span></span><a class="headerlink" href="#stacking-inference" title="Permalink to this image">¶</a></p>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Note that we <strong>clone</strong> models in the model dictionaries to avoid leaking state changes outside instances of this class.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StackingClassifier</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Implements model stacking for classification.&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> 
        <span class="n">num_folds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">NUM_FOLDS</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">        models (dict) - List of dictionaries of name model pairs for each level. </span>
<span class="sd">        verbose (bool) - Verbosity level.</span>
<span class="sd">        num_folds (int) - No. of CV folds.</span>

<span class="sd">        Example:</span>
<span class="sd">        &gt;&gt;&gt; models = [</span>
<span class="sd">            {&#39;level1_model1&#39;: level1_model1, &#39;level2_model2&#39;: level2_model2},</span>
<span class="sd">            {&#39;level2_model1&#39;: level2_model1},</span>
<span class="sd">        ]</span>
<span class="sd">        &gt;&gt;&gt; stacked_model = StackingClassifier(models)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[{</span><span class="n">name</span><span class="p">:</span> <span class="n">clone</span><span class="p">(</span><span class="n">level</span><span class="p">[</span><span class="n">name</span><span class="p">])</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">level</span><span class="p">}</span> <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_scores_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metafeatures_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_folds</span> <span class="o">=</span> <span class="n">num_folds</span>

        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit classifier. CV strategy: stratified 5-fold.</span>
<span class="sd">        Inputs:</span>
<span class="sd">            X (DataFrame) - features</span>
<span class="sd">            y (numpy array) - targets</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Create folds (add &quot;kfold&quot; column)</span>
        <span class="n">train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stratified_kfold_cv</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Iterating over all stacking levels and over all models</span>
        <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)):</span>

            <span class="c1"># (1) Get features from predictions of models in the previous level.</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_feature_columns</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">level</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;kfold&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_cols</span><span class="p">]</span>            
            
            <span class="c1"># (2) Create features for next level models using current predictions.  </span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Level </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1"> preds: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
                <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">][</span><span class="n">model_name</span><span class="p">]</span>
                <span class="n">preds</span><span class="p">,</span> <span class="n">aucs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_val_preds</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span> 
                <span class="n">train</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aucs</span>
        
                <span class="c1"># Train models on entire feature columns for inference.</span>
                <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        
        <span class="c1"># Save learned metafeatures</span>
        <span class="n">levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)</span>
        <span class="n">metafeatures</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">levels</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metafeatures_</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">metafeatures</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span>
        

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return classification probabilities.&quot;&quot;&quot;</span>
        
        <span class="c1"># Iterate over layers to make predictions.</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_feature_columns</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">level</span><span class="p">)</span>

            <span class="c1"># Append predictions to test DataFrame.</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">][</span><span class="n">model_name</span><span class="p">]</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">])[:,</span> <span class="mi">1</span><span class="p">]</span> 
                <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>

        <span class="c1"># Return last prediction, i.e. top-most model.</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pred</span><span class="p">,</span> <span class="n">pred</span><span class="p">]</span>

    
    <span class="k">def</span> <span class="nf">_stratified_kfold_cv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;kfold&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">skf</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_folds</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">val_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">)):</span>
            <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">val_</span><span class="p">,</span> <span class="s2">&quot;kfold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold</span>
        <span class="k">return</span> <span class="n">data</span>
    
    
    <span class="k">def</span> <span class="nf">_get_feature_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">level</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">level</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;kfold&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_level</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">level</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">prev_level</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">feature_cols</span>

    
    <span class="k">def</span> <span class="nf">_generate_val_preds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="p">):</span>
        <span class="n">val_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">val_aucs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">kfold</span><span class="o">.</span><span class="n">nunique</span><span class="p">()):</span>
            <span class="n">val_pred</span><span class="p">,</span> <span class="n">val_auc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_pred</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span>
            <span class="n">val_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_pred</span><span class="p">)</span>
            <span class="n">val_aucs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_auc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">val_preds</span><span class="p">),</span> <span class="n">val_aucs</span>

    
    <span class="k">def</span> <span class="nf">_val_pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">fold</span><span class="p">,</span> <span class="n">verbose</span><span class="p">):</span>
        <span class="s2">&quot;Return out-of-fold predictions: train on K-1 folds, predict on fold K.&quot;</span>

        <span class="c1"># Get folds; include target and feature cols.</span>
        <span class="n">data_trn</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">kfold</span> <span class="o">!=</span> <span class="n">fold</span><span class="p">]</span>
        <span class="n">data_val</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">kfold</span> <span class="o">==</span> <span class="n">fold</span><span class="p">]</span>
        
        <span class="c1"># Fit model.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_trn</span><span class="p">,</span> <span class="n">data_trn</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">val_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">data_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> 
        <span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">data_val</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">val_pred</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;fold=</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s2">, auc=</span><span class="si">{</span><span class="n">auc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Return out-of-fold predictions.</span>
        <span class="k">return</span> <span class="n">val_pred</span><span class="p">,</span> <span class="n">auc</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="blending-prediction-probabilities">
<h3>Blending prediction probabilities<a class="headerlink" href="#blending-prediction-probabilities" title="Permalink to this headline">¶</a></h3>
<p>Let’s start with a simple stacked model where we simply perform a weighted average of the prediction probabilities. This method is called <strong>blending</strong>. We will use three base models to generate probabilities. Hopefully these are uncorrelated:</p>
<ol class="simple">
<li><p>Logistic Regression + TF-IDF</p></li>
<li><p>Logistic Regression + Count Vectorizer</p></li>
<li><p>Random Forest + TF-IDF + SVD</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReviewColumnExtractor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Extract text column, e.g. letting X = df_train[[&#39;review&#39;]]</span>
<span class="sd">    as train dataset for TfidfVectorizer and CountVectorizer does</span>
<span class="sd">    not work as expected.&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">review</span>
</pre></div>
</div>
</div>
</div>
<p>Initialize base models:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
    <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
    <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">lr_cnt</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
    <span class="n">CountVectorizer</span><span class="p">(),</span>
    <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rf_svd</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
    <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">decomposition</span><span class="o">.</span><span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Run training:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">basemodels</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="s1">&#39;lr_cnt&#39;</span><span class="p">:</span> <span class="n">lr_cnt</span><span class="p">,</span> <span class="s1">&#39;rf_svd&#39;</span><span class="p">:</span> <span class="n">rf_svd</span><span class="p">}</span>
<span class="n">stack</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">([</span><span class="n">basemodels</span><span class="p">])</span>
<span class="n">stack</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Level 0 preds: lr
fold=0, auc=0.9381197524790099
fold=1, auc=0.9324757299029196
fold=2, auc=0.9339827359309438
fold=3, auc=0.9294992179968721
fold=4, auc=0.9271420860696936

Level 0 preds: lr_cnt
fold=0, auc=0.9485602942411769
fold=1, auc=0.9419147676590707
fold=2, auc=0.9474275397101588
fold=3, auc=0.943625774503098
fold=4, auc=0.9382201109952497

Level 0 preds: rf_svd
fold=0, auc=0.8831412825651302
fold=1, auc=0.8762381299525198
fold=2, auc=0.8792050168200674
fold=3, auc=0.8731112424449698
fold=4, auc=0.8795378539601714
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;__main__.StackingClassifier at 0x16e29e970&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>rf_svd_0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.052181</td>
      <td>0.001930</td>
      <td>0.27</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.029885</td>
      <td>0.000006</td>
      <td>0.30</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.052702</td>
      <td>0.000440</td>
      <td>0.32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.917899</td>
      <td>0.996462</td>
      <td>0.65</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.982799</td>
      <td>0.999165</td>
      <td>0.86</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19995</th>
      <td>0.531607</td>
      <td>0.047658</td>
      <td>0.55</td>
    </tr>
    <tr>
      <th>19996</th>
      <td>0.713444</td>
      <td>0.999911</td>
      <td>0.58</td>
    </tr>
    <tr>
      <th>19997</th>
      <td>0.882874</td>
      <td>0.992238</td>
      <td>0.75</td>
    </tr>
    <tr>
      <th>19998</th>
      <td>0.639375</td>
      <td>0.907093</td>
      <td>0.70</td>
    </tr>
    <tr>
      <th>19999</th>
      <td>0.134785</td>
      <td>0.000208</td>
      <td>0.49</td>
    </tr>
  </tbody>
</table>
<p>20000 rows × 3 columns</p>
</div></div></div>
</div>
<p>Check if basemodels are uncorrelated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>rf_svd_0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lr_0</th>
      <td>1.000000</td>
      <td>0.884571</td>
      <td>0.832398</td>
    </tr>
    <tr>
      <th>lr_cnt_0</th>
      <td>0.884571</td>
      <td>1.000000</td>
      <td>0.727050</td>
    </tr>
    <tr>
      <th>rf_svd_0</th>
      <td>0.832398</td>
      <td>0.727050</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The model saves learned probabilistic features:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">head</span><span class="p">()</span> <span class="c1"># predict probas for each example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(20000, 3)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>rf_svd_0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.052181</td>
      <td>0.001930</td>
      <td>0.27</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.029885</td>
      <td>0.000006</td>
      <td>0.30</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.052702</td>
      <td>0.000440</td>
      <td>0.32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.917899</td>
      <td>0.996462</td>
      <td>0.65</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.982799</td>
      <td>0.999165</td>
      <td>0.86</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can also check scores of the base models on each validation fold. This informs us of the stability of the folds and the cross-validation performance of the base models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>rf_svd_0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>0.932244</td>
      <td>0.943950</td>
      <td>0.878247</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.004218</td>
      <td>0.004196</td>
      <td>0.003773</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s try to blend the probabilities using some hand-designed coefficients.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># roc is scale invariant, so we dont bother dividing by total weights</span>
<span class="n">avg_preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">wtd_preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rank_avg_preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rank_wtd_preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Calculate AUC over combined OOF preds</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (averaged):     &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">avg_preds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (wtd. avg):     &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">wtd_preds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (rank avg):     &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">rank_avg_preds</span><span class="p">))</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (wtd. rank avg):&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">rank_wtd_preds</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train AUC (averaged):      0.9320632947484941
Train AUC (wtd. avg):      0.9333874895288372
Train AUC (rank avg):      0.9279256398115597
Train AUC (wtd. rank avg): 0.9338361261484154
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="finding-blending-coefficients-that-optimize-auc">
<h3>Finding blending coefficients that optimize AUC<a class="headerlink" href="#finding-blending-coefficients-that-optimize-auc" title="Permalink to this headline">¶</a></h3>
<p>Since these coefficients are hand-designed, we may want to devise a strategy for automatically finding the optimal coefficients for blending. This is accomplished by the folowing class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Blender</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implement blending that maximizes AUC score.&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Find optimal blending coefficients.&quot;&quot;&quot;</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_auc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return blended probabilities for class 0 and class 1.&quot;&quot;&quot;</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>
            
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pred</span><span class="p">,</span> <span class="n">pred</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_auc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate AUC of blended predict probas.&quot;&quot;&quot;</span>

        <span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">coef</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">auc</span> <span class="c1"># min -auc = max auc</span>
    
    <span class="k">def</span> <span class="nf">_optimize_auc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Maximize AUC as a bound-constrained optimization problem using Nelder-Mead </span>
<span class="sd">        method with Dirichlet init. </span>
<span class="sd">        </span>
<span class="sd">        Reference: </span>
<span class="sd">        https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">partial_loss</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_auc</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span> 
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">init_coef</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">minimize</span><span class="p">(</span><span class="n">partial_loss</span><span class="p">,</span> <span class="n">init_coef</span><span class="p">,</span> 
                        <span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span> 
                        <span class="n">bounds</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>This implementation uses <code class="docutils literal notranslate"><span class="pre">partial</span></code> from <code class="docutils literal notranslate"><span class="pre">functools</span></code> and <code class="docutils literal notranslate"><span class="pre">minimize</span></code> from <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> to minimize the coefficients constained in <span class="math notranslate nohighlight">\((0, 1).\)</span> The initial values of the coefficient are drawn from a Dirichlet distribution <span class="math notranslate nohighlight">\(\operatorname{Dir}(\boldsymbol{\alpha})\)</span> with <span class="math notranslate nohighlight">\(\boldsymbol{\alpha} = [1, 1, 1].\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Blended predictions</span>
<span class="n">blender</span> <span class="o">=</span> <span class="n">Blender</span><span class="p">()</span>
<span class="n">blender</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">combined_oof_preds</span> <span class="o">=</span> <span class="n">blender</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Blended ranked predictions</span>
<span class="n">blender_rk</span> <span class="o">=</span> <span class="n">Blender</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">blender_rk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">combined_oof_rk_preds</span> <span class="o">=</span> <span class="n">blender_rk</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">metafeatures_</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (Blended):    &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">combined_oof_preds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (Blended rk.):&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">combined_oof_rk_preds</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train AUC (Blended):     0.9335436800926852
Train AUC (Blended rk.): 0.9343620830471198
</pre></div>
</div>
</div>
</div>
<p>These scores beat the scores for hand-designed ones. Note that the model is not overfitted. This motivates why we take out-of-fold predictions to create meta-features. In fact, the train AUC should be a good approximation of the test AUC. Calculating the train AUC on the entire out-of-fold predictions involves tracking the rows of the confusion matrix that is the sum of the confusion matrices for each fold, over all thresholds. On the other hand, the average AUC scores on CV folds involves tracking each confusion matrix separately to compute the AUC, then averaging the resulting individual AUCs. Thus, train and test AUCs should be similar to cross-validation scores, if error is well-distributed between folds.</p>
<p>We don’t want to retrain the stacked models with the blender at the top. So we just hack into the trained models to make inference on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inference</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">stack</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">test_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">test_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">test_pred</span> <span class="o">=</span> <span class="n">blender</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_features</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">test_rk_pred</span> <span class="o">=</span> <span class="n">blender_rk</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_features</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test AUC (Blended):    &#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test AUC (Blended rk.):&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_rk_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test AUC (Blended):     0.9537213269438443
Test AUC (Blended rk.): 0.9535875592174204
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="blender-as-final-stacker">
<h3>Blender as final stacker<a class="headerlink" href="#blender-as-final-stacker" title="Permalink to this headline">¶</a></h3>
<p>Actually, let’s do that. Seems all stochasticity has been taken care of!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stack</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">([</span><span class="n">basemodels</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;blender&#39;</span><span class="p">:</span> <span class="n">Blender</span><span class="p">()}],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">stack</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">stack_rk</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">([</span><span class="n">basemodels</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;blender_rk&#39;</span><span class="p">:</span> <span class="n">Blender</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="kc">True</span><span class="p">)}],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">stack_rk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test AUC (Blended):    &#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">stack</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test AUC (Blended rk.):&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">stack_rk</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test AUC (Blended):     0.9537213269438443
Test AUC (Blended rk.): 0.9535875592174204
</pre></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Using blended <strong>rank probabilities</strong> is a good trick when optimizing AUC score. Here individual probabilities are replaced by their rank index. Recall that AUC only cares about the predict probability of a randomly chosen negative examples to be assigned lower predict proba than a randomly chosen positive example. Note that this only works for ensembles; for single models using rank probabilities does not affect AUC score.</p>
</div>
</div>
<div class="section" id="xgboost-classifier-as-final-stacker">
<h3>XGBoost classifier as final stacker<a class="headerlink" href="#xgboost-classifier-as-final-stacker" title="Permalink to this headline">¶</a></h3>
<p>Blending can be easily generalized to any machine learning model that learns and predicts with the meta-features. For example, we can train an <code class="docutils literal notranslate"><span class="pre">XGBoostClassifier</span></code> on the meta-features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">basemodels</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="s1">&#39;lr_cnt&#39;</span><span class="p">:</span> <span class="n">lr_cnt</span><span class="p">,</span> <span class="s1">&#39;rf_svd&#39;</span><span class="p">:</span> <span class="n">rf_svd</span><span class="p">}</span>
<span class="n">metamodel</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;xgb&#39;</span><span class="p">:</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> <span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">)}</span>
<span class="n">stack</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">([</span><span class="n">basemodels</span><span class="p">,</span> <span class="n">metamodel</span><span class="p">])</span>
<span class="n">stack</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Level 0 preds: lr
fold=0, auc=0.9381197524790099
fold=1, auc=0.9324757299029196
fold=2, auc=0.9339827359309438
fold=3, auc=0.9294992179968721
fold=4, auc=0.9271420860696936

Level 0 preds: lr_cnt
fold=0, auc=0.9485602942411769
fold=1, auc=0.9419147676590707
fold=2, auc=0.9474275397101588
fold=3, auc=0.943625774503098
fold=4, auc=0.9382201109952497

Level 0 preds: rf_svd
fold=0, auc=0.8831412825651302
fold=1, auc=0.8762381299525198
fold=2, auc=0.8792050168200674
fold=3, auc=0.8731112424449698
fold=4, auc=0.8795378539601714

Level 1 preds: xgb
fold=0, auc=1.0
fold=1, auc=1.0
fold=2, auc=1.0
fold=3, auc=1.0
fold=4, auc=1.0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;__main__.StackingClassifier at 0x16e45bcd0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train AUC (XGB stack):&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">stack</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test  AUC (XGB stack):&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">stack</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train AUC (XGB stack): 0.9998198793497644
Test  AUC (XGB stack): 0.9490586576280645
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">stack</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>rf_svd_0</th>
      <th>xgb_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>0.932244</td>
      <td>0.943950</td>
      <td>0.878247</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.004218</td>
      <td>0.004196</td>
      <td>0.003773</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Observe that cross-validated AUC scores is indicative of test performance. Meanwhile, train AUC is useless. A better estimate is the mean cross-validation AUC score. If we assume that each fold has the same error distribution, then this should approximate the test AUC which can be thought of as predicting on another fold. Indeed, the above results supports this.</p>
</div>
</div>
<div class="section" id="parallelizing-model-training">
<h2>Parallelizing Model Training<a class="headerlink" href="#parallelizing-model-training" title="Permalink to this headline">¶</a></h2>
<p>Generating features require training each model on each fold. This is very slow. Note that each training process are independent of each other (they only use static features from the previous level), so in principle can be easily parallelized. For this task, we parallelize only the training on cross-validation folds. During inference, parallelizing results in worse times, likely due to overhead.</p>
<p>We implement parallelizing training on CV folds using <code class="docutils literal notranslate"><span class="pre">joblib.Parallel</span></code>. Some remarks:</p>
<ul class="simple">
<li><p>Setting <code class="docutils literal notranslate"><span class="pre">backend='loky'</span></code> is important. On a Macbook 2015 with Mojave 10.14.6, setting <code class="docutils literal notranslate"><span class="pre">backend='multiprocessing'</span></code> with an XGBoost classifier causes training to hang. In a Kaggle kernel, <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> doesn’t seem to work at all, even without using an XGBoost model. Using the <code class="docutils literal notranslate"><span class="pre">loky</span></code> backend seems to work consistently across platforms.</p></li>
</ul>
<ul class="simple">
<li><p>Setting <code class="docutils literal notranslate"><span class="pre">nthread=1</span></code> for XGBClassifier decreases train trime from ~250s to ~100s with backend <code class="docutils literal notranslate"><span class="pre">loky</span></code> and <code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code>. Note that the former time is way worse than sequential evaluation.</p></li>
</ul>
<ul class="simple">
<li><p>Joblib pickles every object used inside <code class="docutils literal notranslate"><span class="pre">Parallel</span></code>. Best to use stateless objects. Careful about shared memory. Using <code class="docutils literal notranslate"><span class="pre">n_jobs=1</span></code> turns off parallel computing for debugging.</p></li>
</ul>
<p>Results below show that there is significant speed up with parallelization using the <code class="docutils literal notranslate"><span class="pre">loky</span></code> backend. Consider this implementation the current stable version of our implementation of stacking in this notebook.</p>
<div class="section" id="adding-workers-to-stackingclassifier-using-joblib-parallel">
<h3>Adding workers to <code class="docutils literal notranslate"><span class="pre">StackingClassifier</span></code> using <code class="docutils literal notranslate"><span class="pre">joblib.Parallel</span></code><a class="headerlink" href="#adding-workers-to-stackingclassifier-using-joblib-parallel" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegressionClassifier</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Linear regression for model-based AUC optimization.</span>
<span class="sd">    Note that we transform probabilities to rank probabilities!&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
        
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">rank</span><span class="p">())]</span>
</pre></div>
</div>
</div>
</div>
<p>This defines a linear regression ranking model. Next, we finally implement stacking with parallelism.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StackingClassifierParallel</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Implements model stacking for classification.&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span> 
        <span class="n">num_folds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">NUM_FOLDS</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
        <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;loky&#39;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize by passing list of model dictionaries for each level.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ---</span>
<span class="sd">        models: List of dictionaries of name model pairs for each level. </span>
<span class="sd">        verbose: Verbosity level.</span>
<span class="sd">        num_folds: No. of CV folds.</span>
<span class="sd">        n_jobs:  passed to an internal joblib.Parallel object</span>
<span class="sd">        backend: passed to an internal joblib.Parallel object</span>
<span class="sd">        verbose: passed to an internal joblib.Parallel object</span>
<span class="sd">        See: https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">        &gt;&gt;&gt; models = [</span>
<span class="sd">            {&#39;level1_model1&#39;: level1_model1, &#39;level2_model2&#39;: level2_model2},</span>
<span class="sd">            {&#39;level2_model1&#39;: level2_model1},</span>
<span class="sd">        ]</span>
<span class="sd">        &gt;&gt;&gt; stacked_model = StackingClassifier(models)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">[{</span><span class="n">name</span><span class="p">:</span> <span class="n">clone</span><span class="p">(</span><span class="n">level</span><span class="p">[</span><span class="n">name</span><span class="p">])</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">level</span><span class="p">}</span> <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_scores_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metafeatures_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_folds</span> <span class="o">=</span> <span class="n">num_folds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit classifier. CV strategy: stratified 5-fold.</span>
<span class="sd">        Inputs:</span>
<span class="sd">            X (DataFrame) - features</span>
<span class="sd">            y (numpy array) - targets</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create folds (add &quot;kfold&quot; column)</span>
        <span class="n">train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stratified_kfold_cv</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Iterating over all stacking levels and over all models</span>
        <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)):</span>

            <span class="c1"># (1) Get features from predictions of models in the previous level.</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_feature_columns</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">level</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;kfold&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_cols</span><span class="p">]</span> 
                
            <span class="c1"># Parallel context manager: prevents discarding workers for each model.</span>
            <span class="k">with</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span> <span class="k">as</span> <span class="n">parallel</span><span class="p">:</span>
                
                <span class="c1"># (2) Create features for next level models using current predictions. </span>
                <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Level </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1"> preds: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                                    
                    <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">][</span><span class="n">model_name</span><span class="p">]</span>
                    <span class="n">preds</span><span class="p">,</span> <span class="n">aucs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_fold_preds</span><span class="p">(</span>
                        <span class="n">parallel</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
                                        
                    <span class="n">train</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cv_scores_</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">aucs</span>
                    
                    <span class="c1"># Train models on entire feature columns for inference.</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> 
        
        <span class="c1"># Save learned metafeatures</span>
        <span class="n">levels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)</span>
        <span class="n">metafeatures</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">levels</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metafeatures_</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">metafeatures</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="bp">self</span>
        

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return classification probabilities.&quot;&quot;&quot;</span>
        
        <span class="c1"># Iterate over layers to make predictions.</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_feature_columns</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">level</span><span class="p">)</span>

            <span class="c1"># Append predictions to test DataFrame.</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="p">][</span><span class="n">model_name</span><span class="p">]</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">])[:,</span> <span class="mi">1</span><span class="p">]</span> 
                <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>

        <span class="c1"># Return last prediction, i.e. top-most model.</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pred</span><span class="p">,</span> <span class="n">pred</span><span class="p">]</span>

    
    <span class="k">def</span> <span class="nf">_stratified_kfold_cv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;kfold&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">skf</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_folds</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">fold</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">val_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">)):</span>
            <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">val_</span><span class="p">,</span> <span class="s2">&quot;kfold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fold</span>
        <span class="k">return</span> <span class="n">data</span>
    
    
    <span class="k">def</span> <span class="nf">_get_feature_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">level</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">level</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;kfold&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_level</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">level</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">level</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">prev_level</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">feature_cols</span>

    
    <span class="k">def</span> <span class="nf">_generate_fold_preds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parallel</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="p">):</span>
        <span class="c1"># We clone the model inside to not mess with the random seed.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_predict_fold</span><span class="p">)(</span><span class="n">data</span><span class="p">,</span> <span class="n">clone</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">fold</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">kfold</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="p">))</span>

    
    <span class="k">def</span> <span class="nf">_predict_fold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">fold</span><span class="p">,</span> <span class="n">verbose</span><span class="p">):</span>
        <span class="s2">&quot;Return out-of-fold predictions: train on K-1 folds, predict on fold K.&quot;</span>

        <span class="c1"># Get folds; include target and feature cols.</span>
        <span class="n">data_trn</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">kfold</span> <span class="o">!=</span> <span class="n">fold</span><span class="p">]</span>
        <span class="n">data_val</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">kfold</span> <span class="o">==</span> <span class="n">fold</span><span class="p">]</span>
        
        <span class="c1"># Fit model.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_trn</span><span class="p">,</span> <span class="n">data_trn</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">val_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">data_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> 
        <span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">data_val</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">val_pred</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;fold=</span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s2">, auc=</span><span class="si">{</span><span class="n">auc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Return out-of-fold predictions.</span>
        <span class="k">return</span> <span class="n">val_pred</span><span class="p">,</span> <span class="n">auc</span>
</pre></div>
</div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">StackingClassifierParallel</span></code> is not a scikit-learn estimator, so it cannot be used inside pipelines. That should be fine since we tend to tune the base models individually anyway as the complexity of hyperparameter search increasing exponentially in the number of hyperparameters.</p>
</div>
<div class="section" id="defining-models-to-stack">
<h3>Defining models to stack<a class="headerlink" href="#defining-models-to-stack" title="Permalink to this headline">¶</a></h3>
<p>Define the models for each level.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
    <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
    <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">lr_cnt</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
    <span class="n">CountVectorizer</span><span class="p">(),</span>
    <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rf_svd</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
    <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">decomposition</span><span class="o">.</span><span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Define models dictionaries:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Base models</span>
<span class="n">level1</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">make_pipeline</span><span class="p">(</span>
        <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
        <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
        <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="p">),</span> 
    
    <span class="s1">&#39;lr_cnt&#39;</span><span class="p">:</span> <span class="n">make_pipeline</span><span class="p">(</span>
        <span class="n">ReviewColumnExtractor</span><span class="p">(),</span>
        <span class="n">CountVectorizer</span><span class="p">(),</span> 
        <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="p">),</span> 
<span class="p">}</span>

<span class="c1"># Meta models</span>
<span class="n">level2</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="s1">&#39;linreg&#39;</span><span class="p">:</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearRegressionClassifier</span><span class="p">()),</span>
    <span class="s1">&#39;xgb&#39;</span><span class="p">:</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> 
                         <span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                         <span class="n">nthread</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Meta models</span>
<span class="n">level3</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;linreg&#39;</span><span class="p">:</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearRegressionClassifier</span><span class="p">()),</span>
    <span class="s1">&#39;xgb&#39;</span><span class="p">:</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> 
                         <span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                         <span class="n">nthread</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Blender head: rank true for linear reg.</span>
<span class="n">level4</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;blender&#39;</span><span class="p">:</span> <span class="n">Blender</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Setting <code class="docutils literal notranslate"><span class="pre">nthread=1</span></code> for <code class="docutils literal notranslate"><span class="pre">XGBClassifier</span></code> decreases train time for the parallel stacker from ~250s to ~100s. This goes from worse to better than sequential processing. See <a class="reference external" href="https://github.com/dmlc/xgboost/issues/2163">this issue</a> from the XGBoost repository.</p>
</div>
</div>
<div class="section" id="comparing-training-times-between-serial-and-parallel">
<h3>Comparing training times between serial and parallel<a class="headerlink" href="#comparing-training-times-between-serial-and-parallel" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">time_training</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return model training time vs percentage of train data.</span>
<span class="sd">    NOTE: Trains model as a side effect!&quot;&quot;&quot;</span>
    
    <span class="n">train_times</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
        <span class="c1"># Preprocessing</span>
        <span class="n">X_</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.10</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">)]</span>
        <span class="n">y_</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.10</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">)]</span>
        
        <span class="c1"># Actual timing</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        
        <span class="c1"># Postprocessing</span>
        <span class="n">train_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end_time</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="c1"># Cooling down processor</span>
    
    <span class="k">return</span> <span class="n">train_times</span>
</pre></div>
</div>
</div>
</div>
<p>Timing runs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">level1</span><span class="p">,</span> <span class="n">level2</span><span class="p">,</span> <span class="n">level3</span><span class="p">,</span> <span class="n">level4</span><span class="p">]</span>

<span class="n">serial</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">parallel</span> <span class="o">=</span> <span class="n">StackingClassifierParallel</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">serial_times</span> <span class="o">=</span> <span class="n">time_training</span><span class="p">(</span><span class="n">serial</span><span class="p">)</span>
<span class="n">parallel_times</span> <span class="o">=</span> <span class="n">time_training</span><span class="p">(</span><span class="n">parallel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 10/10 [04:37&lt;00:00, 27.74s/it]
100%|██████████| 10/10 [03:06&lt;00:00, 18.63s/it]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">serial_times</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Serial&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">parallel_times</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Parallel&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Percentage of data. (Total size=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training time (s)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/blending-stacking_65_0.svg" src="../../_images/blending-stacking_65_0.svg" /></div>
</div>
<p>Notice that training times are linear in the dataset size. Training time with parallel processing has a smaller slope, which makes sense since there are more workers which introduces a constant reduction factor for the training time. I was expecting to see some overhead with parallel (initializing / closing workers and consolidating results from different workers). But from the graph, there seems to be little to none! (Joblib good.)</p>
</div>
<div class="section" id="testing-consistency-of-parallel-and-serial-predictions">
<h3>Testing consistency of parallel and serial predictions<a class="headerlink" href="#testing-consistency-of-parallel-and-serial-predictions" title="Permalink to this headline">¶</a></h3>
<p>Testing if predictions agree between serial and parallel training:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># These models are already trained as a side-effect of timing</span>
<span class="n">yp_test</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">ys_test</span> <span class="o">=</span> <span class="n">serial</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">yp_test</span> <span class="o">-</span> <span class="n">ys_test</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e-16</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parallel</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>lr_1</th>
      <th>linreg_1</th>
      <th>xgb_1</th>
      <th>linreg_2</th>
      <th>xgb_2</th>
      <th>blender_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.052181</td>
      <td>0.001930</td>
      <td>0.000659</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>955.843253</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.029885</td>
      <td>0.000006</td>
      <td>0.000640</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>1038.124480</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.052702</td>
      <td>0.000440</td>
      <td>0.000658</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>955.843253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.917899</td>
      <td>0.996462</td>
      <td>0.999197</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>1841.468940</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.982799</td>
      <td>0.999165</td>
      <td>0.999260</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>1704.229475</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">serial</span><span class="o">.</span><span class="n">metafeatures_</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lr_0</th>
      <th>lr_cnt_0</th>
      <th>lr_1</th>
      <th>linreg_1</th>
      <th>xgb_1</th>
      <th>linreg_2</th>
      <th>xgb_2</th>
      <th>blender_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.052181</td>
      <td>0.001930</td>
      <td>0.000659</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>955.843253</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.029885</td>
      <td>0.000006</td>
      <td>0.000640</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>1038.124480</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.052702</td>
      <td>0.000440</td>
      <td>0.000658</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>-0.375688</td>
      <td>0.000111</td>
      <td>955.843253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.917899</td>
      <td>0.996462</td>
      <td>0.999197</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>1841.468940</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.982799</td>
      <td>0.999165</td>
      <td>0.999260</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>-0.125688</td>
      <td>0.999888</td>
      <td>1704.229475</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="checking-side-effect-on-data">
<h3>Checking side-effect on data<a class="headerlink" href="#checking-side-effect-on-data" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">stack</span> <span class="o">=</span> <span class="n">StackingClassifierParallel</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">stack</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">assert</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">==</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                             
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>In this notebook we have implemented a class for model stacking and blending on a text classification task. We saw that stacking uncorrelated models result in some improvement in performance by creating metafeatures which are prediction probabilities of lower level models.</p>
<p>The main tools constructed in this notebook are the <strong><code class="docutils literal notranslate"><span class="pre">StackingClassifierParallel</span></code></strong> and the <strong><code class="docutils literal notranslate"><span class="pre">Blender</span></code></strong> classes. These classes expose a <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.predict_proba()</span></code> method similar to scikit-learn models, as well as learned attributes <code class="docutils literal notranslate"><span class="pre">.metafeatures_</span></code> and <code class="docutils literal notranslate"><span class="pre">.coef_</span></code> which can be useful for hacking into the models. The parallel implementation resulted in significant reduction in training time, without any undesirable side-effects. The implementation of blending uses the Nelder-Mead method from <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> to find the best blending coefficents for the columns.</p>
<div class="section" id="parallelized-model-training">
<h3>Parallelized model training<a class="headerlink" href="#parallelized-model-training" title="Permalink to this headline">¶</a></h3>
<p>Parallelism can perhaps be implemented during inference, but this would depend on the exact use case.
We got into some trouble with getting reproducible results using <code class="docutils literal notranslate"><span class="pre">joblib.Parallel</span></code>. This is solved by cloning the models in the right places. Also, we had issues making parallel work with XGBoost. But the current configuration seems to work in a Kaggle Kernel.</p>
</div>
<div class="section" id="further-improvements">
<h3>Further improvements<a class="headerlink" href="#further-improvements" title="Permalink to this headline">¶</a></h3>
<p>To further support hacking into the models and metafeatures of the stacker, we can implement a <code class="docutils literal notranslate"><span class="pre">start_from_level</span></code> parameter on the fit function which assumes metafeatures from levels <code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">...,</span> <span class="pre">start_from_level-1</span></code> has been appended to the <code class="docutils literal notranslate"><span class="pre">.metafeatures_</span></code> attribute, and that the corresponding models have been trained on the respective whole columns, ready for inference. Some rules are needed to make this work, for one, the models dict should include the models to be injected. And that there must be a function to supply the metafeatures so that naming conventions are adhered to — both are easy. This is nice if we have large models to stack and we don’t have the resources to retrain them.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/fundamentals"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="house-prices.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Modelling with Pipelines</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="optuna.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Model Tuning with Optuna</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 𝗥𝗼𝗻 𝗠𝗲𝗱𝗶𝗻𝗮. Powered by <a href="https://jupyterbook.org">Jupyter Book</a>.<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>