{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "hyperopt-optuna-test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-bCjQI4cMwJ"
      },
      "source": [
        "# Hyperparameter Tuning with Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NK-oxLtcMwV"
      },
      "source": [
        "\n",
        "\n",
        "With great models, comes the great problem of optimizing hyperparameters {cite}`AAAMLP`. Once a good search algorithm is established for hyperparameter optimization, the task becomes an engineering problem [^ref]. Hence, we will explore an open-source library that offers a framework for solving this task. \n",
        "\n",
        "[^ref]: Like all applied machine learning solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2gyvfOcMwZ"
      },
      "source": [
        "```{figure} ../img/optuna.png\n",
        "---\n",
        "width: 25em\n",
        "name: optuna\n",
        "---\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ht_p93LcMwa"
      },
      "source": [
        "> **Optuna** is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, *define-by-run* style user API. Thanks to our *define-by-run* API, the code written with Optuna enjoys high modularity, and the user of Optuna can dynamically construct the search spaces for the hyperparameters.\n",
        "\n",
        "\n",
        "- [Optuna FAQ](https://optuna.readthedocs.io/en/stable/faq.html)\n",
        "- [Optuna docs](https://optuna.readthedocs.io/en/stable/index.html#)\n",
        "- [Optuna paper](https://arxiv.org/abs/1907.10902)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klJlBflxcMwb"
      },
      "source": [
        "## Basics with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTOBy10ecMwb"
      },
      "source": [
        "Optuna is a black-box optimizer, which means it only needs an objective function, which is any function that returns a numerical value, to evaluate the performance of the its parameters, and decide where to sample in upcoming trials. An optimization problem is framed in the Optuna API using two basic concepts: `study` and `trial`. \n",
        "\n",
        "A study is conceptually an optimization based on an objective function, while a trial is a single execution of an objective function. The combination of hyperparameters for each trial is sampled according to some sampling algorithm defined by the study. \n",
        "\n",
        "In the following code example, the search space is constructed within imperative Python code, e.g. inside conditionals or loops. On the other hand, recall that for `GridSearchCV` and `RandomSearchCV` in scikit-learn, we had to define the entire search space before running the search algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HmNJmtscMwc"
      },
      "source": [
        "````{margin}\n",
        "```{tip}\n",
        "Always perform model evaluation on a dataset within a cross-validation framework!\n",
        "```\n",
        "````"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MYKq1Y9cMwd",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:11:23.639681Z",
          "iopub.execute_input": "2021-09-23T18:11:23.639999Z",
          "iopub.status.idle": "2021-09-23T18:11:35.179886Z",
          "shell.execute_reply.started": "2021-09-23T18:11:23.639920Z",
          "shell.execute_reply": "2021-09-23T18:11:35.179172Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2108c313-f967-4d79-9e0c-426bedaa33ab"
      },
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "import pandas as pd\n",
        "from sklearn import ensemble, svm\n",
        "from sklearn import datasets\n",
        "from sklearn import model_selection\n",
        "from functools import partial\n",
        "import joblib\n",
        "\n",
        "\n",
        "# [1] Define an objective function to be maximized.\n",
        "def objective(trial, X, y):\n",
        "    \n",
        "    # [2] Suggest values for the hyperparameters using trial object.\n",
        "    clf_name = trial.suggest_categorical('classifier', ['SVC', 'RandomForest'])\n",
        "    if clf_name == 'SVC':\n",
        "        svc_c = trial.suggest_loguniform('svc_c', 1e-10, 1e10)\n",
        "        clf = svm.SVC(C=svc_c, gamma='auto')\n",
        "    else:\n",
        "        rf_max_depth = int(trial.suggest_loguniform('rf_max_depth', 2, 32))\n",
        "        clf = ensemble.RandomForestClassifier(max_depth=rf_max_depth, n_estimators=10)\n",
        "\n",
        "    score = model_selection.cross_val_score(clf, X, y, n_jobs=-1, cv=5)\n",
        "    return score.mean()\n",
        "\n",
        "# [3] Create a study object and optimize the objective function.\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(partial(objective, X=X, y=y), n_trials=5)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.23)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.3-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.2.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.2.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 43.4 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 57.0 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=f947121c655b70878501035318321913678424de3907ac3a82165dfe493b9116\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.5 alembic-1.7.3 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.2.0 colorama-0.4.4 colorlog-6.4.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-23 18:35:02,488]\u001b[0m A new study created in memory with name: no-name-f461ac73-40bc-492b-bb8c-4864ca99b83e\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:35:03,652]\u001b[0m Trial 0 finished with value: 0.9508150908244062 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 6.509030505470388}. Best is trial 0 with value: 0.9508150908244062.\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:35:03,752]\u001b[0m Trial 1 finished with value: 0.6274181027790716 and parameters: {'classifier': 'SVC', 'svc_c': 1449.4111764866836}. Best is trial 0 with value: 0.9508150908244062.\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:35:03,854]\u001b[0m Trial 2 finished with value: 0.6274181027790716 and parameters: {'classifier': 'SVC', 'svc_c': 10299.635699270357}. Best is trial 0 with value: 0.9508150908244062.\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:35:03,976]\u001b[0m Trial 3 finished with value: 0.9595559695699425 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 18.812277838603638}. Best is trial 3 with value: 0.9595559695699425.\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:35:04,094]\u001b[0m Trial 4 finished with value: 0.9543549138332557 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 20.212303328083728}. Best is trial 3 with value: 0.9595559695699425.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsGUAer5cMwg"
      },
      "source": [
        "The `study` object saves the result of evaluating the objective each trial &mdash; which is essentially some choice of hyperparameters to evaluate. In the above study, the problem of model selection is framed as a hyperparameter optimization problem. Here we choose between an SVM-based algorithm or Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e2vQKKTcMwh",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:11:35.181756Z",
          "iopub.execute_input": "2021-09-23T18:11:35.182002Z",
          "iopub.status.idle": "2021-09-23T18:11:35.215602Z",
          "shell.execute_reply.started": "2021-09-23T18:11:35.181963Z",
          "shell.execute_reply": "2021-09-23T18:11:35.214740Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f23de1a8-301f-4b07-e572-e4cf2ef4180e"
      },
      "source": [
        "study.trials_dataframe().head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_classifier</th>\n",
              "      <th>params_rf_max_depth</th>\n",
              "      <th>params_svc_c</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.950815</td>\n",
              "      <td>2021-09-23 18:35:02.492833</td>\n",
              "      <td>2021-09-23 18:35:03.652200</td>\n",
              "      <td>0 days 00:00:01.159367</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>6.509031</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.627418</td>\n",
              "      <td>2021-09-23 18:35:03.654568</td>\n",
              "      <td>2021-09-23 18:35:03.752128</td>\n",
              "      <td>0 days 00:00:00.097560</td>\n",
              "      <td>SVC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1449.411176</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.627418</td>\n",
              "      <td>2021-09-23 18:35:03.754231</td>\n",
              "      <td>2021-09-23 18:35:03.854141</td>\n",
              "      <td>0 days 00:00:00.099910</td>\n",
              "      <td>SVC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10299.635699</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.959556</td>\n",
              "      <td>2021-09-23 18:35:03.855947</td>\n",
              "      <td>2021-09-23 18:35:03.976102</td>\n",
              "      <td>0 days 00:00:00.120155</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>18.812278</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.954355</td>\n",
              "      <td>2021-09-23 18:35:03.977696</td>\n",
              "      <td>2021-09-23 18:35:04.094330</td>\n",
              "      <td>0 days 00:00:00.116634</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>20.212303</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   number     value  ...  params_svc_c     state\n",
              "0       0  0.950815  ...           NaN  COMPLETE\n",
              "1       1  0.627418  ...   1449.411176  COMPLETE\n",
              "2       2  0.627418  ...  10299.635699  COMPLETE\n",
              "3       3  0.959556  ...           NaN  COMPLETE\n",
              "4       4  0.954355  ...           NaN  COMPLETE\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJFdE1kwcMwi"
      },
      "source": [
        "### Fine tuning Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x20Gt3wccMwj"
      },
      "source": [
        "Here we focus on tuning a single Random Forest model. Then, plot the accuracy for each pair of hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2o11RCLcMwk",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:11:35.217082Z",
          "iopub.execute_input": "2021-09-23T18:11:35.217426Z",
          "iopub.status.idle": "2021-09-23T18:14:43.355194Z",
          "shell.execute_reply.started": "2021-09-23T18:11:35.217384Z",
          "shell.execute_reply": "2021-09-23T18:14:43.354507Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac54e856-cbd6-40a2-c787-60f2e91000df"
      },
      "source": [
        "def objective(trial):\n",
        "    \n",
        "    max_depth = trial.suggest_int('max_depth', 2, 128, log=True)    \n",
        "    max_features = trial.suggest_float('max_features', 0.1, 1.0)    \n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 800)\n",
        "    \n",
        "    clf = ensemble.RandomForestClassifier(\n",
        "        max_depth=max_depth,\n",
        "        n_estimators=n_estimators,\n",
        "        max_features=max_features,\n",
        "        random_state=42)   \n",
        "    \n",
        "    score = model_selection.cross_val_score(clf, X, y, n_jobs=-1, cv=5)\n",
        "    return score.mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-23 18:36:54,213]\u001b[0m A new study created in memory with name: no-name-4158c0df-530d-4ec5-8bf9-3ac5c03224b7\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:36:59,231]\u001b[0m Trial 0 finished with value: 0.9543238627542309 and parameters: {'max_depth': 2, 'max_features': 0.15685233834481263, 'n_estimators': 518}. Best is trial 0 with value: 0.9543238627542309.\u001b[0m\n",
            "\u001b[32m[I 2021-09-23 18:37:01,252]\u001b[0m Trial 1 finished with value: 0.9631423691973297 and parameters: {'max_depth': 22, 'max_features': 0.3306429704798146, 'n_estimators': 183}. Best is trial 1 with value: 0.9631423691973297.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5feGzBJTcMwm",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:43.356416Z",
          "iopub.execute_input": "2021-09-23T18:14:43.358114Z",
          "iopub.status.idle": "2021-09-23T18:14:43.366779Z",
          "shell.execute_reply.started": "2021-09-23T18:14:43.358084Z",
          "shell.execute_reply": "2021-09-23T18:14:43.365955Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7992a381-4410-4677-ccfe-69fdaca001ff"
      },
      "source": [
        "study.best_params"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 22, 'max_features': 0.3306429704798146, 'n_estimators': 183}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzKJQni3iEiD",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:43.369289Z",
          "iopub.execute_input": "2021-09-23T18:14:43.369749Z",
          "iopub.status.idle": "2021-09-23T18:14:43.378058Z",
          "shell.execute_reply.started": "2021-09-23T18:14:43.369713Z",
          "shell.execute_reply": "2021-09-23T18:14:43.377333Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a439499-5130-47a4-a412-a2b2d7658990"
      },
      "source": [
        "study.best_value"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9631423691973297"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqulVaLvfkD1"
      },
      "source": [
        "### Sampling algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMDs6zccMwl",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:43.379198Z",
          "iopub.execute_input": "2021-09-23T18:14:43.379397Z",
          "iopub.status.idle": "2021-09-23T18:14:44.021748Z",
          "shell.execute_reply.started": "2021-09-23T18:14:43.379375Z",
          "shell.execute_reply": "2021-09-23T18:14:44.021086Z"
        },
        "trusted": true
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
        "\n",
        "def plot_results(study, p1, p2, j, cb):\n",
        "    study.trials_dataframe().plot(\n",
        "        kind='scatter', ax=axes[j], x=p1, y=p2,\n",
        "        c='value', s=60, cmap=plt.get_cmap(\"jet\"), \n",
        "        colorbar=cb, label=\"accuracy\", figsize=(16, 4)\n",
        "    )\n",
        "\n",
        "plot_results(study, 'params_max_depth',    'params_n_estimators', j=0, cb=False)\n",
        "plot_results(study, 'params_max_depth',    'params_max_features', j=1, cb=False)\n",
        "plot_results(study, 'params_n_estimators', 'params_max_features', j=2, cb=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttvy3BEAcMwm"
      },
      "source": [
        "**Figure.** TPE in action. Optuna uses  **Tree-structured Parzen Estimater (TPE)** {cite}`bergstra` as the default sampler which is a form of Bayesian optimization. Observe that the hyperparameter space is searched more efficiently than a random search with the sampler choosing points closer to previous good results. Samplers are specified when creating a study: \n",
        "\n",
        "```python\n",
        "study = create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
        "```\n",
        "\n",
        "From the [docs](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler):\n",
        "\n",
        "> On each trial, for each parameter, TPE fits one Gaussian Mixture Model (GMM) `l(x)` to the set of parameter values associated with the best objective values, and another GMM `g(x)` to the remaining parameter values. It chooses the parameter value `x` that maximizes the ratio `l(x)/g(x)`.\n",
        "\n",
        "Thus, TPE samples every hyperparameter **independently** &mdash; no explicit hyperparameter interactions are considered when sampling future trials, although other parameters implicitly affect objective value. Optuna also implements old friends random and grid search in the following samplers:\n",
        "- `optuna.samplers.GridSampler`\n",
        "- `optuna.samplers.RandomSampler`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN6cMax5fkD2"
      },
      "source": [
        "Results from the [paper](https://arxiv.org/pdf/1907.10902.pdf) {cite}`akiba2019optuna`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRbOyHBvfkD3"
      },
      "source": [
        "```{figure} ../img/fig9-optuna.png\n",
        "---\n",
        "width: 35em\n",
        "name: fig9-optuna\n",
        "---\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi5gn3PZfkD4"
      },
      "source": [
        "```{figure} ../img/fig10-optuna.png\n",
        "---\n",
        "width: 35em\n",
        "name: fig10-optuna\n",
        "---\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx-tL9u0c5eK"
      },
      "source": [
        "```{figure} ../img/optuna-results.png\n",
        "---\n",
        "width: 35em\n",
        "name: optuna-results\n",
        "---\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVSTHUFifkD4"
      },
      "source": [
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "**TPE+CMA-ES** sampling can be implemented as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMS3blPQfkD5",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:44.022885Z",
          "iopub.execute_input": "2021-09-23T18:14:44.023664Z",
          "iopub.status.idle": "2021-09-23T18:14:44.029665Z",
          "shell.execute_reply.started": "2021-09-23T18:14:44.023626Z",
          "shell.execute_reply": "2021-09-23T18:14:44.028909Z"
        },
        "trusted": true
      },
      "source": [
        "sampler = optuna.samplers.CmaEsSampler(\n",
        "    warn_independent_sampling=False,\n",
        "    independent_sampler=optuna.samplers.TPESampler()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm4sWHu3fkD6"
      },
      "source": [
        "This uses the CMA-ES algorithm {cite}`hansen2016cma` with TPE for searching dynamically constructed hyperparameters (as CMA-ES requires that parameters are specified prior to the optimization). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN93Al8mcMwp"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ2Pxq8UcMwq"
      },
      "source": [
        "Optuna provides visualization functions in the `optuna.visualization` library [^ref4]. The following plot shows the best objective value found as the trials progress. The increasing trend in accuracy indicates that the TPE sampler is working well, i.e. the search algorithm learns from previous trials.\n",
        "\n",
        "[^ref4]: See [Optuna dashboard](https://github.com/optuna/optuna-dashboard) which displays the same plots that are updated in real-time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKyxRYrDcMwq",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:44.030831Z",
          "iopub.execute_input": "2021-09-23T18:14:44.031254Z",
          "iopub.status.idle": "2021-09-23T18:14:44.139947Z",
          "shell.execute_reply.started": "2021-09-23T18:14:44.031196Z",
          "shell.execute_reply": "2021-09-23T18:14:44.139262Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "cda97e9e-e93e-4ed7-8581-7efc519b4a75"
      },
      "source": [
        "fig = optuna.visualization.plot_optimization_history(study)\n",
        "fig.show(renderer=\"colab\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"e412938d-3ea7-42be-aac1-08fff3370925\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"e412938d-3ea7-42be-aac1-08fff3370925\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'e412938d-3ea7-42be-aac1-08fff3370925',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.9543238627542309, 0.9631423691973297]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0.9543238627542309, 0.9631423691973297]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e412938d-3ea7-42be-aac1-08fff3370925');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjeqUb4ycMws"
      },
      "source": [
        "The **parallel coordinate plot** gives us a feel of how the hyperparameters interact. For instance, `max_features` around 0.5 with `n_estimators` around 280 and `max_depth` around 20 generally perform well. This setting includes the best performing hyperparameters. To isolate subsets of lines, use the interactive capabilities of the plot below by dragging on each axis to restrict it. See {ref}`figure <optuna-restrict-rf>` immediately below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRj1KRqPYkuX",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:44.141173Z",
          "iopub.execute_input": "2021-09-23T18:14:44.141451Z",
          "iopub.status.idle": "2021-09-23T18:14:44.204416Z",
          "shell.execute_reply.started": "2021-09-23T18:14:44.141415Z",
          "shell.execute_reply": "2021-09-23T18:14:44.203767Z"
        },
        "trusted": true
      },
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3RxLfaFc5eR"
      },
      "source": [
        "```{figure} ../img/optuna-restrict-rf.png\n",
        "---\n",
        "name: optuna-restrict-rf\n",
        "---\n",
        "Using sliders to restrict values for certain parameters.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnLBWNAycMwt"
      },
      "source": [
        "**Slice plots** project the path of the optimizer in the hyperparameter space on each dimension, then shift along the $y$-axis according on its objective value. A large spread of dark dots indicate that a large range of values of that hyperparameter is feasible even at later stages. Meanwhile, a small spread means that the sampler focuses on a small part of the search space &mdash; in this case, other hyperparameters implicitly improve the objective. For example, the parameter `max_features` is explored at a wide range even at later trials. Hence, we think of this feature as important. Indeed, the importance plot below supports this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWjlffH3cMwu",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:44.205548Z",
          "iopub.execute_input": "2021-09-23T18:14:44.205768Z",
          "iopub.status.idle": "2021-09-23T18:14:44.389725Z",
          "shell.execute_reply.started": "2021-09-23T18:14:44.205739Z",
          "shell.execute_reply": "2021-09-23T18:14:44.388963Z"
        },
        "trusted": true
      },
      "source": [
        "optuna.visualization.plot_slice(study, params=['n_estimators', 'max_depth', 'max_features'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iII1pxdlcMwv"
      },
      "source": [
        "By default, the **hyperparameter importance evaluator** in Optuna is `optuna.importance.FanovaImportanceEvaluator`. This takes as input performance data gathered with different hyperparameter settings of the algorithm, fits a random forest to capture the relationship between hyperparameters and performance, and then applies functional ANOVA to assess how important each of the hyperparameters and each low-order interaction of hyperparameters is to performance {cite}`pmlr-v32-hutter14`. From the [docs](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.importance.FanovaImportanceEvaluator.html):\n",
        "\n",
        "> The performance of fANOVA depends on the prediction performance of the underlying random forest model. In order to obtain high prediction performance, it is necessary to cover a wide range of the hyperparameter search space. It is recommended to use an exploration-oriented sampler such as `RandomSampler`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK8u3L14cMwv",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:44.390811Z",
          "iopub.execute_input": "2021-09-23T18:14:44.391120Z",
          "iopub.status.idle": "2021-09-23T18:14:45.574258Z",
          "shell.execute_reply.started": "2021-09-23T18:14:44.391083Z",
          "shell.execute_reply": "2021-09-23T18:14:45.573428Z"
        },
        "trusted": true
      },
      "source": [
        "fig = optuna.visualization.plot_param_importances(study)\n",
        "fig.update_layout(width=600, height=350)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1pnFEAUcMwx"
      },
      "source": [
        "To visualize interactions of any pair of hyperparameters, we use **contour plots.** The contour plots indicate regions of high and low objective value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIfwjUHQcMwx",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:45.575992Z",
          "iopub.execute_input": "2021-09-23T18:14:45.576295Z",
          "iopub.status.idle": "2021-09-23T18:14:45.661852Z",
          "shell.execute_reply.started": "2021-09-23T18:14:45.576261Z",
          "shell.execute_reply": "2021-09-23T18:14:45.661224Z"
        },
        "trusted": true
      },
      "source": [
        "fig = optuna.visualization.plot_contour(study, params=[\"max_depth\", \"max_features\"])\n",
        "fig.update_layout(width=550, height=500)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOMjA7fcMw2"
      },
      "source": [
        "## Neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQlLZWfcMw2"
      },
      "source": [
        "As noted above, we should always perform tuning within a cross-validation framework. However, with neural networks, doing 5-fold CV would require too much compute time &mdash; hence, too much resources, e.g. GPU usage. Instead, we perform tuning on a hold-out validation set and hope for the best. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmb20AphcMw2",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:45.663008Z",
          "iopub.execute_input": "2021-09-23T18:14:45.663410Z",
          "iopub.status.idle": "2021-09-23T18:14:50.124937Z",
          "shell.execute_reply.started": "2021-09-23T18:14:45.663363Z",
          "shell.execute_reply": "2021-09-23T18:14:50.124207Z"
        },
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "from tqdm import tqdm\n",
        "import optuna\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r6ehhdjcMw3"
      },
      "source": [
        "Define a simple network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsALWtW9cMw4",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:50.128186Z",
          "iopub.execute_input": "2021-09-23T18:14:50.128456Z",
          "iopub.status.idle": "2021-09-23T18:14:50.136645Z",
          "shell.execute_reply.started": "2021-09-23T18:14:50.128420Z",
          "shell.execute_reply": "2021-09-23T18:14:50.135701Z"
        },
        "trusted": true
      },
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network with multiple hidden fully-connected layers with ReLU \n",
        "    activation and dropout.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, num_classes, n_layers, out_features, drop_rate):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_features = input_size\n",
        "        for i in range(n_layers):\n",
        "\n",
        "            m = nn.Linear(in_features, out_features[i])\n",
        "            nn.init.kaiming_normal_(m.weight)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "            layers.append(m)\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(drop_rate))\n",
        "\n",
        "            in_features = out_features[i]\n",
        "\n",
        "        layers.append(nn.Linear(in_features, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBCd4FoBcMw6"
      },
      "source": [
        "We also define a `Dataset` class for MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Hp-YoCcMw6",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:50.138043Z",
          "iopub.execute_input": "2021-09-23T18:14:50.138671Z",
          "iopub.status.idle": "2021-09-23T18:14:50.149067Z",
          "shell.execute_reply.started": "2021-09-23T18:14:50.138526Z",
          "shell.execute_reply": "2021-09-23T18:14:50.148230Z"
        },
        "trusted": true
      },
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, features, targets, transform=None):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        X = self.features[i, :]\n",
        "        y = self.targets[i]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "            \n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7GrtPtEcMw6"
      },
      "source": [
        "Define a trainer for the neural network model. This will handle all loss and metric evaluation, as well as backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ30iSjfcMw7",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:50.150383Z",
          "iopub.execute_input": "2021-09-23T18:14:50.150804Z",
          "iopub.status.idle": "2021-09-23T18:14:50.165337Z",
          "shell.execute_reply.started": "2021-09-23T18:14:50.150767Z",
          "shell.execute_reply": "2021-09-23T18:14:50.164635Z"
        },
        "trusted": true
      },
      "source": [
        "class Engine:\n",
        "    \"\"\"Neural network trainer.\"\"\"\n",
        "    \n",
        "    def __init__(self, model, device, optimizer):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer \n",
        "\n",
        "    @staticmethod\n",
        "    def loss_fn(outputs, targets):\n",
        "        return nn.CrossEntropyLoss()(outputs, targets)\n",
        "        \n",
        "    def train(self, data_loader):\n",
        "        \"\"\"Train model on one epoch. Return train loss.\"\"\"\n",
        "        \n",
        "        self.model.train()\n",
        "        loss = 0\n",
        "        for i, (data, targets) in enumerate(data_loader):\n",
        "            data = data.to(self.device).reshape(data.shape[0], -1).float()\n",
        "            targets = targets.to(self.device).long()\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = self.model(data)\n",
        "            J = self.loss_fn(outputs, targets)\n",
        "            \n",
        "            # Backward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            J.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Cumulative loss\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def eval(self, data_loader):\n",
        "        \"\"\"Return validation loss and validation accuracy.\"\"\"\n",
        "        \n",
        "        self.model.eval()\n",
        "        num_correct = 0\n",
        "        num_samples = 0\n",
        "        loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i, (data, targets) in enumerate(data_loader):\n",
        "                data = data.to(self.device).float()\n",
        "                targets = targets.to(self.device)\n",
        "                \n",
        "                # Forward pass\n",
        "                data = data.reshape(data.shape[0], -1)\n",
        "                out = self.model(data)\n",
        "                J = self.loss_fn(out, targets)\n",
        "                _, preds = out.max(dim=1)\n",
        "\n",
        "                # Cumulative metrics\n",
        "                loss += (J.detach().item() - loss) / (i + 1)\n",
        "                num_correct += (preds == targets).sum().item()\n",
        "                num_samples += preds.shape[0]\n",
        "\n",
        "        acc = num_correct / num_samples\n",
        "        return loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1WBd1fkcMw7"
      },
      "source": [
        "Some config and setup prior to training. For our dataset, we use MNIST which we get from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlBXgYj8cMw7",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:14:50.166495Z",
          "iopub.execute_input": "2021-09-23T18:14:50.166822Z",
          "iopub.status.idle": "2021-09-23T18:15:30.186927Z",
          "shell.execute_reply.started": "2021-09-23T18:14:50.166782Z",
          "shell.execute_reply": "2021-09-23T18:15:30.185957Z"
        },
        "trusted": true
      },
      "source": [
        "# Config\n",
        "RANDOM_STATE = 42\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EPOCHS = 100\n",
        "PATIENCE = 5\n",
        "INPUT_SIZE = 784\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Fetch data\n",
        "MNIST = fetch_openml(\"mnist_784\")\n",
        "X = MNIST['data'].reshape(-1, 28, 28)\n",
        "y = MNIST['target'].astype(int)\n",
        "\n",
        "# Create folds\n",
        "cv = model_selection.StratifiedKFold(n_splits=5)\n",
        "trn_, val_ = next(iter(cv.split(X=X, y=y)))\n",
        "\n",
        "# Get train and valid data loaders\n",
        "train_dataset = MNISTDataset(X[trn_, :], y[trn_], transform=transforms.ToTensor())\n",
        "valid_dataset = MNISTDataset(X[val_, :], y[val_], transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjqSuZqpcMw8"
      },
      "source": [
        "### Intermediate values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSFEodb0cMw9"
      },
      "source": [
        "Finally, we set up the `study` instance and its objective function. Note that the search space is dynamically constructed depending on the number of layers (i.e. an earlier suggestion for a hyperparameter). During training, we perform early stopping on validation loss. If no new minimum val. loss is found after 5 epochs, then the minimum val. loss is returned as the objective [^ref3].\n",
        "\n",
        "Computing intermediate values allow us to **prune** unpromising trials to conserve resources. The default pruner in Optuna is [`optuna.pruners.MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html) which prunes a trial if its best intermediate result as of the current step (e.g. current best valid loss) is worse than the median of all intermediate results of previous trials *at the current step*. Hence, the best intermediate result of a pruned trial is less than the best intermediate result of 1/2 of the other trials as of that step. In our case, if the minimum val. loss does not improve too quickly, then the trial is pruned. Of course, the validation loss could descend rapidly at later steps, but the median pruner does not bet on this happening.\n",
        "\n",
        "[^ref3]: In practice, we save the best model parameters at this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDsmzBW_cMw-",
        "execution": {
          "iopub.status.busy": "2021-09-23T18:15:30.188574Z",
          "iopub.execute_input": "2021-09-23T18:15:30.188885Z"
        },
        "trusted": true
      },
      "source": [
        "def define_model(trial):\n",
        "  \n",
        "    # Optimize the # of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    out_features = []\n",
        "    drop_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
        "    for i in range(n_layers):\n",
        "        out_features.append(trial.suggest_int(\"n_units_l{}\".format(i), 4, 128))\n",
        "\n",
        "    return MLPClassifier(INPUT_SIZE, NUM_CLASSES, n_layers, out_features, drop_rate)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "    batch_size = trial.suggest_int('batch_size', 8, 512, log=True)\n",
        "    learning_rate = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.5)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
        "    engine = Engine(model, DEVICE, optimizer)\n",
        "\n",
        "    # Init. dataloaders\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "    \n",
        "    # Run training\n",
        "    best_loss = np.inf\n",
        "    patience = PATIENCE\n",
        "    for epoch in tqdm(range(EPOCHS), total=EPOCHS, leave=False):\n",
        "\n",
        "        # Train and validation step\n",
        "        train_loss = engine.train(train_loader)\n",
        "        valid_loss, valid_acc = engine.eval(valid_loader)\n",
        "\n",
        "        # Reduce learning rate\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(valid_loss)\n",
        "            \n",
        "        # Early stopping\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            patience = PATIENCE\n",
        "        else:\n",
        "            patience -= 1\n",
        "            if patience == 0:\n",
        "                break\n",
        "    \n",
        "        # Pruning unpromising trials\n",
        "        trial.report(valid_loss, step=epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return best_loss\n",
        "\n",
        "# Create and run optimization problem \n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ33X-NacMw8",
        "trusted": true
      },
      "source": [
        "from optuna.trial import TrialState\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials:\\t\", len(study.trials))\n",
        "print(\"  Number of pruned trials:\\t\", len(pruned_trials))\n",
        "print(\"  Number of complete trials:\\t\", len(complete_trials))\n",
        "\n",
        "print(\"\\nBest trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kXDduuNcMw_"
      },
      "source": [
        "Trials below either early stops (gradient descent loses momentum) or gets pruned (unlikely to improve even if gradient descent continues). Note that pruning starts at Trial 5. This can be tweaked in the `n_startup_trials=5` parameter of the pruner. In this case, pruning is disabled until the 5 trials finish in the same study. This is so that the pruner obtains enough information about the behavior of the gradient descent optimizer before starting to prune. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktKfx9tZcMxA",
        "trusted": true
      },
      "source": [
        "optuna.visualization.plot_intermediate_values(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5-JO1htcMxB",
        "trusted": true
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1v_xkn-cMxC"
      },
      "source": [
        "### Hyperparameter interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHlDxIRDfkEO"
      },
      "source": [
        "We look at which combinations of hyperparameters work well from the parallel coordinate plot. Note that there is something weird going on here. For example, trials with `n_layers=1` has coordinates in axes where they should have no values, e.g. `n_units_l1` and `n_units_l2`. This is a known issue for parallel plots, e.g. [#1809](https://github.com/optuna/optuna/issues/1809). Turns out, lines with dynamically constructed parameters with NaNs should be skipped by plotter. Moreover, trials with NaN values are excluded from the parameter importance computation which limits its usefulness. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWisDC0pcMxD",
        "trusted": true
      },
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGTKvWzrYkuj",
        "trusted": true
      },
      "source": [
        "study.trials_dataframe().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnYWhE5cec4Q",
        "trusted": true
      },
      "source": [
        "study.trials_dataframe().query(\"state=='COMPLETE'\").params_n_layers.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkA_kYbvc5eh"
      },
      "source": [
        "Instead, we can look at each subset of trials for different values of `n_layers`. The resulting trials have no NaN parameters since the paramaters are sampled after a value for `n_layers` has been suggested. Looks like `n_layers=1` works best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THs6gM21Ykuj",
        "trusted": true
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Isolate a study for each value of n_layers\n",
        "studies = [optuna.create_study() for j in range(3)]\n",
        "for j in range(3):\n",
        "    studies[j].add_trials([t for t in study.trials if t.params['n_layers'] == j+1])\n",
        "    fig = optuna.visualization.plot_parallel_coordinate(studies[j])\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwToT9Spc5ei"
      },
      "source": [
        "From the following contour plot, we see that a low batch size is generally good, with high values of dropout, learning rate, and weight decay, and only a single hidden layer. From the above parallel plot, a hidden layer of size around 90 looks good. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_p3HH33cMxH",
        "trusted": true
      },
      "source": [
        "fig = optuna.visualization.plot_contour(study, params=['batch_size', 'lr', 'n_layers', 'weight_decay', 'dropout_rate'])\n",
        "fig.update_layout(autosize=False, width=1200, height=1200)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE-8JzvCcMxJ"
      },
      "source": [
        "## Appendix: Hyperparameters of commonly used models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5eopYOBcMxJ"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaEeJGwecMxJ"
      },
      "source": [
        "```{figure} ../img/hyp.png\n",
        "---\n",
        "name: hyp\n",
        "---\n",
        "Table from p. 184 of {cite}`AAAMLP`. **RS**$^*$ implies random search should be better.\n",
        "```"
      ]
    }
  ]
}