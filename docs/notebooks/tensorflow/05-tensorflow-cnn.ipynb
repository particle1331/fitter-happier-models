{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in previous notebooks to classify images we flattened them into long vectors as inputs to MLPs. This is unstatisfying since we are discarding important spatial information, i.e. observe that MLPs are invariant to a permutation of the neurons. In addition to this, a dense layer taking in a 256 x 256 RGB image producing a 256 x 256 x 3 image of the same dimensions would require around 39 billion parameters. This requires too much memory and results in excess capacity for a single layer.\n",
    "\n",
    "It would be nice if we can include our prior knowledge that pixels are spatially related in some way into the structure of our networks. For tasks such as object detection and classification, we can abstract away two desirable properties: **translation invariance** and **locality**. For our purposes, we take \"translation invariance\" to mean that a transformation that is meaningful at a certain location should be also meaningful everywhere. In addition, we want the transformation to be local because since discriminative features for images typically exist only on localized regions, e.g. a dog's nose or cat ears, and looking at large regions of the image can potentially confuse the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look at **convolution** which embody this idea of capturing local effects with a transformation that is somewhat translationally invariant. This is defined for a kernel $\\mathbf K$ and an input image $\\mathbf X$ as\n",
    "\n",
    "$$\n",
    "(\\mathbf X \\circledast \\mathbf K)_{ij} = \\sum_{h = 1}^{k_1} \\sum_{w=1}^{k_2} {\\mathbf K}_{hw}\\, {\\mathbf X}_{i + h, j + w}.\n",
    "$$\n",
    "\n",
    "The kernel $\\mathbf K$ is applied locally on a patch of size $k_1 \\times k_2.$ The figure below show two convolution operations for 1-dimensional signals. Note that depending on the kernel, convolutions can be used to capture patterns (top), and also as differential operators (bottom). The latter can be useful for tasks such as edge detection.\n",
    "\n",
    "\n",
    "```{margin}\n",
    "[[source]](https://fleuret.org/dlc/materials/dlc-handout-4-4-convolutions.pdf)\n",
    "```\n",
    "```{figure} ../../img/conv-effect.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "Convolution for 1-dimensional signals.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural networks, a **convolutional layer** replaces the dense operation with a convolution between the input tensor $\\mathbf X$ and the weights $\\mathbf W$ so that it implements the computation $\\mathbf H = \\varphi( u + \\mathbf X \\circledast \\mathbf W)$ for a nonlinear activation $\\varphi.$  This significantly reduces the size of the weight matrix. Since images have channels, we extend the 2-dimensional convolution layer to having an extra dimension indexed by $c_\\text{out}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "{\\mathbf H}_{ij,\\, c_\\text{out}} \n",
    "&= \\varphi\\left(u_{c_\\text{out}} + \\sum_{h = 0}^{k_1-1} \\sum_{w=0}^{k_2-1} {\\mathbf K}_{hw,\\,{c_\\text{in}},\\,{c_\\text{out}}} \\, {\\mathbf X}_{i + h,\\, j + w,\\, c_\\text{in}} \\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the first two indices for navigating along the spatial dimensions of the input image. This is done for each input channel, so we require a third dimension indexed by $c_{in}.$\n",
    "Finally, we have such 3-dimensional tensors for each output channel, so that our final weight tensor is a 4-dimensional tensor. We can think of this geometrically as having $c_\\text{out}$ filters of shape $(k_1, k_2, c_\\text{in})$ which forms a $(k_1, k_2, c_\\text{in}, c_\\text{out})$ weight tensor. Note that if the input image $\\mathbf X$ has spatial dimensions $H \\times W$, then the resulting image $\\mathbf H$ has spatial dimension $(H - h + 1) \\times (W - w +1).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[[Krizhevsky et. al.]](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)\n",
    "```\n",
    "\n",
    "```{figure} ../../img/kernels_cnn.jpeg\n",
    "---\n",
    "\n",
    "---\n",
    "Kernels learned by the first layer of AlexNet. Each of the 96 kernels shown here is of size 11x11x3,  shared by the 55x55 neurons in each of the 96 output channels. Note that most of these look like edge detectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "\n",
    "from inefficient_networks.config import config\n",
    "config.set_tensorflow_seeds(0)\n",
    "config.set_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistent with the above equation, TensorFlow expects input images to be of shape `(B, H, W, c)` for an batch input of size `B` of `H x W` images with `c` channels. Note that since these layers will be stacked, this is also expected the shape of output of a convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 02:12:44.558733: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-26 02:12:44.559054: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 24, 24, 3)\n",
      "(5, 5, 1, 3)\n",
      "(3,)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.normal(shape=(256, 28, 28, 1))             # (B, H_in, W_in, c_in)\n",
    "conv = kr.layers.Conv2D(filters=3, kernel_size=(5, 5))   # [(5, 5, c_in, c_out), (c_out,)]\n",
    "\n",
    "# Get out image, and check shapes\n",
    "Y = conv(X)\n",
    "K = conv.weights[0]\n",
    "u = conv.weights[1]\n",
    "\n",
    "# Check if implementation follows above formula\n",
    "h, w = 5, 5\n",
    "B, H, W, c = X.shape\n",
    "H_out, W_out, c_out = H-h+1, W-w+1, 3\n",
    "out = np.zeros(shape=(B, H_out, W_out, c_out))\n",
    "for i in range(out.shape[1]):\n",
    "    for j in range(out.shape[2]):\n",
    "        XX = X.numpy()[:, i: i+h, j: j+w, :].reshape(B, -1)\n",
    "        KK = K.numpy().reshape(h*w, -1)\n",
    "        out[:, i, j, :] = u + (XX @ KK)\n",
    "\n",
    "print(Y.shape)   # (B, H_out, W_out, c_out)\n",
    "print(K.shape)   # (h, w, c_in, c_out)\n",
    "print(u.shape)   # (c_out,)\n",
    "print(np.abs(out - conv(X)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the output is 28 - 5  + 1 = 24. Next, we show that an example showing convolution is a **linear operation**. This can be shown directly from the definition, but here we show an actual construction of convolution as matrix multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 21. -27.]\n",
      " [-39.  45.]]\n",
      "\n",
      "[[ 21. -27.]\n",
      " [-39.  45.]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.convert_to_tensor(\n",
    "    [[-1., 2.,-3.],\n",
    "     [ 4.,-5., 6.],\n",
    "     [-7., 8.,-9.],]\n",
    ")[None, :, :, None]\n",
    "\n",
    "K = tf.convert_to_tensor(\n",
    "    [[-1.,  1.],\n",
    "     [ 2., -2.]]\n",
    ")[:, :, None, None]\n",
    "\n",
    "conv_small = kr.layers.Conv2D(filters=1, kernel_size=(2, 2))\n",
    "conv_small.build(input_shape=(256, 3, 3, 1))\n",
    "conv_small.set_weights([K, tf.zeros(shape=(1,))])\n",
    "\n",
    "\n",
    "X_ = np.array([-1., 2., -3., 4., -5., 6., -7., 8., -9.,])\n",
    "K_ = np.array([\n",
    "    [-1., 0., 0., 0.],\n",
    "    [ 1.,-1., 0., 0.],\n",
    "    [ 0., 1., 0., 0.],\n",
    "    [ 2., 0.,-1., 0.],\n",
    "    [-2., 2., 1.,-1.],\n",
    "    [ 0.,-2., 0., 1.],\n",
    "    [ 0., 0., 2., 0.],\n",
    "    [ 0., 0.,-2., 2.],\n",
    "    [ 0., 0., 0.,-2],\n",
    "])\n",
    "\n",
    "print((X_ @ K_).reshape(2, 2))\n",
    "print()\n",
    "print(tf.reshape(conv_small(X), (2, 2)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride and padding\n",
    "\n",
    "The above definition of convolution can be modified to include a parameter $s$ called the **stride** that controls the step size of the kernel when it slides over the input image. A convolution layer with stride $s$ computes:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "{\\mathbf H}_{ij,\\, c_\\text{out}} \n",
    "&= \\varphi\\left(u_{c_\\text{out}} + \\sum_{h = 0}^{k_1-1} \\sum_{w=0}^{k_2-1} {\\mathbf K}_{hw,\\,{c_\\text{in}},\\,{c_\\text{out}}} \\, {\\mathbf X}_{si + h,\\, sj + w,\\, c_\\text{in}} \\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This includes the original definition which has a step size of 1. It would be beneficial to use a larger stride along with a large kernel size if objects are large relative to the dimension of the image. For example, AlexNet {cite}`imagenet-paper` used a kernel of size 11 x 11 with a stride of 4 in the first layer since objects in the [ImageNet dataset](https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/description) tend to occupy more pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/imagenet.jpeg\n",
    "---\n",
    "width: 45em\n",
    "name: imagenet\n",
    "---\n",
    "Sample images from the ImageNet dataset. {cite}`imagenet`\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding.** Observe that convolution as defined above, with the kernel placed entirely within the input image, is biased towards the center pixels resulting in information loss along the borders. Also notice that applying convolutions will always result in decreasing spatial dimension which limits how deep we can make our networks. A simple fix is to simply pad the edges with zero so that only a portion of the kernel is placed over the input image around the edges.\n",
    "\n",
    "\n",
    "```{margin}\n",
    "[[source]](https://github.com/rasbt/machine-learning-book/blob/main/ch14/figures/14_05.png)\n",
    "```\n",
    "```{figure} ../../img/padding.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can implemented in TensorFlow using the `ZeroPadding2D` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 34, 34, 1)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"251.565pt\" height=\"249.119697pt\" viewBox=\"0 0 251.565 249.119697\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-04-26T07:56:16.528797</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 249.119697 \nL 251.565 249.119697 \nL 251.565 0 \nL 0 0 \nL 0 249.119697 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 225.241572 \nL 244.365 225.241572 \nL 244.365 7.801572 \nL 26.925 7.801572 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pab9768f9b0)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"image85ffebb619\" transform=\"scale(1 -1)translate(0 -218)\" x=\"26.925\" y=\"-7.241572\" width=\"218\" height=\"218\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m94b255cda5\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"30.122647\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.941397 239.840009)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"62.099118\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(58.917868 239.840009)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"94.075588\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(87.713088 239.840009)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"126.052059\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(119.689559 239.840009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"158.028529\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(151.666029 239.840009)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"190.005\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(183.6425 239.840009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m94b255cda5\" x=\"221.981471\" y=\"225.241572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 30 -->\n      <g transform=\"translate(215.618971 239.840009)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"mbddd493f64\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"42.975689\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 46.774908)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"74.95216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 78.751379)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"106.928631\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 110.727849)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"138.905101\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 142.70432)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"170.881572\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 174.68079)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mbddd493f64\" x=\"26.925\" y=\"202.858042\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 206.657261)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 225.241572 \nL 26.925 7.801572 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 225.241572 \nL 244.365 7.801572 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 225.241572 \nL 244.365 225.241572 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.801572 \nL 244.365 7.801572 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pab9768f9b0\">\n   <rect x=\"26.925\" y=\"7.801572\" width=\"217.44\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = tf.random.normal(shape=(256, 28, 28, 1))            \n",
    "pad = kr.layers.ZeroPadding2D(padding=3)\n",
    "\n",
    "print(pad(X).shape)\n",
    "plt.imshow(pad(X)[0, :, :, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial dimension of the output is directly influenced by padding `p` and stride `s`. Suppose the layer's input has width `W` and let the kernel have width `f`, then the output image has width `W_out = ⌊(W + 2p - f)/s⌋ + 1` assuming equal padding on both sides. \n",
    "Directly using discrete convolution is not always desirable as some pixels of the input are essentially dropped because a kernel cannot be placed within the image to cover them following the set stride:\n",
    "\n",
    "```bash\n",
    "input    1 2 3 4 5 6 7 8 9\n",
    "kernel   0 0 1 0 0       \n",
    "               0 0 1 0 0\n",
    "         -----------------                     \n",
    "output       3     6     \n",
    "```\n",
    "\n",
    "For odd kernel size `f` and unit stride `s = 1`, we can use `2p = f - 1` to get same sized outputs and with the kernel covering the entire input in a symmetric manner. For this reason, as well as symmetry considerations, we [prefer odd-sized kernels](https://datascience.stackexchange.com/a/23186) for convolutions.\n",
    "\n",
    "```bash\n",
    "input    0 0 1 2 3 4 5 6 7 8 9 0 0\n",
    "kernel   0 0 1 0 0\n",
    "           0 0 1 0 0\n",
    "                  ...\n",
    "                       0 0 1 0 0\n",
    "                         0 0 1 0 0\n",
    "         -------------------------                        \n",
    "output       1 2 3 4 5 6 7 8 9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For strides `s > 1`, best practice is to choose a kernel size `f` and the smallest padding `p` such that `s` divides `W + 2p - f`. This way the entire input image is covered symmetrically by the kernel in constructing the convolved image.\n",
    "\n",
    "```bash\n",
    "input    0 1 2 3 4 5 6 7 8 9 0\n",
    "kernel   0 0 1 0 0\n",
    "               0 0 1 0 0\n",
    "                     0 0 1 0 0\n",
    "         ---------------------                         \n",
    "output       2     5     8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF implementation.** The `padding` argument in `Conv2D` and other convolutional layers takes in either `\"valid\"` or `\"same\"`. The `\"valid\"` setting means that no padding is used an the kernel is placed only where it can be validly placed within the image. As discussed above this can result in discarding some pixels in the right as well as bottom part of the image. The `\"same\"` setting is a bit more tricky. TensorFlow zero pads the image as evenly as possible such that the output image has width `⌈W / s⌉`. So if `⌊(W + 2p - f) / s⌋ + 1 == ⌈W / s⌉`, such as when `s = 1` and `2p = f-1`, then we can use `\"same\"` to implement a symmetric construction of the convolved image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receptive field\n",
    "\n",
    "For any element `h` of a hidden layer, its **receptive field** refers to all the elements from all the previous layers that may affect the calculation of `h` during forward pass. \n",
    "\n",
    "```{margin}\n",
    "[[Lin et. al.]](https://www.researchgate.net/figure/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks_fig4_316950618)\n",
    "```\n",
    "```{figure} ../../img/receptive_field.png\n",
    "---\n",
    "width: 18em\n",
    "---\n",
    "Receptive field of a pixel in the third layer.\n",
    "```\n",
    "\n",
    "In particular, elements of the final classification layer should have a receptive field that contains the whole input image in the input layer. Otherwise, some parts of the input data will not improve the performance of the model for that class. Ideally, large receptive fields are desirable, e.g. exponentially increasing with depth, since this should result in a network that minimizes information loss from its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "One way to increase receptive field is by downsampling, i.e. reducing the spatial dimensions of the output by means of some method of sampling a subset or aggregating the previous values. This can be achieved by a **pooling** operation. \n",
    "A pooling layer operates like a convolutional layer in that we can set a stride, padding, and kernel size. But unlike the convolution operation, pooling is non-parameteric. \n",
    "\n",
    "For example, we will be using **max-pooling** frequently which takes the maximum value in the region that it covers, hence does not require learning parameters. One effect of max pooling is that it provides invariance to small translations of the input at the cost of some information loss (which may be good for the network). Note that max-pooling works well with the ReLU activation so all values that are compared have the same sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 9],\n",
       "       [4, 8]], dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.convert_to_tensor([\n",
    "    [ 1, 1, 2, 4],\n",
    "    [ 4, 5, 6, 9],\n",
    "    [ 3, 1, 0, 3],\n",
    "    [ 4, 0, 1, 8]]\n",
    ")[None, :, :, None]\n",
    "\n",
    "pool = kr.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "pool(X).numpy().reshape(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pooling is applied to each channel separately, and the number of output channels is maintained. This makes sense since we want only to compress the original input without affecting its semantic structure. \n",
    "In practice, there are only two commonly used settings: overlapping pooling with `k=3` and `s=2` which results in little information loss, and more commonly `k=2` and `s=2` so that the pooling regions are nonoverlapping. Note that larger kernel sizes can be too aggressive. An alternative to pooling is to use non-overlapping convolution. This can be thought of as a pooling operation with trainable parameters for a weighted combination of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Keras sequential API, let us implement the following convolutional network for classifying MNIST:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[[source]](https://github.com/rasbt/machine-learning-book/blob/main/ch14/figures/14_12.png)\n",
    "```\n",
    "```{figure} ../../img/convnet.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_68 (Conv2D)          (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              3212288   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = kr.Sequential()\n",
    "model.add(kr.layers.Conv2D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(kr.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(1024, activation='relu'))\n",
    "model.add(kr.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 04:40:52.053785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  70/1875 [>.............................] - ETA: 27s - loss: 0.6238 - accuracy: 0.8094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=11'>12</a>\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=12'>13</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=13'>14</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=16'>17</a>\u001b[0m \u001b[39m# Fit model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=18'>19</a>\u001b[0m     x_train, y_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=19'>20</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=20'>21</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(x_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/particle1331/code/inefficient-networks/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb#ch0000084?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py?line=1386'>1387</a>\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py?line=1387'>1388</a>\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py?line=1388'>1389</a>\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py?line=1389'>1390</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/engine/training.py?line=1390'>1391</a>\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=430'>431</a>\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=431'>432</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=432'>433</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=433'>434</a>\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=434'>435</a>\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=435'>436</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=436'>437</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=437'>438</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=294'>295</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=295'>296</a>\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=296'>297</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=297'>298</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=298'>299</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=299'>300</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=314'>315</a>\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=315'>316</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=317'>318</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=319'>320</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=320'>321</a>\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=353'>354</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=354'>355</a>\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=355'>356</a>\u001b[0m   hook(batch, logs)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=358'>359</a>\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1032'>1033</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1033'>1034</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1101'>1102</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1103'>1104</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1104'>1105</a>\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1105'>1106</a>\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/callbacks.py?line=1106'>1107</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=559'>560</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=560'>561</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=562'>563</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=553'>554</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=554'>555</a>\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=555'>556</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=556'>557</a>\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=557'>558</a>\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/keras/utils/tf_utils.py?line=558'>559</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1199'>1200</a>\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1200'>1201</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1201'>1202</a>\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1219'>1220</a>\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1220'>1221</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1221'>1222</a>\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1222'>1223</a>\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1223'>1224</a>\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1186'>1187</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1187'>1188</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1188'>1189</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1189'>1190</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=1190'>1191</a>\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Compile model with RMSProp and CE loss\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=5, \n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 (ml)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
