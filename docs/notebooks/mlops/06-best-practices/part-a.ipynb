{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Engineering Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=brightgreen)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/inefficient-networks/blob/master/docs/notebooks/mlops/04-deployment)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/inefficient-networks?style=social)](https://github.com/particle1331/inefficient-networks)\n",
    "\n",
    "```text\n",
    "ùóîùòÅùòÅùóøùó∂ùóØùòÇùòÅùó∂ùóºùóª: Notes for Module 6 of the MLOps Zoomcamp (2022) by DataTalks.Club.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will cover best practices for developing and deploying our code. We will take our example [streaming code](https://particle1331.github.io/inefficient-networks/notebooks/mlops/04-deployment/notes.html#streaming-deploying-models-with-kinesis-and-lambda) from a previous module, break it down into testable units, and generally just improve it with software engineering best practices. \n",
    "\n",
    "More precisely, we create and automate unit and integration testing, code quality checks, and add pre-commit hooks for all of these. We will also look at how to use `make` which is a nice tools for abstracting and automating repetitive but involved tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Python code with pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the [streaming module](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment/streaming/lambda_function.py) that we will work on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Load environmental variables\n",
    "PREDICTIONS_STREAM_NAME = os.getenv('PREDICTIONS_STREAM_NAME', 'ride_predictions')\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "TEST_RUN = os.getenv('TEST_RUN', 'False') == 'True'\n",
    "\n",
    "# Load model from S3\n",
    "logged_model = f's3://mlflow-models-ron/1/{RUN_ID}/artifacts/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "\n",
    "\n",
    "def predict(features):\n",
    "    pred = model.predict(features)\n",
    "    return float(pred[0])\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    predictions_events = []\n",
    "    \n",
    "    for record in event['Records']:\n",
    "        encoded_data = record['kinesis']['data']\n",
    "        decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "        ride_event = json.loads(decoded_data)\n",
    "\n",
    "        ride = ride_event['ride']\n",
    "        ride_id = ride_event['ride_id']\n",
    "    \n",
    "        features = prepare_features(ride)\n",
    "        prediction = predict(features)\n",
    "    \n",
    "        prediction_event = {\n",
    "            'model': 'ride_duration_prediction_model',\n",
    "            'version': '123',\n",
    "            'prediction': {\n",
    "                'ride_duration': prediction,\n",
    "                'ride_id': ride_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if not TEST_RUN:\n",
    "            kinesis_client = boto3.client('kinesis')\n",
    "            kinesis_client.put_record(\n",
    "                StreamName=PREDICTIONS_STREAM_NAME,\n",
    "                Data=json.dumps(prediction_event),\n",
    "                PartitionKey=str(ride_id)\n",
    "            )\n",
    "        \n",
    "        predictions_events.append(prediction_event)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions_events\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review, first this script loads the environmental variables and the model from S3. Then, it defines two helper functions for preprocessing and making prediction with the model. The most important function in this script is `lambda_handler` which takes in an `event` which contains a batch of events from the input stream. This explains the outer loop over `event['Records']`. \n",
    "\n",
    "Inside this block, the data is decoded and a prediction is made which is packaged as an event for the output stream. If this function is in production, i.e. outside of a test run, then the prediction event is written on the output stream. In this case, a Kinesis client is instantiated, and an output event is written to the specific predictions stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a `tests/` folder where we will put all our tests. We will be using `pipenv` to manage our environment. See the [previous module](https://particle1331.github.io/inefficient-networks/notebooks/mlops/04-deployment/notes.html#setting-up-the-environment-with-pipenv) for details. We will start with the following Pipfile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ini\n",
    "[[source]]\n",
    "url = \"https://pypi.org/simple\"\n",
    "verify_ssl = true\n",
    "name = \"pypi\"\n",
    "\n",
    "[packages]\n",
    "boto3 = \"*\"\n",
    "mlflow = \"*\"\n",
    "scikit-learn = \"==1.0.2\"\n",
    "\n",
    "[dev-packages]\n",
    "pytest = \"*\"\n",
    "\n",
    "[requires]\n",
    "python_version = \"3.9\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this installs [pytest](https://docs.pytest.org/en/7.1.x/) as a dev dependency. Let us create one test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "import lambda_function\n",
    "\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 130,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 3.66\n",
    "    }\n",
    "\n",
    "    actual_features = lambda_function.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '130_205',\n",
    "        'trip_distance': 3.66,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this, since this test is not related to the model, we can comment out the block that loads the model from S3 to make this test run faster. Tests can be run either by doing `$ pytest` on the terminal:\n",
    "\n",
    "```bash\n",
    "$ pytest\n",
    "======================== test session starts ========================\n",
    "platform darwin -- Python 3.9.12, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: /Users/particle1331/code/inefficient-networks/docs/notebooks/mlops/06-best-practices\n",
    "plugins: anyio-3.6.1\n",
    "collected 1 item\n",
    "\n",
    "tests/model_test.py .                                         [100%]\n",
    "\n",
    "========================= 1 passed in 1.03s =========================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using the UI in VS Code after selecting pytest in the configuration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/vscode-testing.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "Testing interface in VS Code. Really convenient for running and visualizing tests.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we should always try is to deliberately **break** the tests. This makes sure that tests cover the changes being made. For example, we may forget adding `assert` statements which means the test are passed trivially.\n",
    "\n",
    "Notice that unit tests act as invariants that must remain true even if particular implementation details around them changes. This is nice since the tests make sure that the important parts of the code are functioning even if we change or refactor things around it. And also allows fast iteration, we know that we are not making breaking changes to the code. In its extreme form, this practice is called [test-driven development](https://en.wikipedia.org/wiki/Test-driven_development) (TDD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring the lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had to manually comment out things in our tests. This is not really great. Also, it would fail if our dev environment cannot connect to S3. A way to fix this is to create a special class which we can call `Model` containing all the logic of the original function, but with parts that are easier to test.\n",
    "\n",
    "\n",
    "For this we modify `lambda_function.py` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# lambda_function.py\n",
    "import model\n",
    "import os\n",
    "\n",
    "# Load environmental variables\n",
    "PREDICTIONS_STREAM_NAME = os.getenv('PREDICTIONS_STREAM_NAME', 'ride_predictions')\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "TEST_RUN = os.getenv('TEST_RUN', 'False') == 'True'\n",
    "\n",
    "\n",
    "model_service = model.init(\n",
    "    predictions_stream_name=PREDICTIONS_STREAM_NAME,\n",
    "    run_id=RUN_ID,\n",
    "    test_run=TEST_RUN\n",
    ")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    return model_service.lambda_handler(event)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `predictions_stream_name` is specified as the stream where the function writes to. The stream where the function reads from need not be specified since this is configured in AWS Lambda. Then, we need to specify `run_id` to determine the model in S3 to use. Finally, `test_run` is simply a flag to indicate that we are in development mode (i.e. so we don't write on the output stream which may be already deployed during the development of this code). These are variables that are configured when the Docker container is run.\n",
    "\n",
    "All of these variables determine a prediction service called `model_service` which abstracts away the process of predicting on an event. In particular, this means that we don't test directly on the actual `lambda_function` that is exposed by the container. (Although, we will see later that this is still covered with integration tests, since these make sure that everything is working together.) This is implemented in the following class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def load_model(run_id: str):\n",
    "    logged_model = f's3://mlflow-models-ron/1/{run_id}/artifacts/model'\n",
    "    model =  mlflow.pyfunc.load_model(logged_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def base64_decode(encoded_data):\n",
    "    decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "    ride_event = json.loads(decoded_data)\n",
    "    return ride_event\n",
    "\n",
    "\n",
    "class ModelService:\n",
    "\n",
    "    def __init__(self, model, model_version):\n",
    "        self.model = model\n",
    "        self.model_version = model_version\n",
    "\n",
    "    def prepare_features(self, ride):\n",
    "        features = {}\n",
    "        features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "        features['trip_distance'] = ride['trip_distance']\n",
    "        return features\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred = self.model.predict(features)\n",
    "        return float(pred[0])\n",
    "\n",
    "\n",
    "    def lambda_handler(self, event):\n",
    "    \n",
    "        predictions_events = []\n",
    "        \n",
    "        for record in event['Records']:\n",
    "            encoded_data = record['kinesis']['data']\n",
    "            ride_event = base64_decode(encoded_data)\n",
    "\n",
    "            ride = ride_event['ride']\n",
    "            ride_id = ride_event['ride_id']\n",
    "        \n",
    "            features = self.prepare_features(ride)\n",
    "            prediction = self.predict(features)\n",
    "        \n",
    "            prediction_event = {\n",
    "                'model': 'ride_duration_prediction_model',\n",
    "                'version': self.model_version,\n",
    "                'prediction': {\n",
    "                    'ride_duration': prediction,\n",
    "                    'ride_id': ride_id\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # if not TEST_RUN:\n",
    "            #     kinesis_client = boto3.client('kinesis')\n",
    "            #     kinesis_client.put_record(\n",
    "            #         StreamName=PREDICTIONS_STREAM_NAME,\n",
    "            #         Data=json.dumps(prediction_event),\n",
    "            #         PartitionKey=str(ride_id)\n",
    "            #     )\n",
    "            \n",
    "            predictions_events.append(prediction_event)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'predictions': predictions_events\n",
    "        }\n",
    "\n",
    "\n",
    "def init(predictions_stream_name: str, run_id: str, test_run: bool):\n",
    "    model = load_model(run_id)\n",
    "    model_service = ModelService(model=model, model_version=run_id)\n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attributes of the class are informed by the methods that we collect inside of it. For example, we also version the models with `run_id`, hence the `model_version` attribute. This information is packaged along with the prediction. Also notice that the functionality for writing outputs is commented out. For now, we focus on getting correct predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the unit tests should fail now after refactoring. Modifying the code so that it uses the `ModelService` class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 130,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 3.66\n",
    "    }\n",
    "\n",
    "    model_service = model.ModelService(model=None, model_version=None)\n",
    "    \n",
    "    actual_features = model_service.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '130_205',\n",
    "        'trip_distance': 3.66,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more tests on units of functionalities. For example, we can test the decoding base 64 inputs.\n",
    "\n",
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "def test_base64_decode():\n",
    "\n",
    "    base64_input = \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\"\n",
    "    \n",
    "    actual_result = model.base64_decode(base64_input)\n",
    "    \n",
    "    expected_result = {\n",
    "        \"ride\": {\n",
    "            \"PULocationID\": 130,\n",
    "            \"DOLocationID\": 205,\n",
    "            \"trip_distance\": 3.66\n",
    "        }, \n",
    "        \"ride_id\": 123\n",
    "    }\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we are setting `model=None` since this functionality does not use any model. Now, we want to test predict so we want to have a model to test with. We don't really want to connect to S3 in our dev environment, i.e. we don't want to bother with things like credentials, or delays when downloading the model. Or the S3 bucket might not be up yet. So we will create a **mock model** which mimics all relevant attributes and methods of real models for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "class ModelMock:\n",
    "    def __init__(self, value):\n",
    "        self.value = value \n",
    "\n",
    "    def predict(self, X):\n",
    "        n = len(X)\n",
    "        return [self.value] * n\n",
    "\n",
    "\n",
    "def test_predict():\n",
    "    \n",
    "    features = {\n",
    "        'PU_DO': '130_205',\n",
    "        'trip_distance': 3.66,\n",
    "    }\n",
    "\n",
    "    model_mock = ModelMock(value=10.0)\n",
    "    model_service = model.ModelService(model=model_mock, model_version=None)\n",
    "\n",
    "    actual_result = model_service.predict(features)\n",
    "    expected_result = 10.0\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to test the `ModelService.lambda_handler` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "def test_lambda_handler():\n",
    "    \n",
    "    event = {\n",
    "        \"Records\": [\n",
    "            {\n",
    "                \"kinesis\": {\n",
    "                    \"data\": \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    model_mock = ModelMock(value=10.0)\n",
    "    model_service = model.ModelService(model=model_mock, model_version=\"Test123\")\n",
    "\n",
    "    actual_result = model_service.lambda_handler(event)\n",
    "    expected_result = {\n",
    "        'predictions': [\n",
    "            {\n",
    "                'model': 'ride_duration_prediction_model', \n",
    "                'version': 'Test123', \n",
    "                'prediction': {\n",
    "                    'ride_duration': 10.0,\n",
    "                    'ride_id': 123\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We covered pretty much everything except the writing on the output stream. Note that this part of the `lambda_handler` code seems out of place. All other functionalities are geared towards prediction and now, if we include writing on an output stream, the model service has to know about the Kinesis client, the stream name, etc.\n",
    "\n",
    "Instead, what we can do is define a separate unit that handles what happens **after** the prediction is done, i.e. a **callback** on prediction events. This is called every time the model service completes a prediction. Putting something on the Kinesis stream would be one of the callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "class ModelService:\n",
    "\n",
    "    def __init__(self, model, model_version, callbacks=None):\n",
    "        self.model = model\n",
    "        self.model_version = model_version\n",
    "        self.callbacks = callbacks or []\n",
    "\n",
    "    ...\n",
    "\n",
    "    def lambda_handler(self, event):\n",
    "    \n",
    "        predictions_events = []\n",
    "        \n",
    "        for record in event['Records']:\n",
    "            \n",
    "            ...\n",
    "        \n",
    "            prediction_event = {\n",
    "                'model': 'ride_duration_prediction_model',\n",
    "                'version': self.model_version,\n",
    "                'prediction': {\n",
    "                    'ride_duration': prediction,\n",
    "                    'ride_id': ride_id\n",
    "                }\n",
    "            }\n",
    "\n",
    "            for callback in self.callbacks:     # !\n",
    "                callback(prediction_event)\n",
    "            \n",
    "            predictions_events.append(prediction_event)\n",
    "\n",
    "        return {\n",
    "            'predictions': predictions_events\n",
    "        }\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that callbacks act on prediction events, e.g. writes them to Kinesis streams. Below we modify the `init` function to include the Kinesis callback which we package into a class since we need a callable. Here we simply pass a reference to the `put_record` method which acts on prediction events in the `callbacks` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "class KinesisCallback:\n",
    "    \n",
    "    def __init__(self, kinesis_client, predictions_stream_name):\n",
    "        self.kinesis_client = kinesis_client\n",
    "        self.predictions_stream_name = predictions_stream_name\n",
    "\n",
    "    def put_record(self, prediction_event):\n",
    "        ride_id = prediction_event['prediction']['ride_id']\n",
    "        self.kinesis_client.put_record(\n",
    "            StreamName=self.predictions_stream_name,\n",
    "            Data=json.dumps(prediction_event),\n",
    "            PartitionKey=str(ride_id)\n",
    "        )\n",
    "\n",
    "\n",
    "def init(predictions_stream_name: str, run_id: str, test_run: bool):\n",
    "    \"\"\"Initialize model_service for lambda_function module.\"\"\"\n",
    "\n",
    "    model = load_model(run_id)\n",
    "    callbacks = []\n",
    "    \n",
    "    if not test_run:\n",
    "        kinesis_client = boto3.client('kinesis')\n",
    "        kinesis_callback = KinesisCallback(kinesis_client, predictions_stream_name)\n",
    "        callbacks.append(kinesis_callback.put_record)\n",
    "\n",
    "    model_service = ModelService(model=model, model_version=run_id, callbacks=callbacks)\n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks really really nice. We will test this later with a local cloud setup! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here for the [finished code](https://github.com/particle1331/inefficient-networks/tree/2a5cad64632e098cc305bfe0dfb8bd1242135939/docs/notebooks/mlops/06-best-practices/code) for this section. Final directory structure at the end should look like:\n",
    "\n",
    "```text\n",
    ".\n",
    "‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îú‚îÄ‚îÄ Pipfile\n",
    "‚îú‚îÄ‚îÄ Pipfile.lock\n",
    "‚îú‚îÄ‚îÄ lambda_function.py\n",
    "‚îú‚îÄ‚îÄ model.py\n",
    "‚îî‚îÄ‚îÄ tests\n",
    "    ‚îú‚îÄ‚îÄ __init__.py\n",
    "    ‚îî‚îÄ‚îÄ model_test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we refactored our original code for our lambda function and created tests. But these tests are quite limited. They only test only functions. They don't test that the entire thing still works. Recall that we have `test_docker.py` which sort of checks that predictions still work for the container as a whole. At this point, we can build and run the container to make sure that this code still works as a whole. \n",
    "\n",
    "**Remark.** Note that in practice the following test should be done along with writing the unit tests, or after refactoring, so that no drastic change is done without making sure everything still are integrated well. But here we separate the two processes for the sake of presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM public.ecr.aws/lambda/python:3.9\n",
    "\n",
    "RUN pip install -U pip\n",
    "RUN pip install pipenv\n",
    "\n",
    "COPY [ \"Pipfile\", \"Pipfile.lock\", \"./\" ]\n",
    "\n",
    "RUN pipenv install --system --deploy\n",
    "\n",
    "COPY [ \"lambda_function.py\", \"model.py\", \"./\" ]\n",
    "\n",
    "CMD [ \"lambda_function.lambda_handler\" ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker build -t stream-model-duration:v2 .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[+] Building 1.2s (11/11) FINISHED\n",
    " => [internal] load build definition from Dockerfile            0.0s\n",
    " => => transferring dockerfile: 37B                             0.0s\n",
    " => [internal] load .dockerignore                               0.0s\n",
    " => => transferring context: 2B                                 0.0s\n",
    " => [internal] load metadata for public.ecr.aws/lambda/python:  1.0s\n",
    " => [1/6] FROM public.ecr.aws/lambda/python:3.9@sha256:3dda276  0.0s\n",
    " => [internal] load build context                               0.0s\n",
    " => => transferring context: 2.64kB                             0.0s\n",
    " => CACHED [2/6] RUN pip install -U pip                         0.0s\n",
    " => CACHED [3/6] RUN pip install pipenv                         0.0s\n",
    " => CACHED [4/6] COPY [ Pipfile, Pipfile.lock, ./ ]             0.0s\n",
    " => CACHED [5/6] RUN pipenv install --system --deploy           0.0s\n",
    " => [6/6] COPY [ lambda_function.py, model.py, ./ ]             0.0s\n",
    " => exporting to image                                          0.0s\n",
    " => => exporting layers                                         0.0s\n",
    " => => writing image sha256:26e91ec8b6a57ba80437dc8ee278c92dfd  0.0s\n",
    " => => naming to docker.io/library/stream-model-duration:v2     0.0s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -it --rm -p 8080:8080 --env-file .env stream-model-duration:v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "24 Jul 2022 02:31:10,656 [INFO] (rapid) exec '/var/runtime/bootstrap' (cwd=/var/task, handler=)\n",
    "24 Jul 2022 02:31:14,705 [INFO] (rapid) extensionsDisabledByLayer(/opt/disable-extensions-jwigqn8j) -> stat /opt/disable-extensions-jwigqn8j: no such file or directory\n",
    "24 Jul 2022 02:31:14,707 [WARNING] (rapid) Cannot list external agents error=open /opt/extensions: no such file or directory\n",
    "START RequestId: aa21ad77-9ae1-49bc-a7d2-a7bfa3e42266 Version: $LATEST\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this uses a `.env` file for defining environmental variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# .env\n",
    "RUN_ID=f4e2242a53a3410d89c061d1958ae70a\n",
    "TEST_RUN=True\n",
    "PREDICTIONS_STREAM_NAME=ride_predictions\n",
    "\n",
    "AWS_ACCESS_KEY_ID=AKIATQLTRYVSVQ6EWDLI\n",
    "AWS_SECRET_ACCESS_KEY=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\n",
    "AWS_DEFAULT_REGION=us-east-1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing prediction using the following script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# test_docker.py\n",
    "import requests\n",
    "\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"kinesis\": {\n",
    "                \"kinesisSchemaVersion\": \"1.0\",\n",
    "                \"partitionKey\": \"1\",\n",
    "                \"sequenceNumber\": \"49630706038424016596026506533782471779140474214180454402\",\n",
    "                \"data\": \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\",\n",
    "                \"approximateArrivalTimestamp\": 1655944485.718\n",
    "            },\n",
    "            \"eventSource\": \"aws:kinesis\",\n",
    "            \"eventVersion\": \"1.0\",\n",
    "            \"eventID\": \"shardId-000000000000:49630706038424016596026506533782471779140474214180454402\",\n",
    "            \"eventName\": \"aws:kinesis:record\",\n",
    "            \"invokeIdentityArn\": \"arn:aws:iam::241297376613:role/lambda-kinesis-role\",\n",
    "            \"awsRegion\": \"us-east-1\",\n",
    "            \"eventSourceARN\": \"arn:aws:kinesis:us-east-1:241297376613:stream/ride_events\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    url = 'http://localhost:8080/2015-03-31/functions/function/invocations'\n",
    "    response = requests.post(url, json=event)\n",
    "    print(response.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `python test_docker.py` on the terminal. Looks like the lambda function is still working inside the container. That is, it can do download the model from S3, decode the input data, and make a prediction that is exposed in the lambda container. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pipenv run python test_docker.py\n",
    "{\n",
    "    'predictions': [\n",
    "        {\n",
    "            'model': 'ride_duration_prediction_model', \n",
    "            'version': 'f4e2242a53a3410d89c061d1958ae70a', \n",
    "            'prediction': {\n",
    "                'ride_duration': 18.210770674183355, \n",
    "                'ride_id': 123\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this isn't yet a proper test, i.e. we just printed something and checked the print if it looked correct. In the next section, we change this into something that can be automated with `pytest`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepdiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better process differences in JSON outputs, we install a dev dependency called [DeepDiff](https://deepdiff.readthedocs.io/en/latest/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pipenv install --dev deepdiff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
