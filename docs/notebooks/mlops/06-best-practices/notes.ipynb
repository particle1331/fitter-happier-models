{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=brightgreen)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/inefficient-networks/blob/master/docs/notebooks/mlops/04-deployment)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/inefficient-networks?style=social)](https://github.com/particle1331/inefficient-networks)\n",
    "\n",
    "```text\n",
    "ùóîùòÅùòÅùóøùó∂ùóØùòÇùòÅùó∂ùóºùóª: Notes for Module 6 of the MLOps Zoomcamp (2022) by DataTalks.Club.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look at lambda function code\n",
    "- write unit tests, integration tests\n",
    "- in general, just work on code to make it better from an engineering pov\n",
    "\n",
    "\n",
    "- copy all code from chapter 4.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. Get pipfile, install pipfile.\n",
    "2. Install pytest.\n",
    "3. write 1 test `model_test.py`\n",
    "4. improve our code.\n",
    "5. now we want to test lambda_function, but has too much crap on it giving errors\n",
    "6. define model.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "‚ùØ pytest\n",
    "====================================================== test session starts =======================================================\n",
    "platform darwin -- Python 3.9.12, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: /Users/particle1331/code/inefficient-networks/docs/notebooks/mlops/06-best-practices\n",
    "plugins: anyio-3.6.1\n",
    "collected 0 items\n",
    "\n",
    "===================================================== no tests ran in 0.01s ======================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial version. Focus on prediction. No writing on stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import model\n",
    "\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "\n",
    "model_service = model.init(run_id=RUN_ID)\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # pylint: disable=unused-argument\n",
    "    return model_service.lambda_handler(event)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import mlflow\n",
    "import base64\n",
    "\n",
    "\n",
    "def load_model(run_id):\n",
    "    model_path = f's3://mlflow-models-ron/1/{run_id}/artifacts/model'\n",
    "    model = mlflow.pyfunc.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def base64_decode(encoded_data):\n",
    "    decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "    ride_event = json.loads(decoded_data)\n",
    "    return ride_event\n",
    "\n",
    "\n",
    "class ModelService:\n",
    "\n",
    "    def __init__(self, model, model_version=None):\n",
    "        self.model = model\n",
    "        self.model_version = model_version\n",
    "\n",
    "    def prepare_features(self, ride):\n",
    "        features = {}\n",
    "        features['PU_DO'] = f\"{ride['PULocationID']}_{ride['DOLocationID']}\"\n",
    "        features['trip_distance'] = ride['trip_distance']\n",
    "        return features\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred = self.model.predict(features)\n",
    "        return float(pred[0])\n",
    "\n",
    "    def lambda_handler(self, event):\n",
    "        \"\"\"Predict on batch of input events.\"\"\"\n",
    "\n",
    "        predictions_events = []\n",
    "\n",
    "        for record in event['Records']:\n",
    "\n",
    "            # Decode data from input kinesis stream\n",
    "            encoded_data = record['kinesis']['data']\n",
    "            ride_event = base64_decode(encoded_data)\n",
    "\n",
    "            # Pickout id to match input to output\n",
    "            ride = ride_event['ride']\n",
    "            ride_id = ride_event['ride_id']\n",
    "\n",
    "            # Make predictions using model\n",
    "            features = self.prepare_features(ride)\n",
    "            prediction = self.predict(features)\n",
    "\n",
    "            # Package prediction event for output stream\n",
    "            prediction_event = {\n",
    "                'model': 'ride_duration_prediction_model',\n",
    "                'version': self.model_version,\n",
    "                'prediction': {'ride_duration': prediction, 'ride_id': ride_id},\n",
    "            }\n",
    "\n",
    "            predictions_events.append(prediction_event)\n",
    "\n",
    "        return {'predictions': predictions_events}\n",
    "\n",
    "\n",
    "def init(run_id: str):\n",
    "    \"\"\"Initialize model service.\"\"\"\n",
    "\n",
    "    model = load_model(run_id)\n",
    "    model_service = ModelService(model=model, model_version=run_id)\n",
    "\n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker build -t stream-model-duration:v2 .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker run -it --rm -p 8080:8080 --env-file .env stream-model-duration:v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python test_docker.py to check if still working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test base64 decode\n",
    "test prepare_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from model import ModelService\n",
    "from model import base64_decode\n",
    "\n",
    "\n",
    "def test_base64_decode():\n",
    "    base64_input = \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\"\n",
    "\n",
    "    actual_result = base64_decode(base64_input)\n",
    "    expected_result = {\n",
    "        \"ride\": {\n",
    "            \"PULocationID\": 130,\n",
    "            \"DOLocationID\": 205,\n",
    "            \"trip_distance\": 3.66,\n",
    "        },\n",
    "        \"ride_id\": 123,\n",
    "    }\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 140,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 2.05\n",
    "    }\n",
    "\n",
    "    model_service = ModelService(model=None)\n",
    "\n",
    "    actual_features = model_service.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '140_205',\n",
    "        'trip_distance': 2.05,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
