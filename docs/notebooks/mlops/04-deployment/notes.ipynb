{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will look into deploying the ride duration model which has been our working example in the modules. Deploying means that other applications can get predictions from our model. We will look at three modes of deployment: **online** deployment, **offline** or batch deployment, and **streaming**. \n",
    "\n",
    "In online mode, our service must be up all the time. To do this, we implement a web service which takes in HTTP requests and sends out predictions. In offline or mode, we have a service running regularly, but not necessarily all the time. This can make predictions for a batch of examples that runs periodically using workflow orchestration. Finally, we look at how to implement a streaming service, i.e. a machine learning service that listens to a stream of events and reacts to it using AWS Kinesis and AWS Lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "⚠️ **Attribution:** These are notes for [Module 4: Model Deployment](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment) of the [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp). The MLOps Zoomcamp is a free course from [DataTalks.Club](https://github.com/DataTalksClub).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying models with Flask and Docker\n",
    "\n",
    "In this section, we develop a web server using Flask for serving model predictions. The model is obtained from an S3 artifacts store and predicts on data sent to the service by the backend. We will containerize this application using Docker. This container can be deployed anywhere where Docker is supported such as Kubernetes and Elastic Beanstalk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will package code for model prediction that will be used by the Flask application. This can also be used for offline model training or batch scoring. The directory structure of our project would look like:\n",
    "\n",
    "```\n",
    "deployment/\n",
    "├── app/\n",
    "│   └── main.py\n",
    "├── ride_duration/\n",
    "│   ├── __init__.py\n",
    "│   ├── predict.py\n",
    "│   ├── utils.py\n",
    "│   └── VERSION\n",
    "├── Dockerfile\n",
    "├── Pipfile\n",
    "├── MANIFEST.in\n",
    "├── Pipfile.lock\n",
    "├── setup.py\n",
    "├── test.py\n",
    "├── train.py\n",
    "└── pyproject.toml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create [`setup.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/setup.py) and [`pyproject.toml`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/pyproject.toml) for packaging. Refer to the links to see the complete code. For `setup.py` you only have to change the package metadata (or just leave them blank) and set `install_requires` to `[]`. This list will be later filled using a tool that integrates with Pipenv which we will use for package management.\n",
    "\n",
    "```{margin}\n",
    "[`setup.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/setup.py)\n",
    "```\n",
    "```python\n",
    "from pathlib import Path\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "\n",
    "# Package meta-data.\n",
    "NAME = \"ride-duration-prediction\"\n",
    "DESCRIPTION = \"\"\n",
    "URL = \"\"\n",
    "EMAIL = \"\"\n",
    "AUTHOR = \"\"\n",
    "REQUIRES_PYTHON = \">=3.9.0\"\n",
    "\n",
    "\n",
    "# The rest you shouldn't have to touch too much. Except for install_requires=[]. \n",
    "# Perhaps also the License and Trove Classifiers if publishing to PyPI (public).\n",
    "...\n",
    "\n",
    "setup(\n",
    "    ...\n",
    "    install_requires=[],             \n",
    "    ...\n",
    "    license=\"MIT\",\n",
    "    classifiers=[\n",
    "        # Trove classifiers\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Programming Language :: Python :: 3.9\",\n",
    "        \"Programming Language :: Python :: Implementation :: CPython\",\n",
    "        \"Programming Language :: Python :: Implementation :: PyPy\",\n",
    "    ],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can include [`MANIFEST.in`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/MANIFEST.in) file to specify the files included in the source distribution of the package. The full list can be viewed in the `SOURCES.txt` file of the generated `egg-info` folder after building the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`MANIFEST.in`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/MANIFEST.in)\n",
    "```\n",
    "```\n",
    "include ride_duration/*.py\n",
    "include ride_duration/VERSION\n",
    "\n",
    "recursive-exclude * __pycache__\n",
    "recursive-exclude * *.py[co]\n",
    "\n",
    "exclude Dockerfile\n",
    "exclude Pipfile\n",
    "exclude Pipfile.lock\n",
    "exclude *.py\n",
    "exclude app/*\n",
    "exclude data/*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage our projects package dependencies, we will use [Pipenv](https://pipenv.pypa.io/en/latest/). Notice that we get `Pipfile` which supersedes the usual requirements file, and also a `Pipfile.lock` containing hashes of downloaded packages that ensure reproducible builds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pipenv install scikit-learn==1.0.2 flask pandas mlflow boto3 --python=3.9\n",
    "pipenv install --dev requests\n",
    "pipenv install --dev pipenv-setup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we install the model package. Here we use `pipenv-setup sync` to update `install_requires` in the `setup` script according to the packages installed using Pipenv. This makes sure there are no dependency conflicts when using the package.\n",
    "\n",
    "```bash\n",
    "pipenv-setup sync\n",
    "pipenv install -e .\n",
    "```\n",
    "\n",
    "Our `Pipfile` should now look like the following. Note that `ride-duration-prediction` is installed in editable mode which makes sense since the underlying code is still in development. \n",
    "\n",
    "```{margin}\n",
    "[`Pipfile`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/Pipfile)\n",
    "```\n",
    "```ini\n",
    "[[source]]\n",
    "url = \"https://pypi.org/simple\"\n",
    "verify_ssl = true\n",
    "name = \"pypi\"\n",
    "\n",
    "[packages]\n",
    "scikit-learn = \"==1.0.2\"\n",
    "flask = \"*\"\n",
    "pandas = \"*\"\n",
    "mlflow = \"*\"\n",
    "boto3 = \"*\"\n",
    "ride-duration-prediction = {editable = true, path = \".\"}\n",
    "\n",
    "[dev-packages]\n",
    "requests = \"*\"\n",
    "pipenv-setup = \"*\"\n",
    "\n",
    "[requires]\n",
    "python_version = \"3.10\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model package scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model package, we have `utils.py` where we define helper functions. These are the usual `load_training_dataframe` function which creates the target features (ride duration in minutes) and filters it to some range, i.e. `[1, 60]`, and `prepare_features` for creating the `PU_DO` combination feature IDs of pickup and dropoff points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`utils.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/ride_duration/utils.py)\n",
    "```\n",
    "```python\n",
    "def load_training_dataframe(file_path, y_min=1, y_max=60):\n",
    "    \"\"\"Load data from disk and preprocess for training.\"\"\"\n",
    "    \n",
    "    # Load data from disk\n",
    "    data = pd.read_parquet(file_path)\n",
    "\n",
    "    # Create target column and filter outliers\n",
    "    data['duration'] = data.lpep_dropoff_datetime - data.lpep_pickup_datetime\n",
    "    data['duration'] = data.duration.dt.total_seconds() / 60\n",
    "    data = data[(data.duration >= y_min) & (data.duration <= y_max)]\n",
    "\n",
    "    # Create uuids\n",
    "    data['ride_id'] = generate_uuids(len(data))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_features(input_data):\n",
    "    \"\"\"Prepare features for dict vectorizer.\"\"\"\n",
    "\n",
    "    X = pd.DataFrame(input_data)\n",
    "    X['PU_DO'] = X['PULocationID'].astype(str) + '_' + X['DOLocationID'].astype(str)\n",
    "    X = X[['PU_DO', 'trip_distance']].to_dict(orient='records')\n",
    "    \n",
    "    return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this package expects models that are pipelines such as:\n",
    "\n",
    "```python\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(), \n",
    "    RandomForestRegressor(**params, n_jobs=-1)\n",
    ")\n",
    "```\n",
    "\n",
    "This avoids having to load the preprocessor separately from the artifacts store. Thus, our models expect `prepare_features(input_data)` where `input_data` can be a dataframe with rows containing features of rides or a list of features dictionaries, e.g. obtained from as a JSON payload. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_model()` function in `predict.py` is of interest. Here we see that the model is loaded either using the MLflow client to get the latest production version of the model, or directly from the S3 artifacts store whenever the request fails (e.g. the tracking server is down). This ensures that we always get a model assuming the following environmental variables are properly configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`predict.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/ride_duration/predict.py)\n",
    "```\n",
    "```python\n",
    "import joblib\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import os \n",
    "import requests\n",
    "\n",
    "from ride_duration.utils import package_dir, prepare_features\n",
    "from typing import Union\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Get latest production model from tracking server \n",
    "    or specific model from S3 bucket if server is down.\"\"\"\n",
    "\n",
    "    try:\n",
    "        TRACKING_SERVER_HOST = os.getenv('TRACKING_SERVER_HOST')\n",
    "        TRACKING_URI = f\"http://{TRACKING_SERVER_HOST}:5000\"\n",
    "\n",
    "        # Check availability of API\n",
    "        response = requests.head(TRACKING_URI)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Tracking server unavailable: HTTP response code {response.status_code}\")\n",
    "            \n",
    "        # Fetch production model from client\n",
    "        mlflow.set_tracking_uri(TRACKING_URI)\n",
    "        client = MlflowClient(tracking_uri=TRACKING_URI)\n",
    "        prod_model = client.get_latest_versions(name='NYCRideDurationModel', stages=['Production'])[0]\n",
    "\n",
    "    except:\n",
    "        EXPERIMENT_ID = os.getenv('EXPERIMENT_ID')\n",
    "        RUN_ID = os.getenv('MODEL_RUN_ID')\n",
    "        source = f\"s3://mlflow-models-ron/{EXPERIMENT_ID}/{RUN_ID}/artifacts/model\"\n",
    "        print(f\"Downloading model {RUN_ID} from S3...\")\n",
    "        \n",
    "    else:\n",
    "        RUN_ID = prod_model.run_id\n",
    "        source = prod_model.source\n",
    "        print(f\"Downloading model {RUN_ID} (latest, production)...\")\n",
    "    \n",
    "    model = mlflow.pyfunc.load_model(source)\n",
    "    return model, RUN_ID\n",
    "\n",
    "\n",
    "def make_prediction(model, input_data: Union[list[dict], pd.DataFrame]):\n",
    "    \"\"\"Make prediction from features dict or DataFrame.\"\"\"\n",
    "    \n",
    "    X = prepare_features(input_data)\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    return preds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to load a model after setting up an environment. Note that the tracking server here is not available as the instance is currently stopped. We expect the model to download from S3 directly using the run ID.\n",
    "\n",
    "```bash\n",
    "❯ export TRACKING_SERVER_HOST=\"ec2-3-93-179-24.compute-1.amazonaws.com\"\n",
    "❯ export EXPERIMENT_ID=\"1\"\n",
    "❯ export MODEL_RUN_ID=\"f4e2242a53a3410d89c061d1958ae70a\"\n",
    "❯ python\n",
    "Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00)\n",
    "[Clang 13.0.1 ] on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> from ride_duration.predict import load_model\n",
    ">>> model, run_id = load_model()\n",
    "Downloading model f4e2242a53a3410d89c061d1958ae70a from S3...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/s3-artifacts-ss.png\n",
    "---\n",
    "---\n",
    "Artifacts store for model runs of experiment 1.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving predictions using Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Flask application, we simply define an endpoint that serves the model predictions. Note that the model loads once when the server starts as this takes a considerable amount of time. For versioning, we return the run ID of the model is returned along with the prediction.\n",
    "\n",
    "```{margin}\n",
    "[`app/main.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/app/main.py)\n",
    "```\n",
    "```python\n",
    "from ride_duration.predict import load_model, make_prediction\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "\n",
    "model, run_id = load_model()\n",
    "app = Flask('duration-prediction')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_endpoint():\n",
    "    \"\"\"Predict ride duration using NYCRideDurationModel.\"\"\"\n",
    "    \n",
    "    ride = request.get_json()\n",
    "    preds = make_prediction(model, ride)\n",
    "\n",
    "    return jsonify({\n",
    "        'duration': float(preds[0]),\n",
    "        'model_version': run_id,\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a script for testing the endpoint. Note that this same script can be used without modification to test remote hosts using port forwarding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`test.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/test.py)\n",
    "```\n",
    "```python\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "ride = [{\n",
    "    'PULocationID': 130,\n",
    "    'DOLocationID': 205,\n",
    "    'trip_distance': 3.66,\n",
    "}]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    host = 'http://0.0.0.0:9696'\n",
    "    url = f'{host}/predict'\n",
    "    response = requests.post(url, json=ride)\n",
    "    result = response.json()\n",
    "    \n",
    "    print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our `Dockerfile`, we start by installing Pipenv. Next we copy `Pipfile` and `Pipfile.lock` as well as files for installing the model package. We also copy the files for the web service. Finally, we install everything using Pipenv, expose the `9696` endpoint, and configure the entrypoint (i.e. serve the main app on `0.0.0.0:9696`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`Dockerfile.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/Dockerfile.py)\n",
    "```\n",
    "```Dockerfile\n",
    "FROM python:3.9.13-slim\n",
    "\n",
    "RUN pip install -U pip\n",
    "RUN pip install pipenv\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY [ \"Pipfile\", \"Pipfile.lock\", \"setup.py\", \"pyproject.toml\",  \"./\"]\n",
    "\n",
    "COPY [ \"ride_duration\",  \"./ride_duration\"]\n",
    "\n",
    "COPY [ \"app\",  \"./app\"]\n",
    "\n",
    "RUN pipenv install --system --deploy\n",
    "\n",
    "EXPOSE 9696\n",
    "\n",
    "# https://stackoverflow.com/a/71092624/1091950\n",
    "ENTRYPOINT [ \"gunicorn\", \"--bind=0.0.0.0:9696\", \"--timeout=600\", \"app.main:app\" ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environmental variables and AWS credentials are saved in a `.env` file in the same directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "TRACKING_SERVER_HOST=ec2-3-93-179-24.compute-1.amazonaws.com\n",
    "EXPERIMENT_ID=1\n",
    "MODEL_RUN_ID=f4e2242a53a3410d89c061d1958ae70a\n",
    "AWS_ACCESS_KEY_ID=******************\n",
    "AWS_SECRET_ACCESS_KEY=******************\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker build -t ride-duration-prediction-service:v1 .\n",
    "```\n",
    "```bash\n",
    "[+] Building 72.3s (13/13) FINISHED\n",
    " => [internal] load build definition from Dockerfile               0.1s\n",
    " => => transferring dockerfile: 388B                               0.0s\n",
    " => [internal] load .dockerignore                                  0.1s\n",
    " => => transferring context: 2B                                    0.0s\n",
    " => [internal] load metadata for docker.io/library/python:3.9.13-  3.4s\n",
    " => [internal] load build context                                  0.1s\n",
    " => => transferring context: 80.02kB                               0.1s\n",
    " => [1/8] FROM docker.io/library/python:3.9.13-slim@sha256:451ccc  0.0s\n",
    " => CACHED [2/8] RUN pip install -U pip                            0.0s\n",
    " => CACHED [3/8] RUN pip install pipenv                            0.0s\n",
    " => CACHED [4/8] WORKDIR /app                                      0.0s\n",
    " => [5/8] COPY [ Pipfile, Pipfile.lock, setup.py, pyproject.toml,  0.1s\n",
    " => [6/8] COPY [ ride_duration,  ./ride_duration]                  0.1s\n",
    " => [7/8] COPY [ app,  ./app]                                      0.0s\n",
    " => [8/8] RUN pipenv install --system --deploy                    64.8s\n",
    " => exporting to image                                             3.6s\n",
    " => => exporting layers                                            3.6s\n",
    " => => writing image sha256:1b2da34ca1b3504d45df527049f788a485713  0.0s\n",
    " => => naming to docker.io/library/ride-duration-prediction-servi  0.0s\n",
    "```\n",
    "\n",
    "Running the container:\n",
    "\n",
    "```bash\n",
    "docker run --env-file .env -it --rm -p 9696:9696 ride-duration-prediction-service:v1\n",
    "```\n",
    "```\n",
    "[2022-06-20 11:12:08 +0000] [1] [INFO] Starting gunicorn 20.1.0\n",
    "[2022-06-20 11:12:08 +0000] [1] [INFO] Listening at: http://0.0.0.0:9696 (1)\n",
    "[2022-06-20 11:12:08 +0000] [1] [INFO] Using worker: sync\n",
    "[2022-06-20 11:12:08 +0000] [9] [INFO] Booting worker with pid: 9\n",
    "Downloading model f4e2242a53a3410d89c061d1958ae70a from S3...\n",
    "2022/06/20 11:22:28 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
    " - psutil (current: uninstalled, required: psutil==5.9.1)\n",
    "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a mismatch between the environment where the model was trained and the current environment where the model is loaded for inference. Running the test script in another terminal to see if it still works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "❯ python test.py\n",
    "{'duration': 18.210770674183355, 'model_version': 'f4e2242a53a3410d89c061d1958ae70a'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after the initial loading time, the next predictions are returned instantaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying batch predictions\n",
    "\n",
    "For use cases that do not require the responsiveness of a web service, we can implement an offline service that makes batch predictions. Typically, offline services are expected to be done between fixed time periods, e.g. daily, weekly, or monthly. A critical element of this is **workflow orchestration** where we regularly pull from a database, make predictions on that data, then write the predictions on a database, or to a file that is uploaded to S3, or it can be pushed to an analytics dashboard thereby refreshing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring script\n",
    "\n",
    "```{margin}\n",
    "[`score.py`](https://github.com/particle1331/inefficient-networks/blob/8edae4a5c88618238550fa319203a7f3f7f690f4/docs/notebooks/mlops/04-deployment/score.py)\n",
    "```\n",
    "```python\n",
    "from ride_duration.utils import load_training_dataframe\n",
    "from ride_duration.predict import load_model, make_prediction\n",
    "\n",
    "\n",
    "def generate_uuids(n):\n",
    "    ride_ids = []\n",
    "    for i in range(n):\n",
    "        ride_ids.append(str(uuid.uuid4()))\n",
    "    return ride_ids\n",
    "\n",
    "\n",
    "def apply_model(\n",
    "    input_file: str, \n",
    "    run_id: str, \n",
    "    output_file: str\n",
    ") -> None:\n",
    "    \n",
    "    print(f'Reading the data from {input_file}...')\n",
    "    df = load_training_dataframe(input_file)\n",
    "    df['ride_id'] = generate_uuids(len(df))\n",
    "\n",
    "    print(f'Loading the model with RUN_ID={run_id}...')\n",
    "    model = load_model()\n",
    "\n",
    "    print(f'Applying the model...')\n",
    "    preds = make_prediction(model, df)\n",
    "\n",
    "    print(f'Saving the result to {output_file}...')\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = df['ride_id']\n",
    "    df_result['lpep_pickup_datetime'] = df['lpep_pickup_datetime']\n",
    "    df_result['PULocationID'] = df['PULocationID']\n",
    "    df_result['DOLocationID'] = df['DOLocationID']\n",
    "    df_result['actual_duration'] = df['duration']\n",
    "    df_result['predicted_duration'] = preds\n",
    "    df_result['diff'] = df_result['actual_duration'] - df_result['predicted_duration']\n",
    "    df_result['model_version'] = run_id\n",
    "    df_result.to_parquet(output_file, index=False)\n",
    "\n",
    "\n",
    "def run(taxi_type: str, year: int, month: int, run_id: str) -> None:\n",
    "\n",
    "    source_url = 'https://s3.amazonaws.com/nyc-tlc/trip+data'\n",
    "    input_file = f'{source_url}/{taxi_type}_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    output_file = f'output/{taxi_type}/{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "    apply_model(\n",
    "        input_file=input_file,\n",
    "        run_id=run_id,\n",
    "        output_file=output_file\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--taxi_type\", default='green', type=str)\n",
    "    parser.add_argument(\"--year\", default=2021, type=int)\n",
    "    parser.add_argument(\"--month\", default=1, type=int)\n",
    "    parser.add_argument(\"--run_id\", type=str)\n",
    "    parser.add_argument(\"--experiment_id\", type=int)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    run(\n",
    "        taxi_type=args.taxi_type,\n",
    "        year=args.year,\n",
    "        month=args.month,\n",
    "        run_id=args.run_id\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pipenv install --dev python-dotenv\n",
    "python score.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning for streaming\n",
    "\n",
    "\n",
    "streaming\n",
    "- producer and consumers\n",
    "- producer pushes event to event stream and consumers wil read from this stream.\n",
    "- and react to these events. \n",
    "- recall web service: 1-1 relationship (explicit connection between user and service)\n",
    "- 1-many  / many - many. \n",
    "- user -> producer=backend -> send event containing all info about ride ->\n",
    "     services will react on this event\n",
    "\n",
    "- e.g. one consuming service predict tip -> send push notif to user asking for tip.\n",
    "- duration prediction (web service) = okay pred\n",
    "- streaming service, better ride duration prediction -> update prediction. \n",
    "- only implicit connection, we dont know which consumer will react, how many\n",
    "- example: content moderation\n",
    "    - user -> video -> event -> C1 (copyright)\n",
    "                             -> C2 (NSFW)        -> prediction stream -> decision service\n",
    "                             -> C2 (violence)          \n",
    "\n",
    "- can be scaled to infinitely many services or models (in principle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 21:38:00</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.63</td>\n",
       "      <td>56.23</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76514</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 22:43:00</td>\n",
       "      <td>2021-01-31 23:21:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.36</td>\n",
       "      <td>46.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76515</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>2021-01-31 22:27:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>18.95</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76516</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:10:00</td>\n",
       "      <td>2021-01-31 23:37:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168</td>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.48</td>\n",
       "      <td>48.87</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>58.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76517</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:35:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.81</td>\n",
       "      <td>15.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76518 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0             2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1             2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2             2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3             2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4             2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "...         ...                  ...                   ...                ...   \n",
       "76513         2  2021-01-31 21:38:00   2021-01-31 22:16:00               None   \n",
       "76514         2  2021-01-31 22:43:00   2021-01-31 23:21:00               None   \n",
       "76515         2  2021-01-31 22:16:00   2021-01-31 22:27:00               None   \n",
       "76516         2  2021-01-31 23:10:00   2021-01-31 23:37:00               None   \n",
       "76517         2  2021-01-31 23:25:00   2021-01-31 23:35:00               None   \n",
       "\n",
       "       RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0             1.0            43           151              1.0           1.01   \n",
       "1             1.0           166           239              1.0           2.53   \n",
       "2             1.0            41            42              1.0           1.12   \n",
       "3             1.0           168            75              1.0           1.99   \n",
       "4             2.0           265           265              3.0           0.00   \n",
       "...           ...           ...           ...              ...            ...   \n",
       "76513         NaN            81            90              NaN          17.63   \n",
       "76514         NaN            35           213              NaN          18.36   \n",
       "76515         NaN            74            69              NaN           2.50   \n",
       "76516         NaN           168           215              NaN          14.48   \n",
       "76517         NaN           119           244              NaN           1.81   \n",
       "\n",
       "       fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0             5.50   0.50      0.5        0.00          0.00      None   \n",
       "1            10.00   0.50      0.5        2.81          0.00      None   \n",
       "2             6.00   0.50      0.5        1.00          0.00      None   \n",
       "3             8.00   0.50      0.5        0.00          0.00      None   \n",
       "4           -52.00   0.00     -0.5        0.00          0.00      None   \n",
       "...            ...    ...      ...         ...           ...       ...   \n",
       "76513        56.23   2.75      0.0        0.00          6.12      None   \n",
       "76514        46.66   0.00      0.0       12.20          6.12      None   \n",
       "76515        18.95   2.75      0.0        0.00          0.00      None   \n",
       "76516        48.87   2.75      0.0        0.00          6.12      None   \n",
       "76517        15.45   2.75      0.0        0.00          0.00      None   \n",
       "\n",
       "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                        0.3          6.80           2.0        1.0   \n",
       "1                        0.3         16.86           1.0        1.0   \n",
       "2                        0.3          8.30           1.0        1.0   \n",
       "3                        0.3          9.30           2.0        1.0   \n",
       "4                       -0.3        -52.80           3.0        1.0   \n",
       "...                      ...           ...           ...        ...   \n",
       "76513                    0.3         65.40           NaN        NaN   \n",
       "76514                    0.3         65.28           NaN        NaN   \n",
       "76515                    0.3         22.00           NaN        NaN   \n",
       "76516                    0.3         58.04           NaN        NaN   \n",
       "76517                    0.3         18.50           NaN        NaN   \n",
       "\n",
       "       congestion_surcharge  \n",
       "0                      0.00  \n",
       "1                      2.75  \n",
       "2                      0.00  \n",
       "3                      0.00  \n",
       "4                      0.00  \n",
       "...                     ...  \n",
       "76513                   NaN  \n",
       "76514                   NaN  \n",
       "76515                   NaN  \n",
       "76516                   NaN  \n",
       "76517                   NaN  \n",
       "\n",
       "[76518 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('data/green_tripdata_2021-01.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.67431673, 13.79195043,  6.96578162, ..., 13.79195043,\n",
       "       36.27351977, 10.71632294])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ride_duration.predict import load_model\n",
    "from ride_duration.predict import make_prediction\n",
    "\n",
    "model = load_model(run_id='f4e2242a53a3410d89c061d1958ae70a')\n",
    "make_prediction(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>actual_duration</th>\n",
       "      <th>predicted_duration</th>\n",
       "      <th>diff</th>\n",
       "      <th>model_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>711a6b32-40d9-4ebd-964d-aeac5ca4ee62</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>6.480039</td>\n",
       "      <td>-2.546706</td>\n",
       "      <td>08fccca832b74a49995863d7ff8a7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50ee8a65-a018-44e7-9424-5149ae0d5c56</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>13.822634</td>\n",
       "      <td>-5.072634</td>\n",
       "      <td>08fccca832b74a49995863d7ff8a7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514ae81e-80bb-47ec-9ff7-8929eb478d75</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>5.966667</td>\n",
       "      <td>6.945991</td>\n",
       "      <td>-0.979325</td>\n",
       "      <td>08fccca832b74a49995863d7ff8a7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46ee914c-0165-4b30-942a-d96b5c0650b2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>11.516087</td>\n",
       "      <td>-4.432754</td>\n",
       "      <td>08fccca832b74a49995863d7ff8a7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41bf60ed-0a5c-4b84-8116-20c52f329097</td>\n",
       "      <td>2021-01-01 00:26:31</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>3.507386</td>\n",
       "      <td>-1.190719</td>\n",
       "      <td>08fccca832b74a49995863d7ff8a7917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ride_id lpep_pickup_datetime  PULocationID  \\\n",
       "0  711a6b32-40d9-4ebd-964d-aeac5ca4ee62  2021-01-01 00:15:56            43   \n",
       "1  50ee8a65-a018-44e7-9424-5149ae0d5c56  2021-01-01 00:25:59           166   \n",
       "2  514ae81e-80bb-47ec-9ff7-8929eb478d75  2021-01-01 00:45:57            41   \n",
       "3  46ee914c-0165-4b30-942a-d96b5c0650b2  2020-12-31 23:57:51           168   \n",
       "4  41bf60ed-0a5c-4b84-8116-20c52f329097  2021-01-01 00:26:31            75   \n",
       "\n",
       "   DOLocationID  actual_duration  predicted_duration      diff  \\\n",
       "0           151         3.933333            6.480039 -2.546706   \n",
       "1           239         8.750000           13.822634 -5.072634   \n",
       "2            42         5.966667            6.945991 -0.979325   \n",
       "3            75         7.083333           11.516087 -4.432754   \n",
       "4            75         2.316667            3.507386 -1.190719   \n",
       "\n",
       "                      model_version  \n",
       "0  08fccca832b74a49995863d7ff8a7917  \n",
       "1  08fccca832b74a49995863d7ff8a7917  \n",
       "2  08fccca832b74a49995863d7ff8a7917  \n",
       "3  08fccca832b74a49995863d7ff8a7917  \n",
       "4  08fccca832b74a49995863d7ff8a7917  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out = pd.read_parquet('output/green/2021-01.parquet')\n",
    "out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1655460227751, current_stage='Production', description='', last_updated_timestamp=1655460239062, name='NYCRideDurationModel', run_id='f4e2242a53a3410d89c061d1958ae70a', run_link='', source='s3://mlflow-models-ron/1/f4e2242a53a3410d89c061d1958ae70a/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_latest_versions(name='NYCRideDurationModel', stages=['Production'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.67431673, 13.79195043,  6.96578162, ..., 13.79195043,\n",
       "       36.27351977, 10.71632294])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model('models:/NYCRideDurationModel/Production')\n",
    "make_prediction(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>actual_duration</th>\n",
       "      <th>predicted_duration</th>\n",
       "      <th>diff</th>\n",
       "      <th>model_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d685e8a5-3374-453d-acb2-20fb17445dad</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>4.403834</td>\n",
       "      <td>-0.470501</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488137c5-c8f9-44aa-9995-884d16800d0a</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.830572</td>\n",
       "      <td>-0.080572</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c8a71eb8-dc60-4223-b81c-520d1e4726f6</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>5.966667</td>\n",
       "      <td>6.819916</td>\n",
       "      <td>-0.853250</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572f288d-f6d7-44e2-bca0-a17e0f920914</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>13.923927</td>\n",
       "      <td>-6.840594</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15c5da8f-13fa-4047-8566-8c25865943ee</td>\n",
       "      <td>2021-01-01 00:26:31</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>6.735151</td>\n",
       "      <td>-4.418484</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73903</th>\n",
       "      <td>23134189-8855-476f-8f66-ab3d6f93ee0c</td>\n",
       "      <td>2021-01-31 21:38:00</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>40.089000</td>\n",
       "      <td>-2.089000</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73904</th>\n",
       "      <td>11b8fc14-744b-4d74-9048-39a2651dd7c9</td>\n",
       "      <td>2021-01-31 22:43:00</td>\n",
       "      <td>35</td>\n",
       "      <td>213</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>31.554369</td>\n",
       "      <td>6.445631</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73905</th>\n",
       "      <td>494fc2dc-8b72-49f1-99df-7243c0bf0506</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.447926</td>\n",
       "      <td>-6.447926</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73906</th>\n",
       "      <td>4b5220e3-005f-41ac-b4a3-503806f5e127</td>\n",
       "      <td>2021-01-31 23:10:00</td>\n",
       "      <td>168</td>\n",
       "      <td>215</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>33.382096</td>\n",
       "      <td>-6.382096</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73907</th>\n",
       "      <td>c81c3b92-29b0-4823-a8c6-b93bcbf69faf</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>119</td>\n",
       "      <td>244</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.173604</td>\n",
       "      <td>-3.173604</td>\n",
       "      <td>e1efc53e9bd149078b0c12aeaa6365df</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73908 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ride_id lpep_pickup_datetime  \\\n",
       "0      d685e8a5-3374-453d-acb2-20fb17445dad  2021-01-01 00:15:56   \n",
       "1      488137c5-c8f9-44aa-9995-884d16800d0a  2021-01-01 00:25:59   \n",
       "2      c8a71eb8-dc60-4223-b81c-520d1e4726f6  2021-01-01 00:45:57   \n",
       "3      572f288d-f6d7-44e2-bca0-a17e0f920914  2020-12-31 23:57:51   \n",
       "4      15c5da8f-13fa-4047-8566-8c25865943ee  2021-01-01 00:26:31   \n",
       "...                                     ...                  ...   \n",
       "73903  23134189-8855-476f-8f66-ab3d6f93ee0c  2021-01-31 21:38:00   \n",
       "73904  11b8fc14-744b-4d74-9048-39a2651dd7c9  2021-01-31 22:43:00   \n",
       "73905  494fc2dc-8b72-49f1-99df-7243c0bf0506  2021-01-31 22:16:00   \n",
       "73906  4b5220e3-005f-41ac-b4a3-503806f5e127  2021-01-31 23:10:00   \n",
       "73907  c81c3b92-29b0-4823-a8c6-b93bcbf69faf  2021-01-31 23:25:00   \n",
       "\n",
       "       PULocationID  DOLocationID  actual_duration  predicted_duration  \\\n",
       "0                43           151         3.933333            4.403834   \n",
       "1               166           239         8.750000            8.830572   \n",
       "2                41            42         5.966667            6.819916   \n",
       "3               168            75         7.083333           13.923927   \n",
       "4                75            75         2.316667            6.735151   \n",
       "...             ...           ...              ...                 ...   \n",
       "73903            81            90        38.000000           40.089000   \n",
       "73904            35           213        38.000000           31.554369   \n",
       "73905            74            69        11.000000           17.447926   \n",
       "73906           168           215        27.000000           33.382096   \n",
       "73907           119           244        10.000000           13.173604   \n",
       "\n",
       "           diff                     model_version  \n",
       "0     -0.470501  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "1     -0.080572  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "2     -0.853250  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "3     -6.840594  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "4     -4.418484  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "...         ...                               ...  \n",
       "73903 -2.089000  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "73904  6.445631  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "73905 -6.447926  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "73906 -6.382096  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "73907 -3.173604  e1efc53e9bd149078b0c12aeaa6365df  \n",
       "\n",
       "[73908 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('output/green/2021-01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mlflow server -h 0.0.0.0 -p 5000\n",
    "    --backend-store-uri=sqlite:///mlflow.db \\\n",
    "    --default-artifact-root=s3://mlflow-models-ron/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-3-93-179-24.compute-1.amazonaws.com\"\n",
    "TRACKING_URI = f\"http://{TRACKING_SERVER_HOST}:5000\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='s3://mlflow-models-ron/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=TRACKING_URI)\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run training\n",
    "- can be accessed locally. but make sure environment is configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TRACKING_SERVER_HOST=ec2-52-90-170-113.compute-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_SERVER_HOST = os.getenv('TRACKING_SERVER_HOST')\n",
    "TRACKING_SERVER_HOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-52-90-170-113.compute-1.amazonaws.com\"\n",
    "TRACKING_URI = f\"http://{TRACKING_SERVER_HOST}:5000\"\n",
    "\n",
    "response = requests.head(TRACKING_URI)\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"Tracking server unavailable: HTTP response code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scenario\n",
    "* Creating the role\n",
    "* Create a Lambda function, test it\n",
    "* Create a Kinesis stream\n",
    "* Connect the function to the stream\n",
    "* Send the records\n",
    "\n",
    "Links\n",
    "* [Tutorial: Using Amazon Lambda with Amazon Kinesis](https://docs.amazonaws.cn/en_us/lambda/latest/dg/with-kinesis-example.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/particle1331/miniforge3/envs/ml/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Train script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training models that we use to serve predictions in our API, we use the following script. This trains a model using the `ride_duration` package, which ensures smooth integration in the API, and logs this model to a remote MLflow tracking server. The tracking server host is provided as a command line argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import mlflow \n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from ride_duration.utils import load_training_dataframe, prepare_features\n",
    "\n",
    "\n",
    "def setup(tracking_server_host):\n",
    "    TRACKING_URI = f\"http://{tracking_server_host}:5000\"\n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "\n",
    "def run_training(X_train, y_train, X_valid, y_valid):\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 20\n",
    "        }\n",
    "        \n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(), \n",
    "            RandomForestRegressor(**params, n_jobs=-1)\n",
    "        )\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_valid)\n",
    "        rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"rmse_valid\", rmse)\n",
    "        mlflow.sklearn.log_model(pipeline, artifact_path='model')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--tracking-server-host\", type=str)\n",
    "    parser.add_argument(\"--train_path\", type=str)\n",
    "    parser.add_argument(\"--valid_path\", type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Getting data from disk\n",
    "    train_data = load_training_dataframe(args.train_path)\n",
    "    valid_data = load_training_dataframe(args.valid_path)\n",
    "\n",
    "    # Preprocessing dataset\n",
    "    X_train = prepare_features(train_data.drop(['duration'], axis=1))\n",
    "    X_valid = prepare_features(valid_data.drop(['duration'], axis=1))\n",
    "    y_train = train_data.duration.values\n",
    "    y_valid = valid_data.duration.values\n",
    "\n",
    "    # Push training to server\n",
    "    setup(args.tracking_server_host)\n",
    "    run_training(X_train, y_train, X_valid, y_valid)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
