{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestration and ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Ongoing&color=orange)\n",
    "\n",
    "<!-- Place this tag where you want the button to render. -->\n",
    "<a class=\"github-button\" href=\"https://github.com/particle1331/steepest-ascent\" data-color-scheme=\"no-preference: dark; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star particle1331/steepest-ascent on GitHub\">Star</a>\n",
    "<!-- Place this tag in your head or just before your close body tag. -->\n",
    "<script async defer src=\"https://buttons.github.io/buttons.js\"></script> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous module, we learned about experiment tracking and model registry.\n",
    "In particular, we discussed how to get a candidate model and promote it from staging to production.\n",
    "In this module, we learn how to automate this process, and having this scheduled with workflow orchestration &mdash; specifically, with [Prefect 2.0](https://orion-docs.prefect.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefect allows us to programatically author, schedule, and monitor workflows. Prefect allows us to minimize time on **negative engineering**, i.e. coding against all possible causes of failure. This is a Sisyphean task as there are endless ways that elements of a data pipeline can fail. In practical terms, Prefect provides tools such as retries, concurrency, logging, a nice UI, tracking dependencies, a database, caching and serialization, parameterization of scheduled tasks, and more. As we shall see later, this adds observability to the whole data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "⚠️ **Attribution:** These are notes for [Module 3](https://github.com/DataTalksClub/mlops-zoomcamp/tree/main/03-orchestration) of the [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp). The MLOps Zoomcamp is a free course from [DataTalks.Club](https://github.com/DataTalksClub).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefect flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **flow** in Prefect is simply a Python function. This consists of **tasks** which can be thought of as the atom of observability in Prefect. In practice, to create a flow, you simply convert functions that make it up into tasks. Consider the following example from the [*Getting Started with Prefect 2.0*](https://www.prefect.io/guide/blog/getting-started-prefect-2/#Makingourflowsbetterwithtasks) blog post. Here, we simulate getting data from an unreliable API, augmenting the fetched data, and writing the resulting data into a database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:26:54.662 | INFO    | prefect.engine - Created flow run 'juicy-platypus' for flow 'pipeline'\n",
      "17:26:54.664 | INFO    | Flow run 'juicy-platypus' - Using task runner 'ConcurrentTaskRunner'\n",
      "17:26:54.671 | WARNING | Flow run 'juicy-platypus' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\n",
      "17:26:54.708 | INFO    | Flow run 'juicy-platypus' - Created task run 'call_unreliable_api-48f93715-0' for task 'call_unreliable_api'\n",
      "17:26:54.729 | INFO    | Flow run 'juicy-platypus' - Created task run 'augment_data-505b3e0c-0' for task 'augment_data'\n",
      "17:26:54.741 | ERROR   | Task run 'call_unreliable_api-48f93715-0' - Encountered exception during execution:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/engine.py\", line 798, in orchestrate_task_run\n",
      "    result = await run_sync_in_worker_thread(task.fn, *args, **kwargs)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/utilities/asyncio.py\", line 54, in run_sync_in_worker_thread\n",
      "    return await anyio.to_thread.run_sync(call, cancellable=True)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/jq/9vsvd9252_349lsng_5gc_jw0000gn/T/ipykernel_38107/3061218592.py\", line 10, in call_unreliable_api\n",
      "    raise Exception(\"Our unreliable service failed.\")\n",
      "Exception: Our unreliable service failed.\n",
      "17:26:54.766 | INFO    | Flow run 'juicy-platypus' - Created task run 'write_to_database-d58974ba-0' for task 'write_to_database'\n",
      "17:26:54.782 | INFO    | Task run 'call_unreliable_api-48f93715-0' - Received non-final state 'AwaitingRetry' when proposing final state 'Failed' and will attempt to run again...\n",
      "17:26:54.804 | ERROR   | Task run 'call_unreliable_api-48f93715-0' - Encountered exception during execution:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/engine.py\", line 798, in orchestrate_task_run\n",
      "    result = await run_sync_in_worker_thread(task.fn, *args, **kwargs)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/utilities/asyncio.py\", line 54, in run_sync_in_worker_thread\n",
      "    return await anyio.to_thread.run_sync(call, cancellable=True)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/jq/9vsvd9252_349lsng_5gc_jw0000gn/T/ipykernel_38107/3061218592.py\", line 10, in call_unreliable_api\n",
      "    raise Exception(\"Our unreliable service failed.\")\n",
      "Exception: Our unreliable service failed.\n",
      "17:26:54.822 | INFO    | Task run 'call_unreliable_api-48f93715-0' - Received non-final state 'AwaitingRetry' when proposing final state 'Failed' and will attempt to run again...\n",
      "17:26:54.857 | INFO    | Task run 'call_unreliable_api-48f93715-0' - Finished in state Completed()\n",
      "17:26:54.885 | INFO    | Task run 'augment_data-505b3e0c-0' - Finished in state Completed()\n",
      "17:26:54.915 | INFO    | Task run 'write_to_database-d58974ba-0' - Finished in state Completed()\n",
      "17:26:54.925 | INFO    | Flow run 'juicy-platypus' - Finished in state Completed('All states completed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote {'data': 42, 'message': '0'} to database successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Completed(message='All states completed.', type=COMPLETED, result=[Completed(message=None, type=COMPLETED, result={'data': 42, 'message': '0'}, task_run_id=72365071-5085-4158-a391-eeddede5ca75), Completed(message=None, type=COMPLETED, result={'data': 42, 'message': '0'}, task_run_id=e7028889-7db0-435f-896c-03e6ff7bb733), Completed(message=None, type=COMPLETED, result='Success!', task_run_id=9ec022e6-39e8-41ea-98b2-b0a14df9eaff)], flow_run_id=be507fa9-289c-4ff1-a7eb-fd2aa29ab969)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from prefect import flow, task \n",
    "\n",
    "\n",
    "@task(retries=3)\n",
    "def call_unreliable_api():\n",
    "    choices = [{\"data\": 42}, \"Failure\"]\n",
    "    res = random.choice(choices)\n",
    "    if res == \"Failure\":\n",
    "        raise Exception(\"Our unreliable service failed.\")\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "@task\n",
    "def augment_data(data: dict, msg: str):\n",
    "    data[\"message\"] = msg\n",
    "    return data\n",
    "\n",
    "@task\n",
    "def write_to_database(data: dict):\n",
    "    print(f\"Wrote {data} to database successfully!\")\n",
    "    return \"Success!\"\n",
    "\n",
    "@flow \n",
    "def pipeline(msg: str):\n",
    "    api_result = call_unreliable_api()\n",
    "    augmented_data = augment_data(data=api_result, msg=msg)\n",
    "    write_to_database(augmented_data)\n",
    "\n",
    "\n",
    "pipeline(0) # Augment data with zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefect Orion UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this failed before pushing through. We can start the UI by calling `prefect orion start` in any directory (`.prefect` is saved in the system's root directory). This starts the Prefect Orion server in port 4200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "❯ prefect orion start\n",
    "Starting...\n",
    "\n",
    " ___ ___ ___ ___ ___ ___ _____    ___  ___ ___ ___  _  _\n",
    "| _ \\ _ \\ __| __| __/ __|_   _|  / _ \\| _ \\_ _/ _ \\| \\| |\n",
    "|  _/   / _|| _|| _| (__  | |   | (_) |   /| | (_) | .` |\n",
    "|_| |_|_\\___|_| |___\\___| |_|    \\___/|_|_\\___\\___/|_|\\_|\n",
    "\n",
    "Configure Prefect to communicate with the server with:\n",
    "\n",
    "    prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n",
    "\n",
    "Check out the dashboard at http://127.0.0.1:4200\n",
    "\n",
    "\n",
    "\n",
    "INFO:     Started server process [20557]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://127.0.0.1:4200 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We navigate around the UI to find the `pipeline` flow and its most recent which, as we have seen in the logs, was able to complete its execution. Here we see that this flow started on `2022/06/10 11:05:51 PM` and ended on `2022/06/10 11:05:52 PM`. We also see the logs has the details of the exception when the API call failed. In the second tab, we can see the tasks that make up this flow. There is also the subflow tab which shows that we can call flows from a parent flow.\n",
    "\n",
    "```{figure} ../../../img/hello-world-2.png\n",
    "---\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more interesting features of the dashboard is **Radar** on the right. This shows the dependence between tasks. Notice the linear dependence of the tasks, e.g. `write_to_database` depends on `augment_data` task but not on `call_unreliable_api`. Hovering on the tasks show the backward and forward data dependencies. Having tasks arranged in concentric circles allow for a heirarchy of dependence. Note that the runtime for each task is also conveniently displayed.\n",
    "\n",
    "```{figure} ../../../img/hello-world-1.png\n",
    "---\n",
    "---\n",
    "```\n",
    "\n",
    "Finally, let us look at a flow which failed to complete all its tasks. Here all calls to the API failed despite the retries. The radar plot nicely shows where the flow has failed. This is really useful, especially when we have a dozens task and multiple subflows happening in our data pipeline.\n",
    "\n",
    "\n",
    "```{figure} ../../../img/hello-world-3.png\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Remark.** Note also that geometrically there is more space available to grow the dependence tree due to nodes being farther apart as we move radially with a fixed angle, this also allows Radar to minimize edge crossing by combining radial and circumferential movement for the edges between task nodes. This is in comparison to traditional top-down or left-right approaches of drawing graphs. Furthermore, it turns out that Radar dynamically updates as tasks complete (or fails) its execution. And the mini-map, edge tracing, and node selection tools make workflow inspection doable even for highly complex graphs. See [*Introducing Radar*](https://www.prefect.io/guide/blog/introducing-radar/) by Bill Palombi for further reading.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow runs as flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will write our code from the previous module for running modelling experiments as a flow in Prefect. Our idea is to have two flows: one for preprocessing the dataset such that the preprocessed datasets will be used by all experiment runs which will be the second flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`utils.py`](https://github.com/particle1331/inefficient-networks/blob/57e38c5eb06ac3323035fb9f8d714870e397a39a/docs/notebooks/mlops/3-prefect/utils.py)\n",
    "```\n",
    "```python\n",
    "@task\n",
    "def load_training_dataframe(file_path, y_min=1, y_max=60):\n",
    "    \"\"\"Load data from disk and preprocess for training.\"\"\"\n",
    "    \n",
    "    # Load data from disk\n",
    "    data = pd.read_parquet(file_path)\n",
    "\n",
    "    # Create target column and filter outliers\n",
    "    data['duration'] = data.lpep_dropoff_datetime - data.lpep_pickup_datetime\n",
    "    data['duration'] = data.duration.dt.total_seconds() / 60\n",
    "    data = data[(data.duration >= y_min) & (data.duration <= y_max)]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "@task\n",
    "def fit_preprocessor(train_data):\n",
    "    \"\"\"Fit and save preprocessing pipeline.\"\"\"\n",
    "\n",
    "    # Unpack passed data\n",
    "    y_train = train_data.duration.values\n",
    "    X_train = train_data.drop('duration', axis=1)    \n",
    "\n",
    "    # Initialize pipeline\n",
    "    cat_features = ['PU_DO']\n",
    "    num_features = ['trip_distance']\n",
    "\n",
    "    preprocessor = make_pipeline(\n",
    "        AddPickupDropoffPair(),\n",
    "        SelectFeatures(cat_features + num_features),\n",
    "        ConvertToString(cat_features),\n",
    "        ConvertToDict(),\n",
    "        DictVectorizer(),\n",
    "    )\n",
    "\n",
    "    # Fit only on train set\n",
    "    preprocessor.fit(X_train, y_train)\n",
    "    joblib.dump(preprocessor, artifacts / 'preprocessor.pkl')\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "@task\n",
    "def create_model_features(preprocessor, train_data, valid_data):\n",
    "    \"\"\"Fit feature engineering pipeline. Transform training dataframes.\"\"\"\n",
    "\n",
    "    # Unpack passed data\n",
    "    y_train = train_data.duration.values\n",
    "    y_valid = valid_data.duration.values\n",
    "    X_train = train_data.drop('duration', axis=1)\n",
    "    X_valid = valid_data.drop('duration', axis=1)\n",
    "    \n",
    "    # Feature engineering\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_valid = preprocessor.transform(X_valid)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "@flow\n",
    "def preprocess_data(train_data_path, valid_data_path):\n",
    "    \"\"\"Preprocess data for model training.\"\"\"\n",
    "\n",
    "    train_data = load_training_dataframe(train_data_path)\n",
    "    valid_data = load_training_dataframe(valid_data_path)\n",
    "    \n",
    "    preprocessor = fit_preprocessor(train_data)\n",
    "    \n",
    "    return create_model_features(preprocessor, train_data, valid_data).result()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the `preprocess_data` flow loads the datasets from disk, fits and saves a preprocessor, and then creates transformed features and targets for training the machine learning model. Note that we have to be careful here to make sure we don't use concurrent execution if using multiple since we may log different preprocessors. In this case, we only use on preprocessor for all experiments so this concern does not materialize.\n",
    "\n",
    "Next, we will create a flow for executing experiment runs. Note that in the `main` flow we are passing around a [`PrefectFuture`](https://orion-docs.prefect.io/api-ref/prefect/futures/) object instead of Python objects. Futures represent the execution of a task and allow retrieval of the task run's state. This so that Prefect is able to track data dependency between tasks &mdash; converting to Python objects, i.e. using `.result()`, breaks this lineage. Note that once a future has been passed into the function, then we can treat this as a usual Python object. This is because the `task` decorator has done work to unpack the Future object into Python objects. For example, instead of defining:\n",
    "\n",
    "```python\n",
    "@task\n",
    "def f(X, y):\n",
    "    ...\n",
    "```\n",
    "\n",
    "We do:\n",
    "\n",
    "```python\n",
    "@task\n",
    "def f(future):\n",
    "    X, y = future\n",
    "```\n",
    "\n",
    "You will see notice this in the `xgboost_runs` and `lr_runs` tasks below. For the `main` flow, we execute the following sequentially:\n",
    "setting up the connection to the experiment (not a task), a subflow run for preprocessing the datasets for modelling, one run of the linear regression baseline model, and multiple runs of XGBoost hyperparameter optimization using the TPE algorithm. Sequential execution ensures that all resources are allocated to a single learning algorithm at each point in the flow run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`main.py`](https://github.com/particle1331/inefficient-networks/blob/fd937c097b9f59e171f263f0208b2407bb22efde/docs/notebooks/mlops/3-prefect/main.py)\n",
    "```\n",
    "```python\n",
    "def objective(params, xgb_train, y_train, xgb_valid, y_valid):\n",
    "    \"\"\"Compute validation RMSE (one trial = one run).\"\"\"\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=xgb_train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(xgb_valid, 'validation')],\n",
    "            early_stopping_rounds=5\n",
    "        )\n",
    "\n",
    "        # MLflow logging\n",
    "        ...\n",
    "\n",
    "    return {'loss': rmse_valid, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "@task\n",
    "def xgboost_runs(num_runs, training_packet):\n",
    "    \"\"\"Run TPE algorithm on search space to minimize objective.\"\"\"\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = training_packet\n",
    "    Xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    Xgb_valid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=partial(\n",
    "            objective, \n",
    "            xgb_train=Xgb_train, y_train=y_train, \n",
    "            xgb_valid=Xgb_valid, y_valid=y_valid,\n",
    "        ),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_runs,\n",
    "        trials=Trials()\n",
    "    )\n",
    "\n",
    "\n",
    "@task\n",
    "def linreg_runs(training_packet):\n",
    "    \"\"\"Run linear regression training.\"\"\"\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = training_packet\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # MLflow logging\n",
    "        ...\n",
    "\n",
    "        \n",
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def main(train_data_path, valid_data_path, num_xgb_runs=1):\n",
    "\n",
    "    # Set and run experiment\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "    future = preprocess_data(train_data_path, valid_data_path)\n",
    "    linreg_runs(future)\n",
    "    xgboost_runs(num_xgb_runs, future)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the dashboard, we can see a `utopian-rat` run of the `main` flow. As expected, this consists of 3 tasks (one of which is a subflow) that are executed sequentially as indicated in the timeline. If we look at the preprocessing subflow, we see that it has concurrent execution from overlapping lines in the timeline graph. This subflow consists of four tasks.\n",
    "\n",
    "```{figure} ../../../img/mlflow-runs-dashboard.png\n",
    "---\n",
    "---\n",
    "```\n",
    "\n",
    "```{figure} ../../../img/radar_preprocessing.png\n",
    "---\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check out the radar of the `main` flow, we see the following. Here in an earlier screenshot, we see that the XGBoost run is still running. The `xgboost_runs` task has been running for 1 minute and 14 seconds. Both runs depend on the preprocessing subflow. We can go down on the radar for the preprocessing subflow by clicking on the `4 task runs` button.\n",
    "\n",
    "\n",
    "```{figure} ../../../img/radar_xgb.png\n",
    "---\n",
    "---\n",
    "```\n",
    "\n",
    "Here we see the radar plot. You might want to open this image in a new tab to see better. Hovering on each task shows its data dependence on other tasks. For each task, we show the dependency lines in the figure below:\n",
    "\n",
    "```{figure} ../../../img/radar.png\n",
    "---\n",
    "---\n",
    "```\n",
    "\n",
    "The `load_training_dataframe` task on the left loads the validation dataset since it only has `create_model_features` as the only forward dependence. The `fit_preprocessor` task trains the preprocessor and therefore depends on the task that loads the training dataframes. Next, we see the dependencies of the `load_training_dataframe` task that loads the train dataset. This sends data to the preprocessor and to the final task `create_model_features` which returns all processed data for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we deploy a workflow that transitions a performant model to staging in MLflow's model registry. This can be useful for regularly staging candidate models models trained on new data. The staged models can then be further checked if it should be deployed into production. Refer to the code in [Module 2](https://particle1331.github.io/inefficient-networks/notebooks/mlops/2-mlflow/2-mlflow.html#api-workflows) to understand the next few code cells. Checking the connection to MLflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model staging review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Experiment)\n",
      "    experiment_id=0\n",
      "    name='Default'\n",
      "    artifact_location='./mlruns/0'\n",
      "\n",
      "(Experiment)\n",
      "    experiment_id=1\n",
      "    name='nyc-taxi-experiment'\n",
      "    artifact_location='./mlruns/1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "\n",
    "def print_experiment(experiment):\n",
    "    print(f\"(Experiment)\")\n",
    "    print(f\"    experiment_id={experiment.experiment_id}\")\n",
    "    print(f\"    name='{experiment.name}'\")\n",
    "    print(f\"    artifact_location='{experiment.artifact_location}'\")\n",
    "    print()\n",
    "\n",
    "for experiment in client.list_experiments():\n",
    "    print_experiment(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we run a flow which performs HPO for XGBoost with 10 runs. So we expect we have experiments in our tracker. We will filter out runs with valid RMSE less than `6.5` and inference time less than `2e-5`. This can be done through the client as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 4659603b9b674df59319ae6d4b67890a   rmse_valid: 6.404   inference_time: 1.1171e-05\n",
      "run_id: d2baeedede3545c7a12f858c86e01605   rmse_valid: 6.415   inference_time: 7.7727e-06\n",
      "run_id: 4a627ff6420549e5a0dbaf41fef5795b   rmse_valid: 6.440   inference_time: 7.2689e-06\n",
      "run_id: 391212c00c67495fbfcf6e5abc0c8a9d   rmse_valid: 6.442   inference_time: 6.0649e-06\n",
      "run_id: f3fc839c1036469290c309afa47e3d3b   rmse_valid: 6.470   inference_time: 8.2583e-06\n"
     ]
    }
   ],
   "source": [
    "candidates = client.search_runs(\n",
    "    experiment_ids=1,\n",
    "    filter_string='metrics.rmse_valid < 6.5 and metrics.inference_time < 20e-6',\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse_valid ASC\"]\n",
    ")\n",
    "\n",
    "for run in candidates:\n",
    "    print(f\"run_id: {run.info.run_id}   rmse_valid: {run.data.metrics['rmse_valid']:.3f}   inference_time: {run.data.metrics['inference_time']:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4659603b9b674df59319ae6d4b67890a', 6.40444573825302)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_stage = candidates[0]\n",
    "model_to_stage.info.run_id, model_to_stage.data.metrics['rmse_valid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model, we register this to `Staging`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'NYCRideDurationModel'.\n",
      "2022/06/11 23:25:29 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: NYCRideDurationModel, version 1\n",
      "Created version '1' of model 'NYCRideDurationModel'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1654961129078, current_stage='Staging', description=None, last_updated_timestamp=1654961129083, name='NYCRideDurationModel', run_id='4659603b9b674df59319ae6d4b67890a', run_link=None, source='./mlruns/1/4659603b9b674df59319ae6d4b67890a/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_model = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{model_to_stage.info.run_id}/model\", \n",
    "    name='NYCRideDurationModel'\n",
    ")\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name='NYCRideDurationModel',\n",
    "    version=registered_model.version, \n",
    "    stage='Staging',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/mlflow-automatic-staging.png\n",
    "---\n",
    "---\n",
    "Staged model from code cells above.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Staging flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, so we now collect the above code cells along with the code for experiment runs into a workflow which will create a new experiment, perform the experiment runs, and filters the best model for staging. We will then schedule this workflow to be run at fixed intervals using Prefect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`mlflow_deploy.py`](https://github.com/particle1331/inefficient-networks/blob/fbd70bedc69e86a76b722c64cf53a6885b85d2ba/docs/notebooks/mlops/3-prefect/mlflow_deploy.py#L259-L306)\n",
    "```\n",
    "```python\n",
    "from prefect.deployments import DeploymentSpec\n",
    "from prefect.orion.schemas.schedules import IntervalSchedule\n",
    "from prefect.flow_runners import SubprocessFlowRunner\n",
    "from datetime import timedelta\n",
    "\n",
    "...\n",
    "\n",
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def deploy_main(train_data_path, valid_data_path, num_xgb_runs=1):\n",
    "\n",
    "    # Set and run experiment\n",
    "    MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "    EXPERIMENT_NAME = f\"nyc-taxi-experiment-{str(datetime.datetime.now())}\"\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    future = preprocess_data(train_data_path, valid_data_path)\n",
    "    linreg_runs(future)\n",
    "    xgboost_runs(num_xgb_runs, future)\n",
    "\n",
    "    # Register best model staging\n",
    "    client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "    candidates = client.search_runs(\n",
    "        experiment_ids=client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id,\n",
    "        filter_string='metrics.rmse_valid < 6.5 and metrics.inference_time < 20e-6',\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=5,\n",
    "        order_by=[\"metrics.rmse_valid ASC\"]\n",
    "    )\n",
    "\n",
    "    model_to_stage = candidates[0]\n",
    "    registered_model = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{model_to_stage.info.run_id}/model\", \n",
    "        name='NYCRideDurationModel'\n",
    "    )\n",
    "\n",
    "    client.transition_model_version_stage(\n",
    "        name='NYCRideDurationModel',\n",
    "        version=registered_model.version, \n",
    "        stage='Staging',\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have created a deployment which will run the `deploy_main` flow every 5 minutes locally. We also set the parameters since the `deploy_main` flow takes in arguments when it runs. This adds a bit of flexibility. Specifying `SubprocessFlowRunner()` as flow runner, means that this flow is executed locally, e.g. not on Kubernetes or Docker containers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local storage setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating a deployment in Prefect let us first setup a local storage for saving for persisting flow code for deployments, task results, and flow results. This is simple enough to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "❯ prefect storage create\n",
    "Found the following storage types:\n",
    "0) Azure Blob Storage\n",
    "    Store data in an Azure blob storage container.\n",
    "1) File Storage\n",
    "    Store data as a file on local or remote file systems.\n",
    "2) Google Cloud Storage\n",
    "    Store data in a GCS bucket.\n",
    "3) Local Storage\n",
    "    Store data in a run's local file system.\n",
    "4) S3 Storage\n",
    "    Store data in an AWS S3 bucket.\n",
    "5) Temporary Local Storage\n",
    "    Store data in a temporary directory in a run's local file system.\n",
    "Select a storage type to create: 3\n",
    "You've selected Local Storage. It has 1 option(s).\n",
    "STORAGE PATH: ~/.prefect/local-storage\n",
    "Choose a name for this storage configuration: local-storage\n",
    "Validating configuration...\n",
    "Registering storage with server...\n",
    "Registered storage 'local-storage' with identifier '0e3f5d76-4058-4bc7-afc6-eb101f749139'.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to create our deployment in Prefect, we have to execute `prefect deployment create <deployment script (.py)>` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "DeploymentSpec(\n",
    "    flow=deploy_main,\n",
    "    name=\"mlflow_staging\",\n",
    "    schedule=IntervalSchedule(interval=timedelta(minutes=5)),\n",
    "    flow_runner=SubprocessFlowRunner(),\n",
    "    parameters={\n",
    "        \"train_data_path\": data_path / 'green_tripdata_2021-01.parquet',\n",
    "        \"valid_data_path\": data_path / 'green_tripdata_2021-02.parquet',\n",
    "        \"num_xgb_runs\": 10\n",
    "    },\n",
    "    tags=[\"ml\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading deployment specifications from python script at \u001b[32m'mlflow_deploy.py'\u001b[0m...\n",
      "/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/deployments.py:247: UserWarning: You have configured local storage, this deployment will only be usable from the current machine..\n",
      "  warnings.warn(\n",
      "Creating deployment \u001b[1;34m'mlflow_staging'\u001b[0m for flow \u001b[34m'deploy-main'\u001b[0m...\n",
      "Deploying flow script from \u001b[32m'/Users/particle1331/code/inefficient-networks/docs/n\u001b[0m\n",
      "\u001b[32motebooks/mlops/3-prefect/main.py'\u001b[0m using Local Storage...\n",
      "Created deployment \u001b[34m'deploy-main/\u001b[0m\u001b[1;34mmlflow_staging'\u001b[0m.\n",
      "View your new deployment with: \n",
      "\n",
      "    prefect deployment inspect \u001b[34m'deploy-main/\u001b[0m\u001b[1;34mmlflow_staging'\u001b[0m\n",
      "\u001b[32mCreated 1 deployments!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prefect deployment create mlflow_deploy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that relative imports fails for Prefect deployments, so we had to paste everything in the [`mlflow_deploy.py`](https://github.com/particle1331/inefficient-networks/blob/fbd70bedc69e86a76b722c64cf53a6885b85d2ba/docs/notebooks/mlops/3-prefect/mlflow_deploy.py) script for lack of time. But if we are to do this properly, we have to create a package for the project so imports for our own scripts work everywhere. Also notice that for the sake of simplicity we have the same dataset for each experiment run. Ideally, this should change depending on when the experiment has been run. Otherwise, we are simply staging the same model for each scheduled run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/late-runs.png\n",
    "---\n",
    "---\n",
    "109 runs are now scheduled in Prefect.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow runs are now scheduled in Prefect. Notice that there are late runs. This is because we haven't attached any workers that will run these tasks. Note that unlike CI/CD platforms, all compute happens outside of Prefect that users will have to provide to run the scheduled workflows. We will now create and fire up a **work queue** for our deployment. Note that the setting up can also be done in the UI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                             Deployments                             \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mName                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mID                                  \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[34m \u001b[0m\u001b[34mdeploy-main/\u001b[0m\u001b[1;34mmlflow_staging\u001b[0m\u001b[34m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m1747f0db-9292-4816-b3d4-21b7757e4ef7\u001b[0m\u001b[36m \u001b[0m│\n",
      "└────────────────────────────┴──────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!prefect deployment ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mUUID\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'9aa4a3e0-9590-43fe-988d-956f652b0bc6'\u001b[0m\u001b[1m)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prefect work-queue create \\\n",
    "    --deployment '1747f0db-9292-4816-b3d4-21b7757e4ef7' \\\n",
    "    --flow-runner subprocess \\\n",
    "    mlflow-deploy-runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mScheduled St…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mRun ID                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mName    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDeployment ID          \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m82b034c5-1e08-47f9-a96…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mcinnamo…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mf3383b88-ac26-44ce-949…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mvigorou…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m481e85dc-0cad-4145-8d7…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32maspirin…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m4a502fde-21bf-43ee-a09…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mhot-tar…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m645a1432-7d1c-4972-98c…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mrose-ma…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mfa4a442c-5b92-4fab-8b6…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mvermili…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m2b5ed1c0-612d-4a83-902…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mhot-cai…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m1b9a8e7d-96fa-4451-aaf…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mstylish…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m74d4945f-5e1b-42e2-8df…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32maquamar…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "│\u001b[33m \u001b[0m\u001b[33m2022-06-11 1…\u001b[0m\u001b[33m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m7e2dc0ac-32e5-4dc1-a24…\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mbrawny-…\u001b[0m\u001b[32m \u001b[0m│\u001b[34m \u001b[0m\u001b[34m1747f0db-9292-4816-b3d…\u001b[0m\u001b[34m \u001b[0m│\n",
      "└───────────────┴─────────────────────────┴──────────┴─────────────────────────┘\n",
      "\u001b[31m                            (**) denotes a late run                             \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prefect work-queue preview 9aa4a3e0-9590-43fe-988d-956f652b0bc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent with ephemeral API...\n",
      "\n",
      "  ___ ___ ___ ___ ___ ___ _____     _   ___ ___ _  _ _____\n",
      " | _ \\ _ \\ __| __| __/ __|_   _|   /_\\ / __| __| \\| |_   _|\n",
      " |  _/   / _|| _|| _| (__  | |    / _ \\ (_ | _|| .` | | |\n",
      " |_| |_|_\\___|_| |___\\___| |_|   /_/ \\_\\___|___|_|\\_| |_|\n",
      "\n",
      "\n",
      "Agent started! Looking for work from queue \n",
      "'9aa4a3e0-9590-43fe-988d-956f652b0bc6'...\n",
      "04:08:50.216 | INFO    | prefect.agent - Submitting flow run '5f8c7d3c-8b41-4c22-b030-c8b65a871ea8'\n",
      "04:08:55.230 | INFO    | prefect.agent - Submitting flow run '5f8c7d3c-8b41-4c22-b030-c8b65a871ea8'\n",
      "04:08:59.266 | INFO    | prefect.flow_runner.subprocess - Opening subprocess for flow run '5f8c7d3c-8b41-4c22-b030-c8b65a871ea8'...\n",
      "04:08:59.278 | INFO    | prefect.agent - Completed submission of flow run '5f8c7d3c-8b41-4c22-b030-c8b65a871ea8'\n",
      "04:09:02.289 | INFO    | Flow run 'sociable-finch' - Using task runner 'SequentialTaskRunner'\n",
      "2022/06/12 04:09:02 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment-2022-06-12 04:07:55.615296' does not exist. Creating a new experiment.\n",
      "04:09:02.404 | INFO    | Flow run 'sociable-finch' - Created subflow run 'notorious-gerbil' for flow 'preprocess-data'\n",
      "04:09:02.443 | INFO    | Flow run 'notorious-gerbil' - Created task run 'load_training_dataframe-4335dacd-0' for task 'load_training_dataframe'\n",
      "04:09:02.471 | INFO    | Flow run 'notorious-gerbil' - Created task run 'load_training_dataframe-4335dacd-1' for task 'load_training_dataframe'\n",
      "04:09:02.561 | INFO    | Flow run 'notorious-gerbil' - Created task run 'fit_preprocessor-5181a278-0' for task 'fit_preprocessor'\n",
      "04:09:02.612 | INFO    | Flow run 'notorious-gerbil' - Created task run 'create_model_features-3b628d84-0' for task 'create_model_features'\n",
      "04:09:03.405 | INFO    | Task run 'load_training_dataframe-4335dacd-1' - Finished in state Completed()\n",
      "04:09:03.863 | INFO    | Task run 'load_training_dataframe-4335dacd-0' - Finished in state Completed()\n",
      "04:09:04.662 | INFO    | Task run 'fit_preprocessor-5181a278-0' - Finished in state Completed()\n",
      "04:09:05.250 | INFO    | Task run 'create_model_features-3b628d84-0' - Finished in state Completed()\n",
      "04:09:05.320 | INFO    | Flow run 'notorious-gerbil' - Finished in state Completed()\n",
      "04:09:05.333 | INFO    | Flow run 'sociable-finch' - Created task run 'linreg_runs-f65b5121-0' for task 'linreg_runs'\n",
      "/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "04:09:11.843 | INFO    | Task run 'linreg_runs-f65b5121-0' - Finished in state Completed()\n",
      "04:09:11.858 | INFO    | Flow run 'sociable-finch' - Created task run 'xgboost_runs-df0e77b4-0' for task 'xgboost_runs'\n",
      "[0]\tvalidation-rmse:19.84237                          \n",
      "[1]\tvalidation-rmse:18.60441                          \n",
      "[2]\tvalidation-rmse:17.47036                          \n",
      "[3]\tvalidation-rmse:16.43342                          \n",
      "[4]\tvalidation-rmse:15.48489                          \n",
      "[5]\tvalidation-rmse:14.61940                          \n",
      "[6]\tvalidation-rmse:13.82969                          \n",
      "[7]\tvalidation-rmse:13.11067                          \n",
      "[8]\tvalidation-rmse:12.45682                          \n",
      "[9]\tvalidation-rmse:11.86479                          \n",
      "[10]\tvalidation-rmse:11.32633                         \n",
      "[11]\tvalidation-rmse:10.83953                         \n",
      "[12]\tvalidation-rmse:10.39990                         \n",
      "[13]\tvalidation-rmse:10.00368                         \n",
      "[14]\tvalidation-rmse:9.64656                          \n",
      "[15]\tvalidation-rmse:9.32533                          \n",
      "[16]\tvalidation-rmse:9.03705                          \n",
      "[17]\tvalidation-rmse:8.77765                          \n",
      "[18]\tvalidation-rmse:8.54531                          \n",
      "[19]\tvalidation-rmse:8.33642                          \n",
      "[20]\tvalidation-rmse:8.15072                          \n",
      "[21]\tvalidation-rmse:7.98464                          \n",
      "[22]\tvalidation-rmse:7.83629                          \n",
      "[23]\tvalidation-rmse:7.70306                          \n",
      "[24]\tvalidation-rmse:7.58389                          \n",
      "[25]\tvalidation-rmse:7.47784                          \n",
      "[26]\tvalidation-rmse:7.38301                          \n",
      "[27]\tvalidation-rmse:7.29761                          \n",
      "[28]\tvalidation-rmse:7.22127                          \n",
      "[29]\tvalidation-rmse:7.15316                          \n",
      "[30]\tvalidation-rmse:7.09193                          \n",
      "[31]\tvalidation-rmse:7.03742                          \n",
      "[32]\tvalidation-rmse:6.98802                          \n",
      "[33]\tvalidation-rmse:6.94369                          \n",
      "[34]\tvalidation-rmse:6.90369                          \n",
      "[35]\tvalidation-rmse:6.86811                          \n",
      "[36]\tvalidation-rmse:6.83613                          \n",
      "[37]\tvalidation-rmse:6.80716                          \n",
      "[38]\tvalidation-rmse:6.77962                          \n",
      "[39]\tvalidation-rmse:6.75586                          \n",
      "[40]\tvalidation-rmse:6.73406                          \n",
      "[41]\tvalidation-rmse:6.71404                          \n",
      "[42]\tvalidation-rmse:6.69559                          \n",
      "[43]\tvalidation-rmse:6.67943                          \n",
      "[44]\tvalidation-rmse:6.66454                          \n",
      "[45]\tvalidation-rmse:6.65145                          \n",
      "[46]\tvalidation-rmse:6.63861                          \n",
      "[47]\tvalidation-rmse:6.62732                          \n",
      "[48]\tvalidation-rmse:6.61733                          \n",
      "[49]\tvalidation-rmse:6.60831                          \n",
      "[50]\tvalidation-rmse:6.60016                          \n",
      "[51]\tvalidation-rmse:6.59197                          \n",
      "[52]\tvalidation-rmse:6.58423                          \n",
      "[53]\tvalidation-rmse:6.57788                          \n",
      "[54]\tvalidation-rmse:6.57146                          \n",
      "[55]\tvalidation-rmse:6.56546                          \n",
      "[56]\tvalidation-rmse:6.55992                          \n",
      "[57]\tvalidation-rmse:6.55536                          \n",
      "[58]\tvalidation-rmse:6.55127                          \n",
      "[59]\tvalidation-rmse:6.54748                          \n",
      "[60]\tvalidation-rmse:6.54414                          \n",
      "[61]\tvalidation-rmse:6.54104                          \n",
      "[62]\tvalidation-rmse:6.53799                          \n",
      "[63]\tvalidation-rmse:6.53559                          \n",
      "[64]\tvalidation-rmse:6.53299                          \n",
      "[65]\tvalidation-rmse:6.53081                          \n",
      "[66]\tvalidation-rmse:6.52854                          \n",
      "[67]\tvalidation-rmse:6.52701                          \n",
      "[68]\tvalidation-rmse:6.52508                          \n",
      "[69]\tvalidation-rmse:6.52342                          \n",
      "[70]\tvalidation-rmse:6.52156                          \n",
      "[71]\tvalidation-rmse:6.51974                          \n",
      "[72]\tvalidation-rmse:6.51817                          \n",
      "[73]\tvalidation-rmse:6.51631                          \n",
      "[74]\tvalidation-rmse:6.51472                          \n",
      "[75]\tvalidation-rmse:6.51340                          \n",
      "[76]\tvalidation-rmse:6.51194                          \n",
      "[77]\tvalidation-rmse:6.51071                          \n",
      "[78]\tvalidation-rmse:6.50947                          \n",
      "[79]\tvalidation-rmse:6.50833                          \n",
      "[80]\tvalidation-rmse:6.50698                          \n",
      "[81]\tvalidation-rmse:6.50596                          \n",
      "[82]\tvalidation-rmse:6.50465                          \n",
      "[83]\tvalidation-rmse:6.50392                          \n",
      "[84]\tvalidation-rmse:6.50287                          \n",
      "[85]\tvalidation-rmse:6.50195                          \n",
      "[86]\tvalidation-rmse:6.50093                          \n",
      "[87]\tvalidation-rmse:6.49981                          \n",
      "[88]\tvalidation-rmse:6.49884                          \n",
      "[89]\tvalidation-rmse:6.49827                          \n",
      "[90]\tvalidation-rmse:6.49697                          \n",
      "[91]\tvalidation-rmse:6.49622                          \n",
      "[92]\tvalidation-rmse:6.49534                          \n",
      "[93]\tvalidation-rmse:6.49457                          \n",
      "[94]\tvalidation-rmse:6.49379                          \n",
      "[95]\tvalidation-rmse:6.49269                          \n",
      "[96]\tvalidation-rmse:6.49209                          \n",
      "[97]\tvalidation-rmse:6.49080                          \n",
      "[98]\tvalidation-rmse:6.48982                          \n",
      "[99]\tvalidation-rmse:6.48922                          \n",
      "[0]\tvalidation-rmse:19.78082                                                   \n",
      "[1]\tvalidation-rmse:18.49134                                                   \n",
      "[2]\tvalidation-rmse:17.31483                                                   \n",
      "[3]\tvalidation-rmse:16.24289                                                   \n",
      "[4]\tvalidation-rmse:15.26716                                                   \n",
      "[5]\tvalidation-rmse:14.38062                                                   \n",
      "[6]\tvalidation-rmse:13.57565                                                   \n",
      "[7]\tvalidation-rmse:12.84635                                                   \n",
      "[8]\tvalidation-rmse:12.18808                                                   \n",
      "[9]\tvalidation-rmse:11.59234                                                   \n",
      "[10]\tvalidation-rmse:11.05572                                                  \n",
      "[11]\tvalidation-rmse:10.57297                                                  \n",
      "[12]\tvalidation-rmse:10.13933                                                  \n",
      "[13]\tvalidation-rmse:9.75004                                                   \n",
      "[14]\tvalidation-rmse:9.40108                                                   \n",
      "[15]\tvalidation-rmse:9.08993                                                   \n",
      "[16]\tvalidation-rmse:8.81208                                                   \n",
      "[17]\tvalidation-rmse:8.56425                                                   \n",
      "[18]\tvalidation-rmse:8.34367                                                   \n",
      "[19]\tvalidation-rmse:8.14712                                                   \n",
      "[20]\tvalidation-rmse:7.97230                                                   \n",
      "[21]\tvalidation-rmse:7.81708                                                   \n",
      "[22]\tvalidation-rmse:7.67884                                                   \n",
      "[23]\tvalidation-rmse:7.55618                                                   \n",
      "[24]\tvalidation-rmse:7.44752                                                   \n",
      "[25]\tvalidation-rmse:7.35031                                                   \n",
      "[26]\tvalidation-rmse:7.26430                                                   \n",
      "[27]\tvalidation-rmse:7.18780                                                   \n",
      "[28]\tvalidation-rmse:7.12007                                                   \n",
      "[29]\tvalidation-rmse:7.05884                                                   \n",
      "[30]\tvalidation-rmse:7.00453                                                   \n",
      "[31]\tvalidation-rmse:6.95621                                                   \n",
      "[32]\tvalidation-rmse:6.91304                                                   \n",
      "[33]\tvalidation-rmse:6.87418                                                   \n",
      "[34]\tvalidation-rmse:6.83984                                                   \n",
      "[35]\tvalidation-rmse:6.80854                                                   \n",
      "[36]\tvalidation-rmse:6.78031                                                   \n",
      "[37]\tvalidation-rmse:6.75439                                                   \n",
      "[38]\tvalidation-rmse:6.73180                                                   \n",
      "[39]\tvalidation-rmse:6.71117                                                   \n",
      "[40]\tvalidation-rmse:6.69229                                                   \n",
      "[41]\tvalidation-rmse:6.67463                                                   \n",
      "[42]\tvalidation-rmse:6.65916                                                   \n",
      "[43]\tvalidation-rmse:6.64500                                                   \n",
      "[44]\tvalidation-rmse:6.63261                                                   \n",
      "[45]\tvalidation-rmse:6.62101                                                   \n",
      "[46]\tvalidation-rmse:6.60974                                                   \n",
      "[47]\tvalidation-rmse:6.60063                                                   \n",
      "[48]\tvalidation-rmse:6.59163                                                   \n",
      "[49]\tvalidation-rmse:6.58375                                                   \n",
      "[50]\tvalidation-rmse:6.57576                                                   \n",
      "[51]\tvalidation-rmse:6.56920                                                   \n",
      "[52]\tvalidation-rmse:6.56277                                                   \n",
      "[53]\tvalidation-rmse:6.55688                                                   \n",
      "[54]\tvalidation-rmse:6.55183                                                   \n",
      "[55]\tvalidation-rmse:6.54687                                                   \n",
      "[56]\tvalidation-rmse:6.54246                                                   \n",
      "[57]\tvalidation-rmse:6.53856                                                   \n",
      "[58]\tvalidation-rmse:6.53443                                                   \n",
      "[59]\tvalidation-rmse:6.53130                                                   \n",
      "[60]\tvalidation-rmse:6.52819                                                   \n",
      "[61]\tvalidation-rmse:6.52536                                                   \n",
      "[62]\tvalidation-rmse:6.52255                                                   \n",
      "[63]\tvalidation-rmse:6.52039                                                   \n",
      "[64]\tvalidation-rmse:6.51815                                                   \n",
      "[65]\tvalidation-rmse:6.51592                                                   \n",
      "[66]\tvalidation-rmse:6.51353                                                   \n",
      "[67]\tvalidation-rmse:6.51145                                                   \n",
      "[68]\tvalidation-rmse:6.50979                                                   \n",
      "[69]\tvalidation-rmse:6.50838                                                   \n",
      "[70]\tvalidation-rmse:6.50575                                                   \n",
      "[71]\tvalidation-rmse:6.50429                                                   \n",
      "[72]\tvalidation-rmse:6.50276                                                   \n",
      "[73]\tvalidation-rmse:6.50096                                                   \n",
      "[74]\tvalidation-rmse:6.49957                                                   \n",
      "[75]\tvalidation-rmse:6.49828                                                   \n",
      "[76]\tvalidation-rmse:6.49719                                                   \n",
      "[77]\tvalidation-rmse:6.49620                                                   \n",
      "[78]\tvalidation-rmse:6.49475                                                   \n",
      "[79]\tvalidation-rmse:6.49337                                                   \n",
      "[80]\tvalidation-rmse:6.49232                                                   \n",
      "[81]\tvalidation-rmse:6.49134                                                   \n",
      "[82]\tvalidation-rmse:6.48986                                                   \n",
      "[83]\tvalidation-rmse:6.48844                                                   \n",
      "[84]\tvalidation-rmse:6.48760                                                   \n",
      "[85]\tvalidation-rmse:6.48673                                                   \n",
      "[86]\tvalidation-rmse:6.48582                                                   \n",
      "[87]\tvalidation-rmse:6.48512                                                   \n",
      "[88]\tvalidation-rmse:6.48416                                                   \n",
      "[89]\tvalidation-rmse:6.48301                                                   \n",
      "[90]\tvalidation-rmse:6.48181                                                   \n",
      "[91]\tvalidation-rmse:6.48116                                                   \n",
      "[92]\tvalidation-rmse:6.48065                                                   \n",
      "[93]\tvalidation-rmse:6.47971                                                   \n",
      "[94]\tvalidation-rmse:6.47896                                                   \n",
      "[95]\tvalidation-rmse:6.47839                                                   \n",
      "[96]\tvalidation-rmse:6.47770                                                   \n",
      "[97]\tvalidation-rmse:6.47697                                                   \n",
      "[98]\tvalidation-rmse:6.47606                                                   \n",
      "[99]\tvalidation-rmse:6.47538                                                   \n",
      "[0]\tvalidation-rmse:15.64095                                                   \n",
      "[1]\tvalidation-rmse:12.05903                                                   \n",
      "[2]\tvalidation-rmse:9.82244                                                    \n",
      "[3]\tvalidation-rmse:8.47341                                                    \n",
      "[4]\tvalidation-rmse:7.68264                                                    \n",
      "[5]\tvalidation-rmse:7.22660                                                    \n",
      "[6]\tvalidation-rmse:6.96034                                                    \n",
      "[7]\tvalidation-rmse:6.80055                                                    \n",
      "[8]\tvalidation-rmse:6.70293                                                    \n",
      "[9]\tvalidation-rmse:6.63813                                                    \n",
      "[10]\tvalidation-rmse:6.59265                                                   \n",
      "[11]\tvalidation-rmse:6.56429                                                   \n",
      "[12]\tvalidation-rmse:6.54293                                                   \n",
      "[13]\tvalidation-rmse:6.52894                                                   \n",
      "[14]\tvalidation-rmse:6.51888                                                   \n",
      "[15]\tvalidation-rmse:6.51135                                                   \n",
      "[16]\tvalidation-rmse:6.50611                                                   \n",
      "[17]\tvalidation-rmse:6.50171                                                   \n",
      "[18]\tvalidation-rmse:6.49589                                                   \n",
      "[19]\tvalidation-rmse:6.49027                                                   \n",
      "[20]\tvalidation-rmse:6.48742                                                   \n",
      "[21]\tvalidation-rmse:6.48506                                                   \n",
      "[22]\tvalidation-rmse:6.48326                                                   \n",
      "[23]\tvalidation-rmse:6.48047                                                   \n",
      "[24]\tvalidation-rmse:6.47771                                                   \n",
      "[25]\tvalidation-rmse:6.47397                                                   \n",
      "[26]\tvalidation-rmse:6.47105                                                   \n",
      "[27]\tvalidation-rmse:6.46951                                                   \n",
      "[28]\tvalidation-rmse:6.46745                                                   \n",
      "[29]\tvalidation-rmse:6.46443                                                   \n",
      "[30]\tvalidation-rmse:6.46339                                                   \n",
      "[31]\tvalidation-rmse:6.46127                                                   \n",
      "[32]\tvalidation-rmse:6.46035                                                   \n",
      "[33]\tvalidation-rmse:6.45978                                                   \n",
      "[34]\tvalidation-rmse:6.45814                                                   \n",
      "[35]\tvalidation-rmse:6.45686                                                   \n",
      "[36]\tvalidation-rmse:6.45520                                                   \n",
      "[37]\tvalidation-rmse:6.45324                                                   \n",
      "[38]\tvalidation-rmse:6.45198                                                   \n",
      "[39]\tvalidation-rmse:6.45068                                                   \n",
      "[40]\tvalidation-rmse:6.44793                                                   \n",
      "[41]\tvalidation-rmse:6.44589                                                   \n",
      "[42]\tvalidation-rmse:6.44392                                                   \n",
      "[43]\tvalidation-rmse:6.44255                                                   \n",
      "[44]\tvalidation-rmse:6.44177                                                   \n",
      "[45]\tvalidation-rmse:6.44060                                                   \n",
      "[46]\tvalidation-rmse:6.44022                                                   \n",
      "[47]\tvalidation-rmse:6.43943                                                   \n",
      "[48]\tvalidation-rmse:6.43836                                                   \n",
      "[49]\tvalidation-rmse:6.43734                                                   \n",
      "[50]\tvalidation-rmse:6.43648                                                   \n",
      "[51]\tvalidation-rmse:6.43462                                                   \n",
      "[52]\tvalidation-rmse:6.43304                                                   \n",
      "[53]\tvalidation-rmse:6.43210                                                   \n",
      "[54]\tvalidation-rmse:6.43118                                                   \n",
      "[55]\tvalidation-rmse:6.43001                                                   \n",
      "[56]\tvalidation-rmse:6.42874                                                   \n",
      "[57]\tvalidation-rmse:6.42779                                                   \n",
      "[58]\tvalidation-rmse:6.42725                                                   \n",
      "[59]\tvalidation-rmse:6.42673                                                   \n",
      "[60]\tvalidation-rmse:6.42623                                                   \n",
      "[61]\tvalidation-rmse:6.42569                                                   \n",
      "[62]\tvalidation-rmse:6.42501                                                   \n",
      "[63]\tvalidation-rmse:6.42365                                                   \n",
      "[64]\tvalidation-rmse:6.42289                                                   \n",
      "[65]\tvalidation-rmse:6.42186                                                   \n",
      "[66]\tvalidation-rmse:6.42167                                                   \n",
      "[67]\tvalidation-rmse:6.42138                                                   \n",
      " 20%|██        | 2/10 [00:40<02:14, 16.76s/trial, best loss: 6.475380867081452]04:09:52.566 | INFO    | prefect.agent - Submitting flow run 'bb1d47f4-2b2a-44b8-b869-d7c23796fda7'\n",
      "[68]\tvalidation-rmse:6.42047                                                   \n",
      "[69]\tvalidation-rmse:6.41966                                                   \n",
      "[70]\tvalidation-rmse:6.41857                                                   \n",
      "[71]\tvalidation-rmse:6.41848                                                   \n",
      "[72]\tvalidation-rmse:6.41770                                                   \n",
      "[73]\tvalidation-rmse:6.41695                                                   \n",
      "[74]\tvalidation-rmse:6.41642                                                   \n",
      "[75]\tvalidation-rmse:6.41571                                                   \n",
      "[76]\tvalidation-rmse:6.41512                                                   \n",
      "[77]\tvalidation-rmse:6.41397                                                   \n",
      "[78]\tvalidation-rmse:6.41252                                                   \n",
      "[79]\tvalidation-rmse:6.41146                                                   \n",
      "[80]\tvalidation-rmse:6.41115                                                   \n",
      "[81]\tvalidation-rmse:6.41079                                                   \n",
      "[82]\tvalidation-rmse:6.40998                                                   \n",
      "[83]\tvalidation-rmse:6.40929                                                   \n",
      "[84]\tvalidation-rmse:6.40924                                                   \n",
      "[85]\tvalidation-rmse:6.40873                                                   \n",
      "[86]\tvalidation-rmse:6.40824                                                   \n",
      "[87]\tvalidation-rmse:6.40765                                                   \n",
      "[88]\tvalidation-rmse:6.40741                                                   \n",
      "[89]\tvalidation-rmse:6.40702                                                   \n",
      "[90]\tvalidation-rmse:6.40650                                                   \n",
      "[91]\tvalidation-rmse:6.40639                                                   \n",
      "[92]\tvalidation-rmse:6.40629                                                   \n",
      "[93]\tvalidation-rmse:6.40620                                                   \n",
      "[94]\tvalidation-rmse:6.40567                                                   \n",
      "[95]\tvalidation-rmse:6.40517                                                   \n",
      "[96]\tvalidation-rmse:6.40462                                                   \n",
      "[97]\tvalidation-rmse:6.40454                                                   \n",
      "[98]\tvalidation-rmse:6.40398                                                   \n",
      "[99]\tvalidation-rmse:6.40381                                                   \n",
      " 20%|██        | 2/10 [00:44<02:14, 16.76s/trial, best loss: 6.475380867081452]04:09:57.699 | INFO    | prefect.agent - Submitting flow run 'bb1d47f4-2b2a-44b8-b869-d7c23796fda7'\n",
      "04:10:00.224 | INFO    | prefect.flow_runner.subprocess - Opening subprocess for flow run 'bb1d47f4-2b2a-44b8-b869-d7c23796fda7'...\n",
      "04:10:00.244 | INFO    | prefect.agent - Completed submission of flow run 'bb1d47f4-2b2a-44b8-b869-d7c23796fda7'\n",
      "04:10:19.730 | ERROR   | prefect.engine - Engine execution of flow run 'bb1d47f4-2b2a-44b8-b869-d7c23796fda7' exited with unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/asgi_lifespan/_concurrency/asyncio.py\", line 17, in wait\n",
      "    await self._event.wait()\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/asyncio/locks.py\", line 226, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/asyncio/tasks.py\", line 490, in wait_for\n",
      "    return fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/asgi_lifespan/_concurrency/asyncio.py\", line 44, in run_and_fail_after\n",
      "    await asyncio.wait_for(coroutine(), timeout=seconds)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/asyncio/tasks.py\", line 492, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/engine.py\", line 985, in <module>\n",
      "    enter_flow_run_engine_from_subprocess(flow_run_id)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/engine.py\", line 130, in enter_flow_run_engine_from_subprocess\n",
      "    return anyio.run(retrieve_flow_then_begin_flow_run, flow_run_id)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_core/_eventloop.py\", line 70, in run\n",
      "    return asynclib.run(func, *args, **backend_options)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 292, in run\n",
      "    return native_run(wrapper(), debug=debug)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 287, in wrapper\n",
      "    return await func(*args)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/client.py\", line 93, in with_injected_client\n",
      "    async with client_context as client:\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/client.py\", line 1800, in __aenter__\n",
      "    self._ephemeral_lifespan = await self._exit_stack.enter_async_context(\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/contextlib.py\", line 575, in enter_async_context\n",
      "    result = await _cm_type.__aenter__(cm)\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/contextlib.py\", line 181, in __aenter__\n",
      "    return await self.gen.__anext__()\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/prefect/client.py\", line 174, in app_lifespan_context\n",
      "    await context.__aenter__()\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/asgi_lifespan/_manager.py\", line 90, in __aenter__\n",
      "    await self.startup()\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/asgi_lifespan/_manager.py\", line 31, in startup\n",
      "    await self._concurrency_backend.run_and_fail_after(\n",
      "  File \"/Users/particle1331/miniforge3/envs/prefect/lib/python3.9/site-packages/asgi_lifespan/_concurrency/asyncio.py\", line 46, in run_and_fail_after\n",
      "    raise TimeoutError\n",
      "TimeoutError\n",
      "04:10:23.844 | ERROR   | prefect.flow_runner.subprocess - Subprocess for flow run 'bb1d47f4-2b2a-44b8-b869-d7c23796fda7' exited with bad code: 1\n",
      "[0]\tvalidation-rmse:8.26741                                                    \n",
      "[1]\tvalidation-rmse:6.89307                                                    \n",
      "[2]\tvalidation-rmse:6.72190                                                    \n",
      "[3]\tvalidation-rmse:6.68746                                                    \n",
      "[4]\tvalidation-rmse:6.67360                                                    \n",
      "[5]\tvalidation-rmse:6.66649                                                    \n",
      "[6]\tvalidation-rmse:6.66497                                                    \n",
      "[7]\tvalidation-rmse:6.66094                                                    \n",
      "[8]\tvalidation-rmse:6.65788                                                    \n",
      "[9]\tvalidation-rmse:6.65634                                                    \n",
      "[10]\tvalidation-rmse:6.65305                                                   \n",
      "[11]\tvalidation-rmse:6.65026                                                   \n",
      "[12]\tvalidation-rmse:6.64815                                                   \n",
      "[13]\tvalidation-rmse:6.64523                                                   \n",
      "[14]\tvalidation-rmse:6.63980                                                   \n",
      "[15]\tvalidation-rmse:6.63841                                                   \n",
      "[16]\tvalidation-rmse:6.63948                                                   \n",
      "[17]\tvalidation-rmse:6.63887                                                   \n",
      "[18]\tvalidation-rmse:6.63878                                                   \n",
      "[19]\tvalidation-rmse:6.63656                                                   \n",
      "[20]\tvalidation-rmse:6.62872                                                   \n",
      "[21]\tvalidation-rmse:6.62310                                                   \n",
      "[22]\tvalidation-rmse:6.62088                                                   \n",
      "[23]\tvalidation-rmse:6.62033                                                   \n",
      "[24]\tvalidation-rmse:6.61547                                                   \n",
      "[25]\tvalidation-rmse:6.61294                                                   \n",
      "[26]\tvalidation-rmse:6.61136                                                   \n",
      "[27]\tvalidation-rmse:6.60706                                                   \n",
      "[28]\tvalidation-rmse:6.60430                                                   \n",
      "[29]\tvalidation-rmse:6.60173                                                   \n",
      "[30]\tvalidation-rmse:6.60164                                                   \n",
      "[31]\tvalidation-rmse:6.60167                                                   \n",
      "[32]\tvalidation-rmse:6.59880                                                   \n",
      "[33]\tvalidation-rmse:6.59832                                                   \n",
      "[34]\tvalidation-rmse:6.59802                                                   \n",
      "[35]\tvalidation-rmse:6.59865                                                   \n",
      "[36]\tvalidation-rmse:6.59788                                                   \n",
      "[37]\tvalidation-rmse:6.59700                                                   \n",
      "[38]\tvalidation-rmse:6.59408                                                   \n",
      "[39]\tvalidation-rmse:6.59562                                                   \n",
      "[40]\tvalidation-rmse:6.59052                                                   \n",
      "[41]\tvalidation-rmse:6.58833                                                   \n",
      "[42]\tvalidation-rmse:6.58397                                                   \n",
      "[43]\tvalidation-rmse:6.58171                                                   \n",
      "[44]\tvalidation-rmse:6.58185                                                   \n",
      "[45]\tvalidation-rmse:6.57997                                                   \n",
      "[46]\tvalidation-rmse:6.57705                                                   \n",
      "[47]\tvalidation-rmse:6.57466                                                   \n",
      "[48]\tvalidation-rmse:6.57922                                                   \n",
      "[49]\tvalidation-rmse:6.57755                                                   \n",
      "[50]\tvalidation-rmse:6.57726                                                   \n",
      "[51]\tvalidation-rmse:6.57598                                                   \n",
      " 30%|███       | 3/10 [01:36<04:07, 35.37s/trial, best loss: 6.403814453097733]^C\n"
     ]
    }
   ],
   "source": [
    "!prefect agent start 9aa4a3e0-9590-43fe-988d-956f652b0bc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "345667e5aa1587f3f99ee9b59f54516e1e87c18189e42869047387925519f8a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('prefect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
