{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking and Model Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n",
    "\n",
    "<!-- Place this tag where you want the button to render. -->\n",
    "<a class=\"github-button\" href=\"https://github.com/particle1331/steepest-ascent\" data-color-scheme=\"no-preference: dark; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star particle1331/steepest-ascent on GitHub\">Star</a>\n",
    "<!-- Place this tag in your head or just before your close body tag. -->\n",
    "<script async defer src=\"https://buttons.github.io/buttons.js\"></script> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will look **experiment tracking** and **model management**. A machine learning experiment is defined as a session or process of making machine learning models. Experiment tracking is the process of keeping track of all relevant information in an experiments. This includes source code, environment, data, models, hyperparameters, and so on which are important for reproducing the experiment as well as for making actual predictions. \n",
    "\n",
    "From experience, we know that manual tracking, e.g. with spreadsheets, is error prone, not standardized, has low visibility, and difficult for teams to collaborate over. As an alternative, we will experiment tracking platforms such as [MLFlow](https://mlflow.org/). MLFlow has four main components: tracking, models, model registry, and projects. In this course, we only be cover the first three. \n",
    "\n",
    "```{margin}\n",
    "⚠️ **Attribution:** These are notes for [Module 2](https://github.com/DataTalksClub/mlops-zoomcamp/tree/main/02-experiment-tracking) of the [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp). The MLOps Zoomcamp is a free course from [DataTalks.Club](https://github.com/DataTalksClub).\n",
    "```\n",
    "\n",
    "As we have seen with our previous prototyping, having the ability to reproduce results is important since we want to have the same results when deploying the model in different environments. Using experiment tracking and model management platforms allows us to have better chance at reproducing our results, as well as aid in organization (staging and deploying models) and optimization (finding the best models). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started: MLFlow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the MLFlow UI with an SQLite backend as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "$ mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "\n",
    "[2022-05-26 19:35:22 +0800] [92498] [INFO] Starting gunicorn 20.1.0\n",
    "[2022-05-26 19:35:22 +0800] [92498] [INFO] Listening at: http://127.0.0.1:5000 (92498)\n",
    "[2022-05-26 19:35:22 +0800] [92498] [INFO] Using worker: sync\n",
    "[2022-05-26 19:35:22 +0800] [92499] [INFO] Booting worker with pid: 92499\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our experiment, we will use our code and data from [Module 1](https://particle1331.github.io/inefficient-networks/notebooks/mlops/1-intro.html). So before doing any run, we either create an **experiment** or connect a run to it if the experiment already exists. This also sets the experiment tracking backend. The same one that is visualized in the UI above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`experiment_lr.py`](https://github.com/particle1331/inefficient-networks/blob/mlops/docs/notebooks/mlops/2-mlflow/experiment_lr.py)\n",
    "```\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section of the code executes a **single run** of the experiment. Note the logging at the end of the script. Everything that runs inside the following context is a single run with run name `demo-lasso`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`experiment_lr.py`](https://github.com/particle1331/inefficient-networks/blob/mlops/docs/notebooks/mlops/2-mlflow/experiment_lr.py)\n",
    "```\n",
    "```python\n",
    "with mlflow.start_run(run_name='lr'):\n",
    "\n",
    "    train_data_path = './data/green_tripdata_2021-01.parquet'\n",
    "    valid_data_path = './data/green_tripdata_2021-02.parquet'\n",
    "\n",
    "    # In-between transformations\n",
    "    transforms = [add_pickup_dropoff_pair]\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "\n",
    "    train_dicts, y_train = preprocess_dataset(train_data_path, transforms, categorical, numerical)\n",
    "    valid_dicts, y_valid = preprocess_dataset(valid_data_path, transforms, categorical, numerical)\n",
    "\n",
    "    # Fit all possible categories\n",
    "    dv = DictVectorizer()\n",
    "    dv.fit(train_dicts + valid_dicts)\n",
    "\n",
    "    X_train = dv.transform(train_dicts)\n",
    "    X_valid = dv.transform(valid_dicts)\n",
    "\n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train);\n",
    "\n",
    "    # Plot predictions vs ground truth\n",
    "    fig = plot_duration_distribution(model, X_train, y_train, X_valid, y_valid)\n",
    "    fig.savefig('plot.svg')\n",
    "\n",
    "    # Print metric\n",
    "    rmse_train = mean_squared_error(y_train, model.predict(X_train), squared=False)\n",
    "    rmse_valid = mean_squared_error(y_valid, model.predict(X_valid), squared=False)\n",
    "\n",
    "    # MLFlow logging\n",
    "    mlflow.set_tag(\"author\", \"particle\")\n",
    "    mlflow.log_param('train_data_path', train_data_path)\n",
    "    mlflow.log_param('valid_data_path', valid_data_path)\n",
    "    mlflow.log_metric('rmse_train', rmse_train)\n",
    "    mlflow.log_metric('rmse_valid', rmse_valid)\n",
    "    mlflow.log_artifact('plot.svg')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will reflect in the UI as a single run in the `nyc-tax-experiment` experiment. MLFlow is able to obtain the version from `git` and the user from the system, i.e. the user that is currently logged in. The other values are obtained from the logs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/single-run-mlflow.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we click on the run, we can see more details about it that we logged. Shown here are the date of the run, the user that executed it, total run time, the source code used, as well as the git commit for this code. Status `FINISHED` indicates that the script successfully ran. These are useful metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/single-run-mlflow-details.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the details of the trained model, we have parameters for the data used (only paths, no versioning). Most importantly, we can see the logged RMSEs `5.7` (train) and `7.759` (valid). The plot of the distributions of the true and predicted distributions, which we logged as a training artifact, is also conveniently displayed here. Note that we can make **queries** on the search bar, e.g. filtering runs with specific tags:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/mlflow-filter-tags.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we switch to a more complex XGBoost model and perform hyperparameter optimization using [Hyperopt](https://hyperopt.github.io/hyperopt/). We show how this looks in MLFlow. Note that it is easy to select the best models in an experiment by simply clicking the column header of the metrics. Finally, we look at **autologging** which makes logging simpler for frameworks with MLFlow integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`experiment_xgb.py`](https://github.com/particle1331/inefficient-networks/blob/mlops/docs/notebooks/mlops/2-mlflow/experiment_xgb.py)\n",
    "```\n",
    "```python\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "mlflow.xgboost.autolog(disable=True)\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Compute RMSE. One trial = one run.\"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name='xgb'):\n",
    "        \n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=xgb_train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(xgb_valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "\n",
    "        rmse_valid = mean_squared_error(y_valid, booster.predict(xgb_valid), squared=False)\n",
    "        rmse_train = mean_squared_error(y_train, booster.predict(xgb_train), squared=False)\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"rmse_valid\", rmse_valid)\n",
    "        mlflow.log_metric(\"rmse_train\", rmse_train)\n",
    "        mlflow.xgboost.log_model(booster, 'xgb-model')\n",
    "        mlflow.set_tag('model', 'xgboost')\n",
    "\n",
    "    return {'loss': rmse_valid, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "\n",
    "# Perform 50 runs with TPE algo\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_datasets\n",
    "train_data_path = '../data/green_tripdata_2021-01.parquet'\n",
    "valid_data_path = '../data/green_tripdata_2021-02.parquet'\n",
    "X_train, y_train, X_valid, y_valid = set_datasets(train_data_path, valid_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c69054bf84d6ad36c63a02b926ed0729b159d9b327d6020e8e7aee9c3ae1ac1f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
