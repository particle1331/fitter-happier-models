{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Ensembling: Blending and Stacking"],"metadata":{}},{"cell_type":"markdown","source":["In this notebook, we demonstrate how blending and stacking of machine learning models can improve scores of individual models such that the whole is greater than its parts. Recall that we need models to be as uncorrelated as possible for this to work well. We show that stacking mainly requires good cross-validation strategy between levels of prediction. In particular, we show that maintaining the same cross-validation folds between levels minimizes overfitting."],"metadata":{}},{"cell_type":"code","execution_count":156,"source":["import pandas as pd\n","import numpy as np\n","from sklearn import model_selection, linear_model, metrics, decomposition, ensemble\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from scipy.optimize import fmin\n","from functools import partial\n","from xgboost import XGBClassifier\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.base import BaseEstimator, TransformerMixin"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T19:48:09.242991Z","iopub.execute_input":"2021-08-21T19:48:09.243347Z","iopub.status.idle":"2021-08-21T19:48:09.249811Z","shell.execute_reply.started":"2021-08-21T19:48:09.243318Z","shell.execute_reply":"2021-08-21T19:48:09.248720Z"},"trusted":true}},{"cell_type":"markdown","source":["## Getting the Dataset"],"metadata":{}},{"cell_type":"markdown","source":["We do not really care too much about the dataset. The dataset used here is particularly nice. No issues. Idea is that we have text data in the form of a movie review, along with its sentiment classification. We will build a **sentiment classifier** using an ensemble of three models."],"metadata":{}},{"cell_type":"code","execution_count":157,"source":["df = pd.read_csv('../input/kumarmanoj-bag-of-words-meets-bags-of-popcorn/labeledTrainData.tsv', \n","                 sep='\\t', encoding='ISO-8859-1')\n","df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       id  sentiment                                             review\n","0  5814_8          1  With all this stuff going down at the moment w...\n","1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n","2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n","3  3630_4          0  It must be assumed that those who praised this...\n","4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5814_8</td>\n","      <td>1</td>\n","      <td>With all this stuff going down at the moment w...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2381_9</td>\n","      <td>1</td>\n","      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7759_3</td>\n","      <td>0</td>\n","      <td>The film starts with a manager (Nicholas Bell)...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3630_4</td>\n","      <td>0</td>\n","      <td>It must be assumed that those who praised this...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9495_8</td>\n","      <td>1</td>\n","      <td>Superbly trashy and wondrously unpretentious 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":157}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.257148Z","iopub.execute_input":"2021-08-21T19:48:09.257514Z","iopub.status.idle":"2021-08-21T19:48:09.597517Z","shell.execute_reply.started":"2021-08-21T19:48:09.257480Z","shell.execute_reply":"2021-08-21T19:48:09.596352Z"},"trusted":true}},{"cell_type":"code","execution_count":158,"source":["len(df)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["25000"]},"metadata":{},"execution_count":158}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.599439Z","iopub.execute_input":"2021-08-21T19:48:09.599867Z","iopub.status.idle":"2021-08-21T19:48:09.607326Z","shell.execute_reply.started":"2021-08-21T19:48:09.599806Z","shell.execute_reply":"2021-08-21T19:48:09.606546Z"},"trusted":true}},{"cell_type":"markdown","source":["## Creating Cross-Validation Folds"],"metadata":{}},{"cell_type":"markdown","source":["Here we create cross-validation folds. Very important for evaluating models, and creating Level 1 features that are not overfitted."],"metadata":{}},{"cell_type":"code","execution_count":159,"source":["df.loc[:, 'kfold'] = -1 \n","df = df.sample(frac=1.0).reset_index(drop=True)\n","y = df['sentiment'].values\n","\n","skf = model_selection.StratifiedKFold(n_splits=6)\n","for f, (t_, v_) in enumerate(skf.split(X=df, y=y)):\n","    df.loc[v_, \"kfold\"] = f"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.608966Z","iopub.execute_input":"2021-08-21T19:48:09.609272Z","iopub.status.idle":"2021-08-21T19:48:09.634341Z","shell.execute_reply.started":"2021-08-21T19:48:09.609243Z","shell.execute_reply":"2021-08-21T19:48:09.633357Z"},"trusted":true}},{"cell_type":"code","execution_count":160,"source":["df.kfold.value_counts()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    4167\n","1    4167\n","2    4167\n","3    4167\n","4    4166\n","5    4166\n","Name: kfold, dtype: int64"]},"metadata":{},"execution_count":160}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.635933Z","iopub.execute_input":"2021-08-21T19:48:09.636227Z","iopub.status.idle":"2021-08-21T19:48:09.644146Z","shell.execute_reply.started":"2021-08-21T19:48:09.636199Z","shell.execute_reply":"2021-08-21T19:48:09.642950Z"},"trusted":true}},{"cell_type":"code","execution_count":161,"source":["df_test = df[df.kfold == 5]\n","df = df[df.kfold < 5]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.645422Z","iopub.execute_input":"2021-08-21T19:48:09.645716Z","iopub.status.idle":"2021-08-21T19:48:09.661508Z","shell.execute_reply.started":"2021-08-21T19:48:09.645688Z","shell.execute_reply":"2021-08-21T19:48:09.660469Z"},"trusted":true}},{"cell_type":"markdown","source":["## Training Base Models"],"metadata":{}},{"cell_type":"markdown","source":["We train three models that we use to make Level 1 predictions. The resulting feature set will be three probability columns for the positive class generated by these base models. First, let us define some helper functions and custom transformers so we can easily create pipelines which take in the whole train and test dataframes without having worrying about correct format."],"metadata":{}},{"cell_type":"code","execution_count":162,"source":["class TfidfVectorizerPreprocessor(BaseEstimator, TransformerMixin):\n","    def __init__(self, max_features):\n","        self.tfv = TfidfVectorizer(max_features=max_features)\n","        \n","    def fit(self, X, y=None):\n","        self.tfv.fit(X.review)\n","        return self\n","    \n","    def transform(self, X):\n","        return self.tfv.transform(X.review)\n","    \n","    \n","class CountVectorizerPreprocessor(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        self.cvec = CountVectorizer()\n","        \n","    def fit(self, X, y=None):\n","        self.cvec.fit(X.review)\n","        return self\n","    \n","    def transform(self, X):\n","        return self.cvec.transform(X.review)\n","    \n","    \n","class TruncatedSVDPreprocessor(BaseEstimator, TransformerMixin):\n","    def __init__(self, n_components):\n","        self.svd = decomposition.TruncatedSVD(n_components=n_components)\n","        \n","    def fit(self, X, y=None):\n","        self.svd.fit(X)\n","        return self\n","    \n","    def transform(self, X):\n","        return self.svd.transform(X)\n","    \n","\n","class StandardScalerPreprocessor(BaseEstimator, TransformerMixin):\n","    def __init__(self, cols):\n","        self.sc = StandardScaler()\n","        self.cols = cols\n","        \n","    def fit(self, X, y=None):\n","        self.sc.fit(X[self.cols])\n","        return self\n","    \n","    def transform(self, X):\n","        return self.sc.transform(X[self.cols])\n","        \n","        \n","class LinearRegressionModel(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        self.lr = linear_model.LinearRegression()\n","    \n","    def fit(self, X, y=None):\n","        self.lr.fit(X, y)\n","        \n","    def predict_proba(self, X):\n","        return np.c_[self.lr.predict(X), self.lr.predict(X)]      "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.663054Z","iopub.execute_input":"2021-08-21T19:48:09.663366Z","iopub.status.idle":"2021-08-21T19:48:09.684599Z","shell.execute_reply.started":"2021-08-21T19:48:09.663336Z","shell.execute_reply":"2021-08-21T19:48:09.683521Z"},"trusted":true}},{"cell_type":"markdown","source":["We also define `stack_oof_preds` which adds one column of prediction from a model obtained using out-of-fold predictions which is described in the `oof_predictions` function."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def oof_predictions(model_pipe, model_name, fold):\n","    \"Train on K-1 folds, predict on fold K. Return predictions.\"\n","    \n","    # Get folds\n","    df_train = df[df.kfold != fold].reset_index(drop=True)\n","    df_valid = df[df.kfold == fold].reset_index(drop=True)\n","    \n","    # Fit model\n","    model_pipe.fit(df_train, df_train.sentiment.values)\n","    \n","    # Predict and evaluate model on `fold`\n","    pred = model_pipe.predict_proba(df_valid)[:, 1]    \n","    auc = metrics.roc_auc_score(df_valid.sentiment.values, pred)\n","    \n","    print(f\"fold={fold}, auc={auc}\")\n","    \n","    # Return OOF predictions with ids\n","    df_valid.loc[:, f\"{model_name}_pred\"] = pred\n","    return df_valid[[\"id\", f\"{model_name}_pred\"]]\n","\n","\n","def stack_oof_preds(df, model_pipe, model_name):\n","    \"Append OOF `model_pipe` predictions as new column on dataframe `df`.\"\n","    \n","    # Make OOF predictions for each fold\n","    dfs = []\n","    print(f'{model_name}')\n","    for j in range(5):\n","        temp_df = oof_predictions(model_pipe, model_name, fold=j)\n","        dfs.append(temp_df)\n","    m = pd.concat(dfs)\n","    \n","    # Merge OOF predictions to `df`. Replace if existing (for fast dev cycles in kernel)\n","    if f'{model_name}_pred' in df.columns:\n","        df.drop(f'{model_name}_pred', axis=1, inplace=True)\n","    \n","    df = df.merge(m[['id', f'{model_name}_pred']], on='id', how='left')\n","    return df"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Base model 1: LogReg + TF-IDF"],"metadata":{}},{"cell_type":"code","execution_count":163,"source":["lr_pipe = make_pipeline(\n","    TfidfVectorizerPreprocessor(max_features=1000),\n","    linear_model.LogisticRegression()\n",")\n","\n","df = stack_oof_preds(df, lr_pipe, \"lr\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["lr\n","fold=0, auc=0.9338189695763991\n","fold=1, auc=0.9352750950708735\n","fold=2, auc=0.934032976946177\n","fold=3, auc=0.9285153186889942\n","fold=4, auc=0.9389834586687974\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:48:09.685950Z","iopub.execute_input":"2021-08-21T19:48:09.686259Z","iopub.status.idle":"2021-08-21T19:49:05.728186Z","shell.execute_reply.started":"2021-08-21T19:48:09.686229Z","shell.execute_reply":"2021-08-21T19:49:05.727077Z"},"trusted":true}},{"cell_type":"markdown","source":["### Base model 2: LR + CountVectorizer"],"metadata":{}},{"cell_type":"code","execution_count":164,"source":["lr_cnt_pipe = make_pipeline(\n","    CountVectorizerPreprocessor(),\n","    linear_model.LogisticRegression(solver='liblinear')\n",")\n","\n","df = stack_oof_preds(df, lr_cnt_pipe, \"lr_cnt\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["lr_cnt\n","fold=0, auc=0.9408010464015892\n","fold=1, auc=0.941410587306253\n","fold=2, auc=0.9454018593070861\n","fold=3, auc=0.9435273943255105\n","fold=4, auc=0.9490850077058897\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:49:05.731401Z","iopub.execute_input":"2021-08-21T19:49:05.732040Z","iopub.status.idle":"2021-08-21T19:50:34.418835Z","shell.execute_reply.started":"2021-08-21T19:49:05.731992Z","shell.execute_reply":"2021-08-21T19:50:34.417812Z"},"trusted":true}},{"cell_type":"markdown","source":["### Base model 3: RF + SVD"],"metadata":{}},{"cell_type":"code","execution_count":165,"source":["rf_svd_pipe = make_pipeline(\n","    TfidfVectorizerPreprocessor(max_features=None),\n","    TruncatedSVDPreprocessor(n_components=120),\n","    ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",")\n","\n","df = stack_oof_preds(df, rf_svd_pipe, \"rf_svd\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["rf_svd\n","fold=0, auc=0.8799584517016005\n","fold=1, auc=0.8788462583955851\n","fold=2, auc=0.8775649785347613\n","fold=3, auc=0.8730771587561496\n","fold=4, auc=0.8778902848171503\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:50:34.420644Z","iopub.execute_input":"2021-08-21T19:50:34.420964Z","iopub.status.idle":"2021-08-21T19:52:36.264336Z","shell.execute_reply.started":"2021-08-21T19:50:34.420932Z","shell.execute_reply":"2021-08-21T19:52:36.263364Z"},"trusted":true}},{"cell_type":"markdown","source":["Check correlations:"],"metadata":{}},{"cell_type":"code","execution_count":166,"source":["level1_cols = ['lr_pred', 'lr_cnt_pred', 'rf_svd_pred']\n","pd.DataFrame(df[level1_cols]).corr()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["              lr_pred  lr_cnt_pred  rf_svd_pred\n","lr_pred      1.000000     0.888219     0.828686\n","lr_cnt_pred  0.888219     1.000000     0.723146\n","rf_svd_pred  0.828686     0.723146     1.000000"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_pred</th>\n","      <th>lr_cnt_pred</th>\n","      <th>rf_svd_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>lr_pred</th>\n","      <td>1.000000</td>\n","      <td>0.888219</td>\n","      <td>0.828686</td>\n","    </tr>\n","    <tr>\n","      <th>lr_cnt_pred</th>\n","      <td>0.888219</td>\n","      <td>1.000000</td>\n","      <td>0.723146</td>\n","    </tr>\n","    <tr>\n","      <th>rf_svd_pred</th>\n","      <td>0.828686</td>\n","      <td>0.723146</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":166}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:36.265608Z","iopub.execute_input":"2021-08-21T19:52:36.266030Z","iopub.status.idle":"2021-08-21T19:52:36.282663Z","shell.execute_reply.started":"2021-08-21T19:52:36.265998Z","shell.execute_reply":"2021-08-21T19:52:36.281624Z"},"trusted":true}},{"cell_type":"markdown","source":["## Blending"],"metadata":{}},{"cell_type":"markdown","source":["Here Abishek uses `glob` to get all files, since he saved all DataFrames on disk. \n","\n","```python\n","files = glob.glob(\"../model_preds/*.csv\")\n","df = None\n","for f in files:\n","    if df is None:\n","        df = pd.read_csv(f)\n","    else:\n","        temp_df = pd.read_csv(f)\n","        df = df.merge(temp_df, on=\"id\", how=\"left\")\n","```"],"metadata":{}},{"cell_type":"code","execution_count":167,"source":["target = df.sentiment.values\n","\n","# roc is scale invariant, so we dont bother dividing by total weights\n","avg_preds = (df[level1_cols] * [1, 1, 1]).sum(axis=1)\n","wtd_preds = (df[level1_cols] * [1, 3, 1]).sum(axis=1)\n","rank_avg_preds = (df[level1_cols].rank() * [1, 1, 1]).sum(axis=1)\n","rank_wtd_preds = (df[level1_cols].rank() * [1, 3, 1]).sum(axis=1)\n","\n","print(f\"auc (averaged):\\t\\t\", metrics.roc_auc_score(target, avg_preds))\n","print(f\"auc (wtd. avg):\\t\\t\", metrics.roc_auc_score(target, wtd_preds))\n","print(f\"auc (rank avg):\\t\\t\", metrics.roc_auc_score(target, rank_avg_preds)) \n","print(f\"auc (wtd. rank avg):\\t\", metrics.roc_auc_score(target, rank_wtd_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["auc (averaged):\t\t 0.9474166574197703\n","auc (wtd. avg):\t\t 0.9486698241918139\n","auc (rank avg):\t\t 0.9429065112577433\n","auc (wtd. rank avg):\t 0.9488866904401518\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:36.284037Z","iopub.execute_input":"2021-08-21T19:52:36.284366Z","iopub.status.idle":"2021-08-21T19:52:36.349215Z","shell.execute_reply.started":"2021-08-21T19:52:36.284332Z","shell.execute_reply":"2021-08-21T19:52:36.348212Z"},"trusted":true}},{"cell_type":"markdown","source":["### Optimize AUC"],"metadata":{}},{"cell_type":"markdown","source":["We want to find the optimal coefficients for blending."],"metadata":{}},{"cell_type":"code","execution_count":168,"source":[" class OptimizeAUC:\n","        \"\"\"Implement blending that maximizes AUC score. \n","        Observe that this looks like an sklearn model.\"\"\"\n","        \n","        def __init__(self):\n","            self.coef_ = None\n","            \n","        def fit(self, X, y):\n","            \"\"\"Find weights of probability columns.\"\"\"\n","            \n","            # Think of: partial_loss(coef) = _auc(coef, X, y)\n","            partial_loss = partial(self._auc, X=X, y=y) \n","            \n","            # Initialize coefficients for descent\n","            init_coef = np.random.dirichlet(np.ones(X.shape[1]))\n","            \n","            # Compute best coefficients for blending\n","            self.coef_ = fmin(partial_loss, init_coef, disp=True) \n","            \n","        def predict_proba(self, X):\n","            \"\"\"Return blended probabilities for class 0 and class 1.\"\"\"\n","            \n","            x_coef = X * self.coef_\n","            predictions = np.sum(x_coef, axis=1)\n","            return np.c_[1-predictions, predictions]\n","        \n","        def _auc(self, coef, X, y):\n","            \"\"\"Compute AUC of blended positive predict probas.\n","            X: probability features columns\n","            y: targets\n","            coef: weights of columns of X.\"\"\"\n","            \n","            x_coef = X * coef\n","            predictions = np.sum(x_coef, axis=1)\n","            auc_score = metrics.roc_auc_score(y, predictions)\n","            \n","            # Negative AUC since we use minimizer\n","            return -1.0 * auc_score "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:36.350392Z","iopub.execute_input":"2021-08-21T19:52:36.350710Z","iopub.status.idle":"2021-08-21T19:52:36.359410Z","shell.execute_reply.started":"2021-08-21T19:52:36.350682Z","shell.execute_reply":"2021-08-21T19:52:36.358423Z"},"trusted":true}},{"cell_type":"code","execution_count":169,"source":["# Example: usage of fmin and partial\n","# Prints min value 3.000, returns minimum, i.e. x = 0\n","def f(x, y):\n","    return x**2 + y\n","\n","print(fmin(partial(f, y=3), 100, disp=True))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Optimization terminated successfully.\n","         Current function value: 3.000000\n","         Iterations: 24\n","         Function evaluations: 48\n","[0.]\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:36.360736Z","iopub.execute_input":"2021-08-21T19:52:36.361106Z","iopub.status.idle":"2021-08-21T19:52:36.380094Z","shell.execute_reply.started":"2021-08-21T19:52:36.361071Z","shell.execute_reply":"2021-08-21T19:52:36.379042Z"},"trusted":true}},{"cell_type":"code","execution_count":170,"source":["def find_best_coef(df, cols, fold, opt):\n","    \"\"\"Helper function for optimizer class. Here opt needs only \n","    to implement two methods and an attribute. Basically, to look\n","    like an sklearn model:\n","        - fit           (method: find best coef)\n","        - predict_proba (method: predicts using best coef)\n","        - coef_         (attr: best coef)\n","        \n","    Return best coef obtained on the ~`fold` subset. The evaluation on\n","    `fold` using the best coef found is printed.\n","    \"\"\"\n","    \n","    # Get train and valid folds of level predictions\n","    P_train = df[df.kfold != fold][cols]\n","    y_train = df[df.kfold != fold].sentiment.values\n","    P_valid = df[df.kfold == fold][cols]\n","    y_valid = df[df.kfold == fold].sentiment.values\n","    \n","    # Find best coef using opt on xtrain subset\n","    opt.fit(P_train, y_train)\n","    \n","    # Make prediction on xvalid subset using optimal coefs\n","    pred = opt.predict_proba(P_valid)[:, 1]\n","    auc = metrics.roc_auc_score(y_valid, pred)\n","    \n","    print(f\"fold={fold} auc={auc}\")\n","    print(opt.coef_)\n","    print()\n","    \n","    return opt.coef_"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:36.381883Z","iopub.execute_input":"2021-08-21T19:52:36.382350Z","iopub.status.idle":"2021-08-21T19:52:36.391126Z","shell.execute_reply.started":"2021-08-21T19:52:36.382316Z","shell.execute_reply":"2021-08-21T19:52:36.390233Z"},"trusted":true}},{"cell_type":"code","execution_count":171,"source":["# Average best coef for each fold. Use average as final blending coefficients\n","coefs = []\n","for j in range(5):\n","    opt = OptimizeAUC()\n","    coefs.append(find_best_coef(df, level1_cols, fold=j, opt=opt))\n","\n","best_coefs = sum(coefs)/5 "],"outputs":[{"output_type":"stream","name":"stdout","text":["Optimization terminated successfully.\n","         Current function value: -0.949795\n","         Iterations: 39\n","         Function evaluations: 80\n","fold=0 auc=0.9459351500078785\n","[0.19805461 0.45966138 0.07145728]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.949316\n","         Iterations: 45\n","         Function evaluations: 98\n","fold=1 auc=0.9479026817035446\n","[0.29371511 0.63384135 0.10039952]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.948747\n","         Iterations: 56\n","         Function evaluations: 113\n","fold=2 auc=0.9502855581653142\n","[0.15863027 0.32254164 0.04235994]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.949593\n","         Iterations: 54\n","         Function evaluations: 108\n","fold=3 auc=0.9468054620025194\n","[0.24773703 0.4791501  0.09503643]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.947791\n","         Iterations: 70\n","         Function evaluations: 134\n","fold=4 auc=0.9543175683913555\n","[0.03706148 0.07863174 0.01324765]\n","\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:36.392241Z","iopub.execute_input":"2021-08-21T19:52:36.392566Z","iopub.status.idle":"2021-08-21T19:52:40.914840Z","shell.execute_reply.started":"2021-08-21T19:52:36.392523Z","shell.execute_reply":"2021-08-21T19:52:40.913983Z"},"trusted":true}},{"cell_type":"code","execution_count":172,"source":["# Final result! Overall train AUC for blended level 1 predictions.\n","# We simply average best coeffs found on each fold. Might be suboptimal.\n","\n","blended_preds = (df[level1_cols] * best_coefs).sum(axis=1)\n","print(\"Train blended AUC:\", metrics.roc_auc_score(df.sentiment.values, blended_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train blended AUC: 0.9490374176894534\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:40.915964Z","iopub.execute_input":"2021-08-21T19:52:40.916270Z","iopub.status.idle":"2021-08-21T19:52:40.933085Z","shell.execute_reply.started":"2021-08-21T19:52:40.916243Z","shell.execute_reply":"2021-08-21T19:52:40.932062Z"},"trusted":true}},{"cell_type":"code","execution_count":173,"source":["# Checking if ranking improves predictions\n","\n","blended_preds = (df[level1_cols].rank() * best_coefs).sum(axis=1)\n","print(\"Train blended rank AUC:\", metrics.roc_auc_score(df.sentiment.values, blended_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train blended rank AUC: 0.9496022301808758\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:40.934252Z","iopub.execute_input":"2021-08-21T19:52:40.934524Z","iopub.status.idle":"2021-08-21T19:52:40.959815Z","shell.execute_reply.started":"2021-08-21T19:52:40.934497Z","shell.execute_reply":"2021-08-21T19:52:40.958824Z"},"trusted":true}},{"cell_type":"markdown","source":["Observe that the blended model has better than train AUC scores of individual models! Even better is using rank probabilities! Here individual probabilities are replaced by their rank index, this is a good trick for AUC which only cares about the probability of ranking negative examples lower than positive examples. Note that for single models, using rank does not affect score. Only works for ensembles. (See below.)"],"metadata":{}},{"cell_type":"markdown","source":["### Blending Inference"],"metadata":{}},{"cell_type":"code","execution_count":174,"source":["# Refit models on whole train set\n","lr_pipe.fit(df, df.sentiment.values)\n","lr_cnt_pipe.fit(df, df.sentiment.values)\n","rf_svd_pipe.fit(df, df.sentiment.values)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n","  FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidfvectorizerpreprocessor',\n","                 TfidfVectorizerPreprocessor(max_features=None)),\n","                ('truncatedsvdpreprocessor',\n","                 TruncatedSVDPreprocessor(n_components=None)),\n","                ('randomforestclassifier', RandomForestClassifier(n_jobs=-1))])"]},"metadata":{},"execution_count":174}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:52:40.961019Z","iopub.execute_input":"2021-08-21T19:52:40.961318Z","iopub.status.idle":"2021-08-21T19:53:46.632266Z","shell.execute_reply.started":"2021-08-21T19:52:40.961288Z","shell.execute_reply":"2021-08-21T19:53:46.631143Z"},"trusted":true}},{"cell_type":"code","execution_count":175,"source":["for model_name in ['lr', 'lr_cnt', 'rf_svd']:\n","    df_test[model_name+'_pred'] = eval(model_name + \"_pipe\").predict_proba(df_test)[:, 1]\n","\n","blended_test_preds = (df_test[level1_cols] * best_coefs).sum(axis=1)\n","print(\"Test blended AUC:\", metrics.roc_auc_score(df_test.sentiment.values, blended_test_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Test blended AUC: 0.9510487592561137\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:46.633810Z","iopub.execute_input":"2021-08-21T19:53:46.634244Z","iopub.status.idle":"2021-08-21T19:53:50.261856Z","shell.execute_reply.started":"2021-08-21T19:53:46.634200Z","shell.execute_reply":"2021-08-21T19:53:50.260619Z"},"trusted":true}},{"cell_type":"markdown","source":["In comparison, let's see test performance of individual models."],"metadata":{}},{"cell_type":"code","execution_count":176,"source":["for model_name in ['lr', 'lr_cnt', 'rf_svd']:\n","    print(f\"Test {model_name} AUC:\", metrics.roc_auc_score(df_test.sentiment.values, df_test[model_name+'_pred']))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Test lr AUC: 0.935395673869509\n","Test lr_cnt AUC: 0.945592062852956\n","Test rf_svd AUC: 0.876999964737517\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:50.263163Z","iopub.execute_input":"2021-08-21T19:53:50.263446Z","iopub.status.idle":"2021-08-21T19:53:50.279418Z","shell.execute_reply.started":"2021-08-21T19:53:50.263418Z","shell.execute_reply":"2021-08-21T19:53:50.278132Z"},"trusted":true}},{"cell_type":"markdown","source":["Awesome!!! This is our current best test score."],"metadata":{}},{"cell_type":"markdown","source":["## Stacking"],"metadata":{}},{"cell_type":"markdown","source":["Instead of fixed constants for stacking, we learn the weights using logistic regression. Then, pass the results through a sigmoid. This is basically **stacking** since we use a Level 2 model. Note that we are using the **same folds** to evaluate the Level 2 model. It is recommended to use the same folds to make Level 2 stacking."],"metadata":{}},{"cell_type":"code","execution_count":177,"source":["def oof_score(fold, model):\n","    \"\"\"Get out-of-fold AUC score of model.\"\"\"\n","    \n","    # Get train and valid folds of level predictions\n","    X_train = df[df.kfold != fold][level1_cols]\n","    y_train = df[df.kfold != fold].sentiment.values\n","    \n","    X_valid = df[df.kfold == fold][level1_cols]\n","    y_valid = df[df.kfold == fold].sentiment.values\n","    \n","    # Find best coef using opt on xtrain subset\n","    model.fit(X_train, y_train)\n","    \n","    # Make prediction on xvalid subset using optimal coefs\n","    pred = model.predict_proba(X_valid)[:, 1]\n","    auc = metrics.roc_auc_score(y_valid, pred)\n","    \n","    print(f\"fold={fold} auc={auc}\")\n","    \n","    return auc"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:50.280619Z","iopub.execute_input":"2021-08-21T19:53:50.280955Z","iopub.status.idle":"2021-08-21T19:53:50.287959Z","shell.execute_reply.started":"2021-08-21T19:53:50.280921Z","shell.execute_reply":"2021-08-21T19:53:50.286971Z"},"trusted":true}},{"cell_type":"markdown","source":["### Meta model 1: Logistic Regression"],"metadata":{}},{"cell_type":"code","execution_count":178,"source":["# cross validate logistic regression model\n","cv_scores = []\n","for j in range(5):\n","    model = linear_model.LogisticRegression()\n","    cv_scores.append(oof_score(fold=j, model=model))\n","    \n","print(sum(cv_scores) / 5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["fold=0 auc=0.945384812433713\n","fold=1 auc=0.9473373705243895\n","fold=2 auc=0.9491648414226123\n","fold=3 auc=0.9446545612365157\n","fold=4 auc=0.9534996170678716\n","0.9480082405370205\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:50.289346Z","iopub.execute_input":"2021-08-21T19:53:50.289753Z","iopub.status.idle":"2021-08-21T19:53:50.770149Z","shell.execute_reply.started":"2021-08-21T19:53:50.289707Z","shell.execute_reply":"2021-08-21T19:53:50.768799Z"},"trusted":true}},{"cell_type":"markdown","source":["### Meta model 2: Linear Regression"],"metadata":{}},{"cell_type":"code","execution_count":179,"source":["# cross validate linear regression model; we need to scale for convergence\n","lin_reg_pipe = make_pipeline(\n","    StandardScalerPreprocessor(level1_cols),\n","    LinearRegressionModel()\n",")\n","cv_scores = []\n","for j in range(5):\n","    model = lin_reg_pipe\n","    cv_scores.append(oof_score(fold=j, model=model))\n","    \n","print(sum(cv_scores) / 5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["fold=0 auc=0.9459627935863211\n","fold=1 auc=0.9479386183555204\n","fold=2 auc=0.950232113913658\n","fold=3 auc=0.9465230367760953\n","fold=4 auc=0.9543042009141052\n","0.9489921527091401\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:50.780999Z","iopub.execute_input":"2021-08-21T19:53:50.785241Z","iopub.status.idle":"2021-08-21T19:53:51.080482Z","shell.execute_reply.started":"2021-08-21T19:53:50.785175Z","shell.execute_reply":"2021-08-21T19:53:51.079265Z"},"trusted":true}},{"cell_type":"markdown","source":["### Meta model 3: XGBClassifier"],"metadata":{}},{"cell_type":"code","execution_count":180,"source":["# cross validate XGBoost classifier \n","cv_scores = []\n","for j in range(5):\n","    model = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)\n","    cv_scores.append(oof_score(fold=j, model=model))\n","    \n","print(sum(cv_scores) / 5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["fold=0 auc=0.9418400994063082\n","fold=1 auc=0.9447695124502069\n","fold=2 auc=0.9454844444976839\n","fold=3 auc=0.9407664919285357\n","fold=4 auc=0.9502164033235234\n","0.9446153903212517\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:51.087941Z","iopub.execute_input":"2021-08-21T19:53:51.091791Z","iopub.status.idle":"2021-08-21T19:53:55.724923Z","shell.execute_reply.started":"2021-08-21T19:53:51.091722Z","shell.execute_reply":"2021-08-21T19:53:55.724116Z"},"trusted":true}},{"cell_type":"markdown","source":["### Stacking Inference"],"metadata":{}},{"cell_type":"markdown","source":["Recall base models have been fitted on the whole train set. And has predicted on the test set. We now check inference scores using the metamodels. Should be close to cross-validated scores."],"metadata":{}},{"cell_type":"code","execution_count":181,"source":["df_test.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id  sentiment                                             review  \\\n","20794   8390_8          1  My first Fassbinder was a wonderful experience...   \n","20797  7316_10          1  This film is one of the best of all time, cert...   \n","20800   5784_8          1  I've noticed that a lot of people who post on ...   \n","20801  10546_9          1  I chanced upon this movie because I had a free...   \n","20803  10796_9          1  If you're a a fan of either or both Chuck Norr...   \n","\n","       kfold   lr_pred  lr_cnt_pred  rf_svd_pred  \n","20794      5  0.977814     0.998684         0.65  \n","20797      5  0.996353     1.000000         0.70  \n","20800      5  0.988561     0.999921         0.60  \n","20801      5  0.757632     0.930755         0.57  \n","20803      5  0.842108     0.961403         0.60  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","      <th>kfold</th>\n","      <th>lr_pred</th>\n","      <th>lr_cnt_pred</th>\n","      <th>rf_svd_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>20794</th>\n","      <td>8390_8</td>\n","      <td>1</td>\n","      <td>My first Fassbinder was a wonderful experience...</td>\n","      <td>5</td>\n","      <td>0.977814</td>\n","      <td>0.998684</td>\n","      <td>0.65</td>\n","    </tr>\n","    <tr>\n","      <th>20797</th>\n","      <td>7316_10</td>\n","      <td>1</td>\n","      <td>This film is one of the best of all time, cert...</td>\n","      <td>5</td>\n","      <td>0.996353</td>\n","      <td>1.000000</td>\n","      <td>0.70</td>\n","    </tr>\n","    <tr>\n","      <th>20800</th>\n","      <td>5784_8</td>\n","      <td>1</td>\n","      <td>I've noticed that a lot of people who post on ...</td>\n","      <td>5</td>\n","      <td>0.988561</td>\n","      <td>0.999921</td>\n","      <td>0.60</td>\n","    </tr>\n","    <tr>\n","      <th>20801</th>\n","      <td>10546_9</td>\n","      <td>1</td>\n","      <td>I chanced upon this movie because I had a free...</td>\n","      <td>5</td>\n","      <td>0.757632</td>\n","      <td>0.930755</td>\n","      <td>0.57</td>\n","    </tr>\n","    <tr>\n","      <th>20803</th>\n","      <td>10796_9</td>\n","      <td>1</td>\n","      <td>If you're a a fan of either or both Chuck Norr...</td>\n","      <td>5</td>\n","      <td>0.842108</td>\n","      <td>0.961403</td>\n","      <td>0.60</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":181}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:55.729197Z","iopub.execute_input":"2021-08-21T19:53:55.731648Z","iopub.status.idle":"2021-08-21T19:53:55.748556Z","shell.execute_reply.started":"2021-08-21T19:53:55.731605Z","shell.execute_reply":"2021-08-21T19:53:55.747749Z"},"trusted":true}},{"cell_type":"code","execution_count":182,"source":["# Define metamodels\n","logreg = linear_model.LogisticRegression()\n","linreg = make_pipeline(\n","    StandardScalerPreprocessor(level1_cols),\n","    LinearRegressionModel()\n",")\n","xgbclf = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)\n","\n","# Fit on level 1 features\n","logreg.fit(df[level1_cols], df.sentiment.values)\n","linreg.fit(df[level1_cols], df.sentiment.values)\n","xgbclf.fit(df[level1_cols], df.sentiment.values)\n","\n","# Score inference\n","metamodels = {\n","    'logreg': logreg,\n","    'linreg': linreg,\n","    'xgbclf': xgbclf\n","}\n","\n","for model_name in metamodels.keys():\n","    stacker_test_preds = metamodels[model_name].predict_proba(df_test[level1_cols])[:, 1]\n","    print(f\"Test {model_name} AUC:\", metrics.roc_auc_score(df_test.sentiment.values, stacker_test_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Test logreg AUC: 0.94972607042955\n","Test linreg AUC: 0.9509284519608591\n","Test xgbclf AUC: 0.9483125749471814\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:55.749891Z","iopub.execute_input":"2021-08-21T19:53:55.750450Z","iopub.status.idle":"2021-08-21T19:53:57.054615Z","shell.execute_reply.started":"2021-08-21T19:53:55.750416Z","shell.execute_reply":"2021-08-21T19:53:57.053831Z"},"trusted":true}},{"cell_type":"markdown","source":["Linear regression best model (as a ranking model). Better than blending. Also similar scores with cross val scores."],"metadata":{}},{"cell_type":"markdown","source":[":::{note}\n","Alternatively, we could make predictions on the test dataset using each base model immediately after it gets fitted on each fold. In our case, this would generate test-set predictions for five of each base models. Then, we would average the predictions per model to generate our level 1 meta features.\n","\n","One benefit to this is that it’s less time consuming than the first approach (since we don’t have to retrain each model on the full training dataset). It also helps that our train meta features and test meta features should follow a similar distribution. However, the test meta features are likely more accurate in the first approach since each base model was trained on the full training dataset (as opposed to 80% of the training dataset, five times in the 2nd approach).\n",":::"],"metadata":{}},{"cell_type":"markdown","source":["## Experiment: Using Same CV Folds for Level 2 Stacking"],"metadata":{}},{"cell_type":"markdown","source":["It's still not clear to me whether using same folds between levels 1 and 2 affect generalization error. We check CV scores with folds shuffled. Compare with actual test performance. Abishek in AAAMLP recommends using same folds. We test whether using different folds results in overfitting.\n","\n","Here we have level two features from the three metamodels. We blend the predict probabilities of each metamodel."],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:51:58.967501Z","iopub.execute_input":"2021-08-21T16:51:58.968012Z","iopub.status.idle":"2021-08-21T16:51:58.986856Z","shell.execute_reply.started":"2021-08-21T16:51:58.96798Z","shell.execute_reply":"2021-08-21T16:51:58.985191Z"}}},{"cell_type":"markdown","source":["### Same Folds"],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T17:49:31.319669Z","iopub.execute_input":"2021-08-21T17:49:31.32014Z","iopub.status.idle":"2021-08-21T17:49:31.344901Z","shell.execute_reply.started":"2021-08-21T17:49:31.320085Z","shell.execute_reply":"2021-08-21T17:49:31.344307Z"}}},{"cell_type":"code","execution_count":183,"source":["class LinearRegressionLevel2(BaseEstimator, TransformerMixin):\n","    def __init__(self, cols):\n","        self.cols = cols\n","        self.lr = linear_model.LinearRegression()\n","        self.sc = StandardScaler()\n","    \n","    def fit(self, X, y):\n","        self.lr.fit(self.sc.fit_transform(X[self.cols]), y)\n","        \n","    def predict_proba(self, X):\n","        return np.c_[self.lr.predict(self.sc.transform(X[self.cols])), \n","                     self.lr.predict(self.sc.transform(X[self.cols]))]\n","    \n","\n","class LogisticRegressionLevel2(BaseEstimator, TransformerMixin):\n","    def __init__(self, cols):\n","        self.cols = cols\n","        self.logreg = linear_model.LogisticRegression()\n","    \n","    def fit(self, X, y):\n","        self.logreg.fit(X[self.cols], y)\n","        \n","    def predict_proba(self, X):\n","        return self.logreg.predict_proba(X[self.cols])\n","\n","    \n","class XGBClassifierLevel2(BaseEstimator, TransformerMixin):\n","    def __init__(self, cols):\n","        self.cols = cols\n","        self.xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)\n","    \n","    def fit(self, X, y):\n","        self.xgb.fit(X[self.cols], y)\n","        \n","    def predict_proba(self, X):\n","        return self.xgb.predict_proba(X[self.cols])"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:57.056006Z","iopub.execute_input":"2021-08-21T19:53:57.056558Z","iopub.status.idle":"2021-08-21T19:53:57.070416Z","shell.execute_reply.started":"2021-08-21T19:53:57.056522Z","shell.execute_reply":"2021-08-21T19:53:57.069278Z"},"trusted":true}},{"cell_type":"code","execution_count":184,"source":["# Define metamodels\n","linreg = LinearRegressionLevel2(level1_cols)\n","logreg = LogisticRegressionLevel2(level1_cols)\n","xgbclf = XGBClassifierLevel2(level1_cols)\n","\n","# Create level 2 features\n","metamodels = {\n","    'logreg': logreg,\n","    'linreg': linreg,\n","    'xgbclf': xgbclf\n","}\n","level2_cols = [model_name + '_pred' for model_name in metamodels.keys()]\n","for model_name in metamodels.keys():\n","    df = stack_oof_preds(df, metamodels[model_name], model_name)"],"outputs":[{"output_type":"stream","name":"stdout","text":["logreg\n","fold=0, auc=0.945384812433713\n","fold=1, auc=0.9473373705243895\n","fold=2, auc=0.9491648414226123\n","fold=3, auc=0.9446545612365157\n","fold=4, auc=0.9534996170678716\n","linreg\n","fold=0, auc=0.9459627935863211\n","fold=1, auc=0.9479386183555204\n","fold=2, auc=0.950232113913658\n","fold=3, auc=0.9465230367760953\n","fold=4, auc=0.9543042009141052\n","xgbclf\n","fold=0, auc=0.9418400994063082\n","fold=1, auc=0.9447695124502069\n","fold=2, auc=0.9454844444976839\n","fold=3, auc=0.9407664919285357\n","fold=4, auc=0.9502164033235234\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:53:57.072054Z","iopub.execute_input":"2021-08-21T19:53:57.072708Z","iopub.status.idle":"2021-08-21T19:54:02.528195Z","shell.execute_reply.started":"2021-08-21T19:53:57.072653Z","shell.execute_reply":"2021-08-21T19:54:02.527080Z"},"trusted":true}},{"cell_type":"code","execution_count":185,"source":["df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id  sentiment                                             review  \\\n","0   4336_4          0  I watched this movie and the original Carlitos...   \n","1   6718_2          0  I wanted to see the movie because of an articl...   \n","2   1962_2          0  The only scary thing about this movie is the t...   \n","3   2773_1          0  Up to this point, Gentle Rain was the movie I ...   \n","4  9713_10          1  This series premiered on the cable TV station ...   \n","\n","   kfold   lr_pred   lr_cnt_pred  rf_svd_pred  logreg_pred  linreg_pred  \\\n","0      0  0.194985  1.108888e-02         0.35     0.053552     0.063751   \n","1      0  0.274892  2.456256e-01         0.60     0.209615     0.278658   \n","2      0  0.005616  1.768062e-07         0.23     0.023239    -0.024696   \n","3      0  0.016342  2.387402e-05         0.23     0.023968    -0.021198   \n","4      0  0.948322  9.998050e-01         0.69     0.962137     0.986046   \n","\n","   xgbclf_pred  \n","0     0.048794  \n","1     0.339733  \n","2     0.002535  \n","3     0.003605  \n","4     0.998475  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","      <th>kfold</th>\n","      <th>lr_pred</th>\n","      <th>lr_cnt_pred</th>\n","      <th>rf_svd_pred</th>\n","      <th>logreg_pred</th>\n","      <th>linreg_pred</th>\n","      <th>xgbclf_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4336_4</td>\n","      <td>0</td>\n","      <td>I watched this movie and the original Carlitos...</td>\n","      <td>0</td>\n","      <td>0.194985</td>\n","      <td>1.108888e-02</td>\n","      <td>0.35</td>\n","      <td>0.053552</td>\n","      <td>0.063751</td>\n","      <td>0.048794</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6718_2</td>\n","      <td>0</td>\n","      <td>I wanted to see the movie because of an articl...</td>\n","      <td>0</td>\n","      <td>0.274892</td>\n","      <td>2.456256e-01</td>\n","      <td>0.60</td>\n","      <td>0.209615</td>\n","      <td>0.278658</td>\n","      <td>0.339733</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1962_2</td>\n","      <td>0</td>\n","      <td>The only scary thing about this movie is the t...</td>\n","      <td>0</td>\n","      <td>0.005616</td>\n","      <td>1.768062e-07</td>\n","      <td>0.23</td>\n","      <td>0.023239</td>\n","      <td>-0.024696</td>\n","      <td>0.002535</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2773_1</td>\n","      <td>0</td>\n","      <td>Up to this point, Gentle Rain was the movie I ...</td>\n","      <td>0</td>\n","      <td>0.016342</td>\n","      <td>2.387402e-05</td>\n","      <td>0.23</td>\n","      <td>0.023968</td>\n","      <td>-0.021198</td>\n","      <td>0.003605</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9713_10</td>\n","      <td>1</td>\n","      <td>This series premiered on the cable TV station ...</td>\n","      <td>0</td>\n","      <td>0.948322</td>\n","      <td>9.998050e-01</td>\n","      <td>0.69</td>\n","      <td>0.962137</td>\n","      <td>0.986046</td>\n","      <td>0.998475</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":185}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:02.529901Z","iopub.execute_input":"2021-08-21T19:54:02.530318Z","iopub.status.idle":"2021-08-21T19:54:02.551898Z","shell.execute_reply.started":"2021-08-21T19:54:02.530273Z","shell.execute_reply":"2021-08-21T19:54:02.550781Z"},"trusted":true}},{"cell_type":"markdown","source":["Blend Level 2 predictions."],"metadata":{}},{"cell_type":"code","execution_count":186,"source":["# Average best coef for each fold. Use average as final blending coefficients\n","coefs = []\n","for j in range(5):\n","    opt = OptimizeAUC()\n","    coefs.append(find_best_coef(df, level2_cols, fold=j, opt=opt))\n","\n","best_coefs = sum(coefs)/5 "],"outputs":[{"output_type":"stream","name":"stdout","text":["Optimization terminated successfully.\n","         Current function value: -0.949651\n","         Iterations: 87\n","         Function evaluations: 169\n","fold=0 auc=0.9460222272799732\n","[0.01642233 0.85312636 0.1141321 ]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.949126\n","         Iterations: 49\n","         Function evaluations: 111\n","fold=1 auc=0.9481351181256181\n","[0.0098476  0.86634474 0.06720761]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.948633\n","         Iterations: 60\n","         Function evaluations: 116\n","fold=2 auc=0.9503219555435971\n","[0.06304008 0.78625821 0.089259  ]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.949586\n","         Iterations: 39\n","         Function evaluations: 87\n","fold=3 auc=0.9461788742244825\n","[0.24736973 0.67406233 0.13163703]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.947411\n","         Iterations: 46\n","         Function evaluations: 100\n","fold=4 auc=0.9541767489327337\n","[0.33470507 0.16846998 0.07960809]\n","\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:02.553434Z","iopub.execute_input":"2021-08-21T19:54:02.554054Z","iopub.status.idle":"2021-08-21T19:54:07.927289Z","shell.execute_reply.started":"2021-08-21T19:54:02.554005Z","shell.execute_reply":"2021-08-21T19:54:07.926053Z"},"trusted":true}},{"cell_type":"code","execution_count":187,"source":["# Refit models on whole train set\n","for model_name in metamodels.keys():\n","    metamodels[model_name].fit(df, df.sentiment.values)\n","    df_test[model_name+'_pred'] = eval(model_name).predict_proba(df_test)[:, 1]\n","\n","blended_test_preds = (df_test[level2_cols] * best_coefs).sum(axis=1)\n","print(\"Test blended AUC:\", metrics.roc_auc_score(df_test.sentiment.values, blended_test_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Test blended AUC: 0.9510374660425746\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:07.928513Z","iopub.execute_input":"2021-08-21T19:54:07.928798Z","iopub.status.idle":"2021-08-21T19:54:09.232756Z","shell.execute_reply.started":"2021-08-21T19:54:07.928771Z","shell.execute_reply":"2021-08-21T19:54:09.231709Z"},"trusted":true}},{"cell_type":"code","execution_count":188,"source":["blended_train_preds = (df[level2_cols] * best_coefs).sum(axis=1)\n","print(\"Train blended AUC:\", metrics.roc_auc_score(df.sentiment.values, blended_train_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train blended AUC: 0.9489021078214236\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:09.234514Z","iopub.execute_input":"2021-08-21T19:54:09.235280Z","iopub.status.idle":"2021-08-21T19:54:09.256333Z","shell.execute_reply.started":"2021-08-21T19:54:09.235232Z","shell.execute_reply":"2021-08-21T19:54:09.255126Z"},"trusted":true}},{"cell_type":"code","execution_count":189,"source":["df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id  sentiment                                             review  \\\n","0   4336_4          0  I watched this movie and the original Carlitos...   \n","1   6718_2          0  I wanted to see the movie because of an articl...   \n","2   1962_2          0  The only scary thing about this movie is the t...   \n","3   2773_1          0  Up to this point, Gentle Rain was the movie I ...   \n","4  9713_10          1  This series premiered on the cable TV station ...   \n","\n","   kfold   lr_pred   lr_cnt_pred  rf_svd_pred  logreg_pred  linreg_pred  \\\n","0      0  0.194985  1.108888e-02         0.35     0.053552     0.063751   \n","1      0  0.274892  2.456256e-01         0.60     0.209615     0.278658   \n","2      0  0.005616  1.768062e-07         0.23     0.023239    -0.024696   \n","3      0  0.016342  2.387402e-05         0.23     0.023968    -0.021198   \n","4      0  0.948322  9.998050e-01         0.69     0.962137     0.986046   \n","\n","   xgbclf_pred  \n","0     0.048794  \n","1     0.339733  \n","2     0.002535  \n","3     0.003605  \n","4     0.998475  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","      <th>kfold</th>\n","      <th>lr_pred</th>\n","      <th>lr_cnt_pred</th>\n","      <th>rf_svd_pred</th>\n","      <th>logreg_pred</th>\n","      <th>linreg_pred</th>\n","      <th>xgbclf_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4336_4</td>\n","      <td>0</td>\n","      <td>I watched this movie and the original Carlitos...</td>\n","      <td>0</td>\n","      <td>0.194985</td>\n","      <td>1.108888e-02</td>\n","      <td>0.35</td>\n","      <td>0.053552</td>\n","      <td>0.063751</td>\n","      <td>0.048794</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6718_2</td>\n","      <td>0</td>\n","      <td>I wanted to see the movie because of an articl...</td>\n","      <td>0</td>\n","      <td>0.274892</td>\n","      <td>2.456256e-01</td>\n","      <td>0.60</td>\n","      <td>0.209615</td>\n","      <td>0.278658</td>\n","      <td>0.339733</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1962_2</td>\n","      <td>0</td>\n","      <td>The only scary thing about this movie is the t...</td>\n","      <td>0</td>\n","      <td>0.005616</td>\n","      <td>1.768062e-07</td>\n","      <td>0.23</td>\n","      <td>0.023239</td>\n","      <td>-0.024696</td>\n","      <td>0.002535</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2773_1</td>\n","      <td>0</td>\n","      <td>Up to this point, Gentle Rain was the movie I ...</td>\n","      <td>0</td>\n","      <td>0.016342</td>\n","      <td>2.387402e-05</td>\n","      <td>0.23</td>\n","      <td>0.023968</td>\n","      <td>-0.021198</td>\n","      <td>0.003605</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9713_10</td>\n","      <td>1</td>\n","      <td>This series premiered on the cable TV station ...</td>\n","      <td>0</td>\n","      <td>0.948322</td>\n","      <td>9.998050e-01</td>\n","      <td>0.69</td>\n","      <td>0.962137</td>\n","      <td>0.986046</td>\n","      <td>0.998475</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":189}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:09.257998Z","iopub.execute_input":"2021-08-21T19:54:09.258419Z","iopub.status.idle":"2021-08-21T19:54:09.281226Z","shell.execute_reply.started":"2021-08-21T19:54:09.258374Z","shell.execute_reply":"2021-08-21T19:54:09.280037Z"},"trusted":true}},{"cell_type":"markdown","source":["### Different Folds (Shuffled)"],"metadata":{}},{"cell_type":"markdown","source":["We shuffle the kfold column and see whether there is significant drop in test score."],"metadata":{}},{"cell_type":"code","execution_count":190,"source":["import random\n","df['kfold'] = random.sample(df.kfold.tolist(), len(df)) \n","\n","# Define metamodels\n","linreg = LinearRegressionLevel2(level1_cols)\n","logreg = LogisticRegressionLevel2(level1_cols)\n","xgbclf = XGBClassifierLevel2(level1_cols)\n","\n","# Create level 2 features\n","metamodels = {\n","    'logreg': logreg,\n","    'linreg': linreg,\n","    'xgbclf': xgbclf\n","}\n","level2_cols = [model_name + '_pred' for model_name in metamodels.keys()]\n","for model_name in metamodels.keys():\n","    df = stack_oof_preds(df, metamodels[model_name], model_name)\n","    \n","# Get blending coefficients\n","coefs = []\n","for j in range(5):\n","    opt = OptimizeAUC()\n","    coefs.append(find_best_coef(df, level2_cols, fold=j, opt=opt))\n","\n","best_coefs = sum(coefs)/5 \n","\n","# Refit models on whole train set\n","for model_name in metamodels.keys():\n","    metamodels[model_name].fit(df, df.sentiment.values)\n","    df_test[model_name+'_pred'] = eval(model_name).predict_proba(df_test)[:, 1]\n","\n","blended_test_preds = (df_test[level2_cols] * best_coefs).sum(axis=1)\n","print(\"Test blended AUC:\", metrics.roc_auc_score(df_test.sentiment.values, blended_test_preds))\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["logreg\n","fold=0, auc=0.9501040818131891\n","fold=1, auc=0.9499241183771747\n","fold=2, auc=0.9499064438524856\n","fold=3, auc=0.9451329726898312\n","fold=4, auc=0.9447659104945992\n","linreg\n","fold=0, auc=0.9508122435965958\n","fold=1, auc=0.9511657757755636\n","fold=2, auc=0.9514574941700232\n","fold=3, auc=0.9455855446264058\n","fold=4, auc=0.9457376475847319\n","xgbclf\n","fold=0, auc=0.9476719354149082\n","fold=1, auc=0.9470740654397218\n","fold=2, auc=0.9472979325474002\n","fold=3, auc=0.9410262800661775\n","fold=4, auc=0.9426348899032251\n","Optimization terminated successfully.\n","         Current function value: -0.948559\n","         Iterations: 38\n","         Function evaluations: 81\n","fold=0 auc=0.9510200386286818\n","[0.03254031 0.3080599  0.05749097]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.948474\n","         Iterations: 38\n","         Function evaluations: 87\n","fold=1 auc=0.9513122867413105\n","[0.09500983 0.57026417 0.10258291]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.948445\n","         Iterations: 59\n","         Function evaluations: 116\n","fold=2 auc=0.9514468942124231\n","[0.0641778  0.2334453  0.05450551]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.949937\n","         Iterations: 38\n","         Function evaluations: 86\n","fold=3 auc=0.9457284863486044\n","[-0.00708695  0.83304992  0.16371734]\n","\n","Optimization terminated successfully.\n","         Current function value: -0.949830\n","         Iterations: 43\n","         Function evaluations: 97\n","fold=4 auc=0.945932917173188\n","[0.04394636 0.66615797 0.12018765]\n","\n","Test blended AUC: 0.9510750332631234\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:09.283122Z","iopub.execute_input":"2021-08-21T19:54:09.283565Z","iopub.status.idle":"2021-08-21T19:54:20.710491Z","shell.execute_reply.started":"2021-08-21T19:54:09.283520Z","shell.execute_reply":"2021-08-21T19:54:20.709678Z"},"trusted":true}},{"cell_type":"markdown","source":["Test score actually dropped. And train score increased. Repeated this experiment thrice to get different sampling getting same behavior. Very curious!"],"metadata":{}},{"cell_type":"code","execution_count":191,"source":["blended_train_preds = (df[level2_cols] * best_coefs).sum(axis=1)\n","print(\"Train blended AUC:\", metrics.roc_auc_score(df.sentiment.values, blended_train_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train blended AUC: 0.9490388184318046\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:20.714750Z","iopub.execute_input":"2021-08-21T19:54:20.715393Z","iopub.status.idle":"2021-08-21T19:54:20.735269Z","shell.execute_reply.started":"2021-08-21T19:54:20.715345Z","shell.execute_reply":"2021-08-21T19:54:20.734148Z"},"trusted":true}},{"cell_type":"code","execution_count":192,"source":["df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id  sentiment                                             review  \\\n","0   4336_4          0  I watched this movie and the original Carlitos...   \n","1   6718_2          0  I wanted to see the movie because of an articl...   \n","2   1962_2          0  The only scary thing about this movie is the t...   \n","3   2773_1          0  Up to this point, Gentle Rain was the movie I ...   \n","4  9713_10          1  This series premiered on the cable TV station ...   \n","\n","   kfold   lr_pred   lr_cnt_pred  rf_svd_pred  logreg_pred  linreg_pred  \\\n","0      3  0.194985  1.108888e-02         0.35     0.055443     0.066070   \n","1      1  0.274892  2.456256e-01         0.60     0.215703     0.281514   \n","2      2  0.005616  1.768062e-07         0.23     0.023499    -0.025485   \n","3      3  0.016342  2.387402e-05         0.23     0.025219    -0.017726   \n","4      1  0.948322  9.998050e-01         0.69     0.961982     0.987177   \n","\n","   xgbclf_pred  \n","0     0.062589  \n","1     0.559257  \n","2     0.001189  \n","3     0.001061  \n","4     0.992870  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","      <th>kfold</th>\n","      <th>lr_pred</th>\n","      <th>lr_cnt_pred</th>\n","      <th>rf_svd_pred</th>\n","      <th>logreg_pred</th>\n","      <th>linreg_pred</th>\n","      <th>xgbclf_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4336_4</td>\n","      <td>0</td>\n","      <td>I watched this movie and the original Carlitos...</td>\n","      <td>3</td>\n","      <td>0.194985</td>\n","      <td>1.108888e-02</td>\n","      <td>0.35</td>\n","      <td>0.055443</td>\n","      <td>0.066070</td>\n","      <td>0.062589</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6718_2</td>\n","      <td>0</td>\n","      <td>I wanted to see the movie because of an articl...</td>\n","      <td>1</td>\n","      <td>0.274892</td>\n","      <td>2.456256e-01</td>\n","      <td>0.60</td>\n","      <td>0.215703</td>\n","      <td>0.281514</td>\n","      <td>0.559257</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1962_2</td>\n","      <td>0</td>\n","      <td>The only scary thing about this movie is the t...</td>\n","      <td>2</td>\n","      <td>0.005616</td>\n","      <td>1.768062e-07</td>\n","      <td>0.23</td>\n","      <td>0.023499</td>\n","      <td>-0.025485</td>\n","      <td>0.001189</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2773_1</td>\n","      <td>0</td>\n","      <td>Up to this point, Gentle Rain was the movie I ...</td>\n","      <td>3</td>\n","      <td>0.016342</td>\n","      <td>2.387402e-05</td>\n","      <td>0.23</td>\n","      <td>0.025219</td>\n","      <td>-0.017726</td>\n","      <td>0.001061</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9713_10</td>\n","      <td>1</td>\n","      <td>This series premiered on the cable TV station ...</td>\n","      <td>1</td>\n","      <td>0.948322</td>\n","      <td>9.998050e-01</td>\n","      <td>0.69</td>\n","      <td>0.961982</td>\n","      <td>0.987177</td>\n","      <td>0.992870</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":192}],"metadata":{"execution":{"iopub.status.busy":"2021-08-21T19:54:20.736685Z","iopub.execute_input":"2021-08-21T19:54:20.737040Z","iopub.status.idle":"2021-08-21T19:54:20.755531Z","shell.execute_reply.started":"2021-08-21T19:54:20.737008Z","shell.execute_reply":"2021-08-21T19:54:20.754549Z"},"trusted":true}},{"cell_type":"markdown","source":["### Conclusion\n","\n","Empirical results strongly indicate that we should use the **same folds** across levels of stacking. Indeed, the same is recommended by GM Abishek in his book AAAMLP. Searching around Kaggle, I found [this comment](https://www.kaggle.com/general/18793#424642) by [Trian](https://www.kaggle.com/trian2018) who is a Kaggle Master that supports this result:\n","\n","> The following theoretical example shows that overfitting can happen [when using different folds], due to the second stage model taking advantage of a certain relationship between ground truth and first stage predictions, without this structure having any real meaning, which could generalise well to the test set.\n","\n","Trian continues to give an example that I don't understand (even after two bottles of milk chocolate). So instead let's come up with an explanation that is of the same spirit but is more abstract.\n","\n","Suppose we have $x_1, x_2, \\ldots, x_{10}$ with five folds such that $x_1$ and $x_2$ are in the same fold $F_1$. Let $x_1, x_2 {\\mapsto} y_1, y_2$ trained on $F_{\\neg 1} = (x_3, \\ldots, x_{10}).$ We can think of as defining distribution that the points in $x_1$ and $x_2$ are compared against. Suppose we reshuffle folds in the next level such that the first fold is $G_1 = (y_1, y_{10}).$ These points are compared against the distribution of $G_{\\neg 1} = (y_2, \\ldots y_9).$ Then, the model trained on $G_{\\neg 1}$ can overfit slightly since $y_2$ is too adapted to the rest of the points $y_3, \\ldots y_9$ in $G_{\\neg 1},$ i.e. $y_2$ is mapped by the model trained on $x_3, \\ldots, x_9.$ \n","\n","\n","Trian further notes:\n","> Theoretically (as mentioned in https://datasciblog.github.io/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/), you always have leakage if you train a second level model on the same training set, which you used to derive the first stage predictions. This is because you used the ground truth to get those first stage predictions, and now you take those predictions as input, and try to predict the same ground truth. However, it seems to me, that this kind of leakage is more theoretical, and does not happen in practice, as long as you keep the same folds, as described above."],"metadata":{}},{"cell_type":"markdown","source":["**Todo**\n","* Record CV scores in a DataFrame. This would allow us to calculate standard deviations which is a measure of stability of the folds. Also, an easy reference to see what's happening with the components of the network. "],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}