{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Ensembling: Blending and Stacking"],"metadata":{"papermill":{"duration":0.043191,"end_time":"2021-08-25T05:24:32.396308","exception":false,"start_time":"2021-08-25T05:24:32.353117","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["In this notebook, we implement stacking of machine learning models. Stacking several uncorrelated models is known to generalize better than individual models. Stacking mainly requires good cross-validation strategy between levels of prediction. In particular, we will demostrate that maintaining the same cross-validation folds between levels minimizes overfitting."],"metadata":{"papermill":{"duration":0.042908,"end_time":"2021-08-25T05:24:32.48371","exception":false,"start_time":"2021-08-25T05:24:32.440802","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\n","import numpy as np\n","import time\n","import joblib\n","import random\n","from joblib import Parallel, delayed\n","from scipy.optimize import minimize\n","from xgboost import XGBClassifier\n","\n","from sklearn import model_selection, linear_model, metrics, decomposition, ensemble\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n","\n","from tqdm.notebook import tqdm as tqdm\n","from functools import partial, reduce\n","from typing import List\n","import warnings\n","warnings.simplefilter(action='ignore')\n","\n","\n","NUM_FOLDS = 5"],"outputs":[],"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.458677,"end_time":"2021-08-25T05:24:33.985203","exception":false,"start_time":"2021-08-25T05:24:32.526526","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:34.883864Z","iopub.execute_input":"2021-08-28T04:16:34.884388Z","iopub.status.idle":"2021-08-28T04:16:36.124383Z","shell.execute_reply.started":"2021-08-28T04:16:34.884305Z","shell.execute_reply":"2021-08-28T04:16:36.123482Z"},"trusted":true}},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"papermill":{"duration":0.041678,"end_time":"2021-08-25T05:24:34.069526","exception":false,"start_time":"2021-08-25T05:24:34.027848","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["We do not really care too much about the dataset. The dataset used here is particularly nice. No issues. Idea is that we have text data in the form of a movie review, along with its sentiment classification. We will build a **sentiment classifier** using an ensemble of three models."],"metadata":{"papermill":{"duration":0.041795,"end_time":"2021-08-25T05:24:34.152993","exception":false,"start_time":"2021-08-25T05:24:34.111198","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":2,"source":["df = pd.read_csv('../input/kumarmanoj-bag-of-words-meets-bags-of-popcorn/labeledTrainData.tsv', sep='\\t')\n","df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       id  sentiment                                             review\n","0  5814_8          1  With all this stuff going down at the moment w...\n","1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n","2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n","3  3630_4          0  It must be assumed that those who praised this...\n","4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5814_8</td>\n","      <td>1</td>\n","      <td>With all this stuff going down at the moment w...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2381_9</td>\n","      <td>1</td>\n","      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7759_3</td>\n","      <td>0</td>\n","      <td>The film starts with a manager (Nicholas Bell)...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3630_4</td>\n","      <td>0</td>\n","      <td>It must be assumed that those who praised this...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9495_8</td>\n","      <td>1</td>\n","      <td>Superbly trashy and wondrously unpretentious 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":2}],"metadata":{"papermill":{"duration":1.050901,"end_time":"2021-08-25T05:24:35.245833","exception":false,"start_time":"2021-08-25T05:24:34.194932","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:36.125627Z","iopub.execute_input":"2021-08-28T04:16:36.125889Z","iopub.status.idle":"2021-08-28T04:16:37.032294Z","shell.execute_reply.started":"2021-08-28T04:16:36.125863Z","shell.execute_reply":"2021-08-28T04:16:37.031376Z"},"trusted":true}},{"cell_type":"markdown","source":["### Train and test split"],"metadata":{"papermill":{"duration":0.042609,"end_time":"2021-08-25T05:24:35.33184","exception":false,"start_time":"2021-08-25T05:24:35.289231","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":3,"source":["df_train, df_test = model_selection.train_test_split(df, test_size=0.20)\n","print(df_train.shape, df_test.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["(20000, 3) (5000, 3)\n"]}],"metadata":{"papermill":{"duration":0.057532,"end_time":"2021-08-25T05:24:35.432258","exception":false,"start_time":"2021-08-25T05:24:35.374726","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.033755Z","iopub.execute_input":"2021-08-28T04:16:37.034036Z","iopub.status.idle":"2021-08-28T04:16:37.045395Z","shell.execute_reply.started":"2021-08-28T04:16:37.033990Z","shell.execute_reply":"2021-08-28T04:16:37.044522Z"},"trusted":true}},{"cell_type":"markdown","source":["### Cross-validation folds"],"metadata":{"papermill":{"duration":0.043332,"end_time":"2021-08-25T05:24:35.518862","exception":false,"start_time":"2021-08-25T05:24:35.47553","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Here we create cross-validation folds. Very important for evaluating models, and creating Level 1 features that are not overfitted."],"metadata":{"papermill":{"duration":0.042668,"end_time":"2021-08-25T05:24:35.60639","exception":false,"start_time":"2021-08-25T05:24:35.563722","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":4,"source":["df_train.loc[:, 'kfold'] = -1 \n","df_train = df_train.sample(frac=1.0).reset_index(drop=True)\n","y = df_train['sentiment'].values\n","\n","skf = model_selection.StratifiedKFold(n_splits=NUM_FOLDS)\n","for f, (t_, v_) in enumerate(skf.split(X=df_train, y=y)):\n","    df_train.loc[v_, \"kfold\"] = f"],"outputs":[],"metadata":{"papermill":{"duration":0.077843,"end_time":"2021-08-25T05:24:35.727222","exception":false,"start_time":"2021-08-25T05:24:35.649379","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.047184Z","iopub.execute_input":"2021-08-28T04:16:37.047556Z","iopub.status.idle":"2021-08-28T04:16:37.073338Z","shell.execute_reply.started":"2021-08-28T04:16:37.047518Z","shell.execute_reply":"2021-08-28T04:16:37.072404Z"},"trusted":true}},{"cell_type":"code","execution_count":5,"source":["df_train.kfold.value_counts()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    4000\n","1    4000\n","2    4000\n","3    4000\n","4    4000\n","Name: kfold, dtype: int64"]},"metadata":{},"execution_count":5}],"metadata":{"papermill":{"duration":0.057671,"end_time":"2021-08-25T05:24:35.828261","exception":false,"start_time":"2021-08-25T05:24:35.77059","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.074449Z","iopub.execute_input":"2021-08-28T04:16:37.074707Z","iopub.status.idle":"2021-08-28T04:16:37.084583Z","shell.execute_reply.started":"2021-08-28T04:16:37.074674Z","shell.execute_reply":"2021-08-28T04:16:37.083660Z"},"trusted":true}},{"cell_type":"markdown","source":["## Stacking and Blending"],"metadata":{"papermill":{"duration":0.043496,"end_time":"2021-08-25T05:24:35.915597","exception":false,"start_time":"2021-08-25T05:24:35.872101","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["We define a class that automates training and prediction of stacked models. Several models can be trained on the training set whose predict probabilities can be used as feature for a further metamodel called a **stacker**. Observe that this process can be iterated to several more levels. To avoid creating meta features that are overfitted to the train set, the meta features are generated by out-of-fold (OOF) training and prediction of the models on the features of the previous level. This requires defining cross-validation folds. The same cross-validation folds will be used to generate metafeatures at deeper levels. This will be justified later. \n","\n","After generating metafeatures, the models will be retrained on the whole training set (not just on train folds). This increases accuracy of prediction on the test set. Finally, prediction on the test set will simulate conditions when the model was trained &mdash; essentially the test set acts like an extra validation fold.\n","\n","\n",":::{note}\n","Alternatively, we could make predictions on the test dataset using each base model immediately after it gets fitted on each fold. In our case, this would generate test-set predictions for five of each base models. Then, we would average the predictions per model to generate our level 1 meta features.\n","\n","One benefit to this is that it’s less time consuming than the first approach (since we don’t have to retrain each model on the full training dataset). It also helps that our train meta features and test meta features should follow a similar distribution. However, the test meta features are likely more accurate in the first approach since each base model was trained on the full training dataset (as opposed to 80% of the training dataset, five times in the 2nd approach).\n",":::\n","\n"],"metadata":{"papermill":{"duration":0.043947,"end_time":"2021-08-25T05:24:36.003197","exception":false,"start_time":"2021-08-25T05:24:35.95925","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["### Implementation"],"metadata":{"papermill":{"duration":0.044259,"end_time":"2021-08-25T05:24:36.091261","exception":false,"start_time":"2021-08-25T05:24:36.047002","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":6,"source":["class StackingClassifier:\n","    \"\"\"Implements model stacking for classification.\"\"\"\n","    \n","    def __init__(self, model_dict_list):\n","        \"\"\"Initialize by passing a list of dictionaries of name-model pairs \n","        for each level.\"\"\"\n","        \n","        self.model_dict_list = model_dict_list\n","        self.cv_scores_ = {}\n","        self.metafeatures_ = None\n","        \n","    def fit(self, df):\n","        \"\"\"Fit classifier. This assumes `df` is a DataFrame with \"id\", \"kfold\", \n","        \"sentiment\" (target) columns, followed by features columns.\"\"\"\n","        \n","        df = df.copy()\n","        \n","        # Iterating over all stacking levels\n","        metafeatures = []\n","        for m in range(len(self.model_dict_list)):\n","            \n","            # Get models in current layer\n","            model_dict = self.model_dict_list[m]\n","            level = m + 1\n","            \n","            # Identify feature columns, i.e. preds of prev. layer\n","            if m == 0:\n","                feature_cols = ['review']\n","            else:\n","                prev_level_names = self.model_dict_list[m-1].keys()\n","                feature_cols = [f'{name}_{level-1}' for name in prev_level_names]\n","            \n","            # Iterate over models in the current layer\n","            for model_name in model_dict.keys():\n","                print(f'\\nLevel {level} preds: {model_name}')\n","                self.cv_scores_[f'{model_name}_{level}'] = []\n","                model = model_dict[model_name]\n","                \n","                # Generate feature for next layer models from OOF preds\n","                oof_preds = []\n","                for j in range(df.kfold.nunique()):\n","                    oof_pred, oof_auc = self._oof_pred(df, feature_cols, model, \n","                                                        model_name, fold=j, level=level)\n","                    oof_preds.append(oof_pred)\n","                    self.cv_scores_[f'{model_name}_{level}'].append(oof_auc)\n","                \n","                pred = pd.concat(oof_preds)\n","                df = df.merge(pred[['id', f'{model_name}_{level}']], on='id', how='left')   \n","                metafeatures.append(f'{model_name}_{level}')\n","        \n","                # Train models on entire feature columns for inference\n","                model.fit(df[feature_cols], df.sentiment.values)\n","        \n","        self.metafeatures_ = df[metafeatures]\n","        return self\n","        \n","    def predict_proba(self, test_df):\n","        \"\"\"Return classification probabilities.\"\"\"\n","        \n","        test_df = test_df.copy()\n","        \n","        # Iterate over layers to make predictions\n","        for m in range(len(self.model_dict_list)):\n","            \n","            # Get models for current layer\n","            model_dict = self.model_dict_list[m]\n","            level = m + 1\n","            \n","            # Get feature columns to use for prediction\n","            if m == 0:\n","                feature_cols = ['review']\n","            else:\n","                prev_names = self.model_dict_list[m-1].keys()\n","                feature_cols = [f\"{model_name}_{level-1}\" for model_name in prev_names]\n","\n","            # Append predictions to test DataFrame\n","            for model_name in model_dict.keys():\n","                model = model_dict[model_name]\n","                pred = model.predict_proba(test_df[feature_cols])[:, 1] \n","                test_df.loc[:, f\"{model_name}_{level}\"] = pred\n","                    \n","        # Return last predictions\n","        return np.c_[1 - pred, pred]\n","        \n","    def _oof_pred(self, df, feature_cols, model, model_name, fold, level):\n","        \"Train on K-1 folds, predict on fold K. Return OOF predictions with IDs.\"\n","\n","        # Get folds; include ID and target cols, and feature cols\n","        df_trn = df[df.kfold != fold][['id', 'sentiment']+feature_cols]\n","        df_oof = df[df.kfold == fold][['id', 'sentiment']+feature_cols]\n","        \n","        # Fit model.\n","        model.fit(df_trn[feature_cols], df_trn.sentiment.values)\n","        oof_pred = model.predict_proba(df_oof[feature_cols])[:, 1] \n","        auc = metrics.roc_auc_score(df_oof.sentiment.values, oof_pred)\n","        print(f\"fold={fold}, auc={auc}\")\n","\n","        # Return OOF predictions with ids\n","        df_oof.loc[:, f\"{model_name}_{level}\"] = oof_pred\n","        return df_oof[[\"id\", f\"{model_name}_{level}\"]], auc"],"outputs":[],"metadata":{"papermill":{"duration":0.067336,"end_time":"2021-08-25T05:24:36.202652","exception":false,"start_time":"2021-08-25T05:24:36.135316","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.085896Z","iopub.execute_input":"2021-08-28T04:16:37.086180Z","iopub.status.idle":"2021-08-28T04:16:37.101111Z","shell.execute_reply.started":"2021-08-28T04:16:37.086154Z","shell.execute_reply":"2021-08-28T04:16:37.100092Z"},"trusted":true}},{"cell_type":"markdown","source":["### Blending"],"metadata":{"papermill":{"duration":0.042941,"end_time":"2021-08-25T05:24:36.289237","exception":false,"start_time":"2021-08-25T05:24:36.246296","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Let's start with a simple stacked model where we simply perform a weighted average of the prediction probabilities. This method is called **blending**. We will use three base models to generate probabilities. Hopefully these are uncorrelated:\n","1. Logistic Regression + TF-IDF\n","2. Logistic Regression + Count Vectorizer\n","3. Random Forest + TF-IDF + SVD"],"metadata":{"execution":{"iopub.execute_input":"2021-08-23T17:34:52.241474Z","iopub.status.busy":"2021-08-23T17:34:52.240952Z","iopub.status.idle":"2021-08-23T17:34:52.256728Z","shell.execute_reply":"2021-08-23T17:34:52.255385Z","shell.execute_reply.started":"2021-08-23T17:34:52.241439Z"},"papermill":{"duration":0.04338,"end_time":"2021-08-25T05:24:36.376446","exception":false,"start_time":"2021-08-25T05:24:36.333066","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":7,"source":["class ReviewColumnExtractor(BaseEstimator, ClassifierMixin):\n","    \"\"\"Extract text column, e.g. letting X = df_train[['review']]\n","    as train dataset for TfidfVectorizer and CountVectorizer does\n","    not work as expected.\"\"\"\n","    \n","    def __init__(self):\n","        pass\n","    \n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X):\n","        return X.review"],"outputs":[],"metadata":{"papermill":{"duration":0.053303,"end_time":"2021-08-25T05:24:36.473674","exception":false,"start_time":"2021-08-25T05:24:36.420371","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.102242Z","iopub.execute_input":"2021-08-28T04:16:37.102512Z","iopub.status.idle":"2021-08-28T04:16:37.112709Z","shell.execute_reply.started":"2021-08-28T04:16:37.102486Z","shell.execute_reply":"2021-08-28T04:16:37.112031Z"},"trusted":true}},{"cell_type":"markdown","source":["Initialize base models:"],"metadata":{"papermill":{"duration":0.045187,"end_time":"2021-08-25T05:24:36.562247","exception":false,"start_time":"2021-08-25T05:24:36.51706","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":8,"source":["lr = make_pipeline(\n","    ReviewColumnExtractor(),\n","    TfidfVectorizer(max_features=1000),\n","    linear_model.LogisticRegression()\n",")\n","\n","lr_cnt = make_pipeline(\n","    ReviewColumnExtractor(),\n","    CountVectorizer(),\n","    linear_model.LogisticRegression(solver='liblinear')\n",")\n","\n","rf_svd = make_pipeline(\n","    ReviewColumnExtractor(),\n","    TfidfVectorizer(max_features=None),\n","    decomposition.TruncatedSVD(n_components=120),\n","    ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",")"],"outputs":[],"metadata":{"papermill":{"duration":0.054259,"end_time":"2021-08-25T05:24:36.660427","exception":false,"start_time":"2021-08-25T05:24:36.606168","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.114473Z","iopub.execute_input":"2021-08-28T04:16:37.114847Z","iopub.status.idle":"2021-08-28T04:16:37.122200Z","shell.execute_reply.started":"2021-08-28T04:16:37.114819Z","shell.execute_reply":"2021-08-28T04:16:37.121552Z"},"trusted":true}},{"cell_type":"markdown","source":["Run training:"],"metadata":{"papermill":{"duration":0.043308,"end_time":"2021-08-25T05:24:36.747089","exception":false,"start_time":"2021-08-25T05:24:36.703781","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":9,"source":["basemodels = {'lr': lr, 'lr_cnt': lr_cnt, 'rf_svd': rf_svd}\n","stack = StackingClassifier([basemodels])\n","stack.fit(df_train)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 1 preds: rf_svd\n","fold=0, auc=0.8823409705852426\n","fold=1, auc=0.8770538442634611\n","fold=2, auc=0.8744843436210858\n","fold=3, auc=0.8865643466410866\n","fold=4, auc=0.8681016181016181\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.StackingClassifier at 0x7f318f360150>"]},"metadata":{},"execution_count":9}],"metadata":{"papermill":{"duration":265.536154,"end_time":"2021-08-25T05:29:02.327619","exception":false,"start_time":"2021-08-25T05:24:36.791465","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:16:37.123441Z","iopub.execute_input":"2021-08-28T04:16:37.123834Z","iopub.status.idle":"2021-08-28T04:19:26.443942Z","shell.execute_reply.started":"2021-08-28T04:16:37.123807Z","shell.execute_reply":"2021-08-28T04:19:26.443029Z"},"trusted":true}},{"cell_type":"markdown","source":["Check if basemodels are uncorrelated:"],"metadata":{"papermill":{"duration":0.049309,"end_time":"2021-08-25T05:29:02.426813","exception":false,"start_time":"2021-08-25T05:29:02.377504","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":10,"source":["stack.metafeatures_.corr()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["              lr_1  lr_cnt_1  rf_svd_1\n","lr_1      1.000000  0.888349  0.830946\n","lr_cnt_1  0.888349  1.000000  0.727274\n","rf_svd_1  0.830946  0.727274  1.000000"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>lr_1</th>\n","      <td>1.000000</td>\n","      <td>0.888349</td>\n","      <td>0.830946</td>\n","    </tr>\n","    <tr>\n","      <th>lr_cnt_1</th>\n","      <td>0.888349</td>\n","      <td>1.000000</td>\n","      <td>0.727274</td>\n","    </tr>\n","    <tr>\n","      <th>rf_svd_1</th>\n","      <td>0.830946</td>\n","      <td>0.727274</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":10}],"metadata":{"papermill":{"duration":0.065366,"end_time":"2021-08-25T05:29:02.541873","exception":false,"start_time":"2021-08-25T05:29:02.476507","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:26.445780Z","iopub.execute_input":"2021-08-28T04:19:26.446098Z","iopub.status.idle":"2021-08-28T04:19:26.457043Z","shell.execute_reply.started":"2021-08-28T04:19:26.446068Z","shell.execute_reply":"2021-08-28T04:19:26.456309Z"},"trusted":true}},{"cell_type":"markdown","source":["The model saves learned probabilistic features:"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["stack.metafeatures_.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       lr_1  lr_cnt_1  rf_svd_1\n","0  0.414118  0.761635      0.28\n","1  0.982611  0.999355      0.86\n","2  0.102193  0.000345      0.40\n","3  0.820037  0.999539      0.67\n","4  0.842690  0.965732      0.69"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.414118</td>\n","      <td>0.761635</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.982611</td>\n","      <td>0.999355</td>\n","      <td>0.86</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.102193</td>\n","      <td>0.000345</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.820037</td>\n","      <td>0.999539</td>\n","      <td>0.67</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.842690</td>\n","      <td>0.965732</td>\n","      <td>0.69</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":11}],"metadata":{"papermill":{"duration":0.064271,"end_time":"2021-08-25T05:29:02.656422","exception":false,"start_time":"2021-08-25T05:29:02.592151","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:26.457993Z","iopub.execute_input":"2021-08-28T04:19:26.458359Z","iopub.status.idle":"2021-08-28T04:19:26.467734Z","shell.execute_reply.started":"2021-08-28T04:19:26.458333Z","shell.execute_reply":"2021-08-28T04:19:26.466877Z"},"trusted":true}},{"cell_type":"markdown","source":["We can also check scores of the base models on each validation fold. This informs us of the stability of the folds and the cross-validation performance of the base models. "],"metadata":{"papermill":{"duration":0.050436,"end_time":"2021-08-25T05:29:02.758225","exception":false,"start_time":"2021-08-25T05:29:02.707789","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":12,"source":["pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1  rf_svd_1\n","mean  0.934775  0.944390  0.877709\n","std   0.002778  0.002634  0.007124"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944390</td>\n","      <td>0.877709</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002634</td>\n","      <td>0.007124</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":12}],"metadata":{"papermill":{"duration":0.077227,"end_time":"2021-08-25T05:29:02.886214","exception":false,"start_time":"2021-08-25T05:29:02.808987","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:26.468677Z","iopub.execute_input":"2021-08-28T04:19:26.469079Z","iopub.status.idle":"2021-08-28T04:19:26.501717Z","shell.execute_reply.started":"2021-08-28T04:19:26.469046Z","shell.execute_reply":"2021-08-28T04:19:26.500712Z"},"trusted":true}},{"cell_type":"markdown","source":["Let's try to blend the probabilities using some hand-designed coefficients."],"metadata":{"papermill":{"duration":0.051017,"end_time":"2021-08-25T05:29:02.988376","exception":false,"start_time":"2021-08-25T05:29:02.937359","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":13,"source":["target = df_train.sentiment.values\n","\n","# roc is scale invariant, so we dont bother dividing by total weights\n","avg_preds = (stack.metafeatures_ * [1, 1, 1]).sum(axis=1)\n","wtd_preds = (stack.metafeatures_ * [1, 3, 1]).sum(axis=1)\n","rank_avg_preds = (stack.metafeatures_.rank() * [1, 1, 1]).sum(axis=1)\n","rank_wtd_preds = (stack.metafeatures_.rank() * [1, 3, 1]).sum(axis=1)\n","\n","# Calculate AUC over combined OOF preds\n","print(f\"Train OOF-AUC (averaged):     \", metrics.roc_auc_score(target, avg_preds))\n","print(f\"Train OOF-AUC (wtd. avg):     \", metrics.roc_auc_score(target, wtd_preds))\n","print(f\"Train OOF-AUC (rank avg):     \", metrics.roc_auc_score(target, rank_avg_preds)) \n","print(f\"Train OOF-AUC (wtd. rank avg):\", metrics.roc_auc_score(target, rank_wtd_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train OOF-AUC (averaged):      0.9476556811560451\n","Train OOF-AUC (wtd. avg):      0.9490704516653627\n","Train OOF-AUC (rank avg):      0.9429212994516678\n","Train OOF-AUC (wtd. rank avg): 0.9489835016340605\n"]}],"metadata":{"papermill":{"duration":0.117588,"end_time":"2021-08-25T05:29:03.157689","exception":false,"start_time":"2021-08-25T05:29:03.040101","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:26.503097Z","iopub.execute_input":"2021-08-28T04:19:26.503393Z","iopub.status.idle":"2021-08-28T04:19:26.562431Z","shell.execute_reply.started":"2021-08-28T04:19:26.503363Z","shell.execute_reply":"2021-08-28T04:19:26.561467Z"},"trusted":true}},{"cell_type":"markdown","source":["Since these coefficients are hand-designed, we may want to devise a strategy for automatically finding the optimal coefficients for blending. This is accomplished by the folowing class."],"metadata":{"papermill":{"duration":0.051642,"end_time":"2021-08-25T05:29:03.26143","exception":false,"start_time":"2021-08-25T05:29:03.209788","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":14,"source":["class Blender(BaseEstimator, ClassifierMixin):\n","    \"\"\"Implement blending that maximizes AUC score.\"\"\"\n","    \n","    def __init__(self, rank=False, random_state=42):\n","        self.coef_ = None\n","        self.rank = rank\n","        self.random_state = random_state\n","\n","    def fit(self, X, y):\n","        \"\"\"Find optimal blending coefficients.\"\"\"\n","        \n","        if self.rank:\n","            X = X.rank()\n","\n","        self.coef_ = self._optimize_auc(X, y)\n","        return self\n","\n","    def predict_proba(self, X):\n","        \"\"\"Return blended probabilities for class 0 and class 1.\"\"\"\n","        \n","        if self.rank:\n","            X = X.rank()\n","            \n","        pred = np.sum(X * self.coef_, axis=1)\n","        return np.c_[1 - pred, pred]\n","\n","    def _auc(self, coef, X, y):\n","        \"\"\"Calculate AUC of blended predict probas.\"\"\"\n","\n","        auc = metrics.roc_auc_score(y, np.sum(X * coef, axis=1))\n","        return -1.0 * auc # min -auc = max auc\n","    \n","    def _optimize_auc(self, X, y):\n","        \"\"\"Maximize AUC as a bound-constrained optimization problem using Nelder-Mead \n","        method with Dirichlet init. \n","        \n","        Reference: \n","        https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n","        \"\"\"\n","        partial_loss = partial(self._auc, X=X, y=y) \n","        rng = np.random.RandomState(self.random_state)\n","        init_coef = rng.dirichlet(np.ones(X.shape[1]))\n","        return minimize(partial_loss, init_coef, \n","                        method='Nelder-Mead', \n","                        bounds=[(0, 1)]*X.shape[1])['x']"],"outputs":[],"metadata":{"papermill":{"duration":0.067038,"end_time":"2021-08-25T05:29:03.380043","exception":false,"start_time":"2021-08-25T05:29:03.313005","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:26.563402Z","iopub.execute_input":"2021-08-28T04:19:26.563657Z","iopub.status.idle":"2021-08-28T04:19:26.572629Z","shell.execute_reply.started":"2021-08-28T04:19:26.563632Z","shell.execute_reply":"2021-08-28T04:19:26.571645Z"},"trusted":true}},{"cell_type":"markdown","source":["This implementation uses `partial` from `functools` and `minimize` from `scipy.optimize` to minimize the coefficients constained in $(0, 1).$ The initial values of the coefficient are drawn from a Dirichlet distribution $\\operatorname{Dir}(\\boldsymbol{\\alpha})$ with $\\boldsymbol{\\alpha} = [1, 1, 1].$"],"metadata":{"papermill":{"duration":0.051135,"end_time":"2021-08-25T05:29:03.482364","exception":false,"start_time":"2021-08-25T05:29:03.431229","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":15,"source":["target = df_train.sentiment.values\n","\n","# Blended predictions\n","blender = Blender()\n","blender.fit(stack.metafeatures_, target)\n","combined_oof_preds = (stack.metafeatures_ * blender.coef_).sum(axis=1)\n","\n","# Blended ranked predictions\n","blender_rk = Blender(rank=True)\n","blender_rk.fit(stack.metafeatures_, target)\n","combined_oof_rk_preds = (stack.metafeatures_.rank() * blender_rk.coef_).sum(axis=1)\n","\n","print(f\"Train OOF-AUC (Blended):    \", metrics.roc_auc_score(target, combined_oof_preds))\n","print(f\"Train OOF-AUC (Blended rk.):\", metrics.roc_auc_score(target, combined_oof_rk_preds))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train OOF-AUC (Blended):     0.9494805318129915\n","Train OOF-AUC (Blended rk.): 0.9499305419749952\n"]}],"metadata":{"papermill":{"duration":2.133792,"end_time":"2021-08-25T05:29:05.667546","exception":false,"start_time":"2021-08-25T05:29:03.533754","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:26.573735Z","iopub.execute_input":"2021-08-28T04:19:26.573986Z","iopub.status.idle":"2021-08-28T04:19:28.391184Z","shell.execute_reply.started":"2021-08-28T04:19:26.573962Z","shell.execute_reply":"2021-08-28T04:19:28.390365Z"},"trusted":true}},{"cell_type":"markdown","source":["Note that Train OOF-AUC is not the same as train AUC. However, this should be a better approximation of the test AUC. Calculating the AUC on the entire out-of-fold predictions involves tracking the rows of the confusion matrix, which is the sum of the confusion matrix of each fold, over all thresholds. On the other hand, the latter approach tracks each confusion matrix separately, then averages the individual AUCs. The two should be similar to cross-validation scores if error is well-distributed between folds &mdash; and we are blending probabilities. [^ref]\n","\n","[^ref]: For some reason OOF-AUC is bad when blending ranking models, e.g. linear regression, with usual classifiers, even after transforming predict probabilities to rank."],"metadata":{"papermill":{"duration":0.051458,"end_time":"2021-08-25T05:29:05.770877","exception":false,"start_time":"2021-08-25T05:29:05.719419","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":16,"source":["# Inference\n","test_target = df_test.sentiment.values\n","test_features = []\n","for model_name in basemodels.keys():\n","    test_features.append(basemodels[model_name].predict_proba(df_test)[:, 1])\n","\n","test_pred = (pd.DataFrame(np.c_[test_features].T) * blender.coef_).sum(axis=1)\n","test_rk_pred = (pd.DataFrame(np.c_[test_features].T) * blender_rk.coef_).sum(axis=1)\n","print('Test AUC (Blended):    ', metrics.roc_auc_score(test_target, test_pred))\n","print('Test AUC (Blended rk.):', metrics.roc_auc_score(test_target, test_rk_pred))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Test AUC (Blended):     0.9442348787929018\n","Test AUC (Blended rk.): 0.9442668789772228\n"]}],"metadata":{"papermill":{"duration":4.333456,"end_time":"2021-08-25T05:29:10.156338","exception":false,"start_time":"2021-08-25T05:29:05.822882","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:28.392159Z","iopub.execute_input":"2021-08-28T04:19:28.392398Z","iopub.status.idle":"2021-08-28T04:19:31.067817Z","shell.execute_reply.started":"2021-08-28T04:19:28.392374Z","shell.execute_reply":"2021-08-28T04:19:31.066935Z"},"trusted":true}},{"cell_type":"markdown","source":[":::{tip}\n","Using blended **rank probabilities** is a good trick when optimizing AUC score. Here individual probabilities are replaced by their rank index. Recall that AUC only cares about the predict probability of a randomly chosen negative examples to be assigned lower predict proba than a randomly chosen positive example. Note that this only works for ensembles; for single models using rank probabilities does not affect AUC score.\n",":::"],"metadata":{"papermill":{"duration":0.051986,"end_time":"2021-08-25T05:29:10.260625","exception":false,"start_time":"2021-08-25T05:29:10.208639","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["### XGB Metamodel"],"metadata":{"papermill":{"duration":0.052289,"end_time":"2021-08-25T05:29:10.365292","exception":false,"start_time":"2021-08-25T05:29:10.313003","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Blending can be easily generalized to more complex machine learning model that learns and predicts with the metafeatures using more complex algorithms. For example, we can use `XGBoostClassifier`."],"metadata":{"papermill":{"duration":0.051887,"end_time":"2021-08-25T05:29:10.469215","exception":false,"start_time":"2021-08-25T05:29:10.417328","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":17,"source":["basemodels = {'lr': lr, 'lr_cnt': lr_cnt, 'rf_svd': rf_svd}\n","metamodel = {'xgb': XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)}\n","stack = StackingClassifier([basemodels, metamodel])\n","stack.fit(df_train)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 1 preds: rf_svd\n","fold=0, auc=0.8860449715112428\n","fold=1, auc=0.8800172200043049\n","fold=2, auc=0.8816349704087426\n","fold=3, auc=0.8886420971605242\n","fold=4, auc=0.8707864957864959\n","\n","Level 2 preds: xgb\n","fold=0, auc=0.9477989869497467\n","fold=1, auc=0.9475459868864966\n","fold=2, auc=0.9424769856192465\n","fold=3, auc=0.9470486117621529\n","fold=4, auc=0.9410519410519409\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.StackingClassifier at 0x7f317c296c90>"]},"metadata":{},"execution_count":17}],"metadata":{"papermill":{"duration":271.700866,"end_time":"2021-08-25T05:33:42.222567","exception":false,"start_time":"2021-08-25T05:29:10.521701","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:19:31.069058Z","iopub.execute_input":"2021-08-28T04:19:31.069397Z","iopub.status.idle":"2021-08-28T04:22:25.041286Z","shell.execute_reply.started":"2021-08-28T04:19:31.069364Z","shell.execute_reply":"2021-08-28T04:22:25.040428Z"},"trusted":true}},{"cell_type":"code","execution_count":18,"source":["y_train = df_train.sentiment.values\n","y_test = df_test.sentiment.values\n","\n","print(f\"Train AUC (XGB stack):\", metrics.roc_auc_score(y_train, stack.predict_proba(df_train)[:, 1]))\n","print(f\"Test AUC  (XGB stack):\", metrics.roc_auc_score(y_test, stack.predict_proba(df_test)[:, 1]))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train AUC (XGB stack): 0.9998812899572643\n","Test AUC  (XGB stack): 0.940547417553125\n"]}],"metadata":{"papermill":{"duration":21.236097,"end_time":"2021-08-25T05:34:03.51935","exception":false,"start_time":"2021-08-25T05:33:42.283253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:22:25.042422Z","iopub.execute_input":"2021-08-28T04:22:25.042735Z","iopub.status.idle":"2021-08-28T04:22:37.937147Z","shell.execute_reply.started":"2021-08-28T04:22:25.042708Z","shell.execute_reply":"2021-08-28T04:22:37.936460Z"},"trusted":true}},{"cell_type":"code","execution_count":19,"source":["pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1  rf_svd_1     xgb_2\n","mean  0.934775  0.944390  0.881425  0.945185\n","std   0.002778  0.002634  0.006867  0.003174"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","      <th>xgb_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944390</td>\n","      <td>0.881425</td>\n","      <td>0.945185</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002634</td>\n","      <td>0.006867</td>\n","      <td>0.003174</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":19}],"metadata":{"papermill":{"duration":0.102779,"end_time":"2021-08-25T05:34:03.692574","exception":false,"start_time":"2021-08-25T05:34:03.589795","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:22:37.938037Z","iopub.execute_input":"2021-08-28T04:22:37.938366Z","iopub.status.idle":"2021-08-28T04:22:37.958744Z","shell.execute_reply.started":"2021-08-28T04:22:37.938341Z","shell.execute_reply":"2021-08-28T04:22:37.957762Z"},"trusted":true}},{"cell_type":"markdown","source":["Observe that cross-validated AUC scores is indicative of test performance. Meanwhile, train AUC is useless. A better estimate is the mean cross-validation AUC score. If we assume that each fold has the same error distribution, then this should approximate the test AUC which can be thought of as predicting on another fold. Indeed, the above results supports this."],"metadata":{"papermill":{"duration":0.074551,"end_time":"2021-08-25T05:34:03.844439","exception":false,"start_time":"2021-08-25T05:34:03.769888","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["### Conclusion\n","\n","The above examples of building ensembles with **blending** or **stacking** (e.g. with XGBoost) show that stacked models significantly outperform single models."],"metadata":{"papermill":{"duration":0.061911,"end_time":"2021-08-25T05:34:03.968291","exception":false,"start_time":"2021-08-25T05:34:03.90638","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["## Experiment: CV Folds"],"metadata":{"papermill":{"duration":0.061718,"end_time":"2021-08-25T05:34:04.143822","exception":false,"start_time":"2021-08-25T05:34:04.082104","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Consider stacking three levels of models. Our current implementation does this by keeping the same cross-validation folds when training the level 2 models [^ref2]. It is unclear whether using same folds between levels 1 and 2 affect generalization error. To check this empirically, we compute cv scores with with fold indices shuffled after training each level. This simulates having different cv fold assignment for each training example. We calculate tran and test set AUCs, as well as cv scores. If cv scores decrease and test AUC decrease, while overall train AUC increases, then this indicates using a different validation fold between levels results in overfitting. \n","\n","[^ref2]: GM Abishek Thakur recommends keeping the same folds in [AAAMLP](https://github.com/abhishekkrthakur/approachingalmost/blob/master/AAAMLP.pdf)."],"metadata":{"papermill":{"duration":0.067269,"end_time":"2021-08-25T05:34:04.273319","exception":false,"start_time":"2021-08-25T05:34:04.20605","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":20,"source":["class LinearRegressionClassifier(BaseEstimator, ClassifierMixin):\n","    \"\"\"Linear regression for model-based AUC optimization.\n","    Note that we transform probabilities to rank probabilities!\"\"\"\n","    \n","    def __init__(self): \n","        self.lr = linear_model.LinearRegression()\n","        \n","    def fit(self, X, y):\n","        self.lr.fit(pd.DataFrame(X).rank(), y)\n","        return self\n","        \n","    def predict_proba(self, X):\n","        return np.c_[[0]*len(X), self.lr.predict(pd.DataFrame(X).rank())]"],"outputs":[],"metadata":{"papermill":{"duration":0.071609,"end_time":"2021-08-25T05:34:04.407031","exception":false,"start_time":"2021-08-25T05:34:04.335422","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:22:37.959849Z","iopub.execute_input":"2021-08-28T04:22:37.960107Z","iopub.status.idle":"2021-08-28T04:22:37.965093Z","shell.execute_reply.started":"2021-08-28T04:22:37.960082Z","shell.execute_reply":"2021-08-28T04:22:37.964414Z"},"trusted":true}},{"cell_type":"markdown","source":["Define models for stacking."],"metadata":{"papermill":{"duration":0.06239,"end_time":"2021-08-25T05:34:04.531601","exception":false,"start_time":"2021-08-25T05:34:04.469211","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":21,"source":["# Base models\n","level1 = {\n","    'lr': make_pipeline(\n","        ReviewColumnExtractor(),\n","        TfidfVectorizer(max_features=1000),\n","        linear_model.LogisticRegression()\n","    ), \n","    \n","    'lr_cnt': make_pipeline(\n","        ReviewColumnExtractor(),\n","        CountVectorizer(),\n","        linear_model.LogisticRegression(solver='liblinear')\n","    ), \n","    \n","    'rf_svd': make_pipeline(\n","        ReviewColumnExtractor(),\n","        TfidfVectorizer(max_features=None),\n","        decomposition.TruncatedSVD(n_components=120),\n","        ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1)\n","    )\n","}\n","\n","# Meta models\n","level2 = {\n","    'lr': linear_model.LogisticRegression(),\n","    'linreg': make_pipeline(\n","        StandardScaler(), \n","        LinearRegressionClassifier()\n","    ),\n","    'xgb': XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)\n","}\n","\n","# Blender head: rank true for linear regression\n","level3 = {'blender': Blender(rank=True)}"],"outputs":[],"metadata":{"papermill":{"duration":0.072664,"end_time":"2021-08-25T05:34:04.666405","exception":false,"start_time":"2021-08-25T05:34:04.593741","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:22:37.966152Z","iopub.execute_input":"2021-08-28T04:22:37.966412Z","iopub.status.idle":"2021-08-28T04:22:37.981186Z","shell.execute_reply.started":"2021-08-28T04:22:37.966379Z","shell.execute_reply":"2021-08-28T04:22:37.980318Z"},"trusted":true}},{"cell_type":"markdown","source":["### Same Folds"],"metadata":{"papermill":{"duration":0.062647,"end_time":"2021-08-25T05:34:04.791138","exception":false,"start_time":"2021-08-25T05:34:04.728491","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":22,"source":["# Run training of stack models\n","stack = StackingClassifier([level1, level2, level3])\n","stack.fit(df_train)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 1 preds: rf_svd\n","fold=0, auc=0.8814884703721176\n","fold=1, auc=0.8815248453812113\n","fold=2, auc=0.875981843995461\n","fold=3, auc=0.8860663465165866\n","fold=4, auc=0.8695517445517444\n","\n","Level 2 preds: lr\n","fold=0, auc=0.9509604877401219\n","fold=1, auc=0.951691987922997\n","fold=2, auc=0.9457739864434966\n","fold=3, auc=0.9504322376080596\n","fold=4, auc=0.9435239435239435\n","\n","Level 2 preds: linreg\n","fold=0, auc=0.9511337377834344\n","fold=1, auc=0.9533894883473722\n","fold=2, auc=0.9472134868033718\n","fold=3, auc=0.9516157379039345\n","fold=4, auc=0.9464746964746964\n","\n","Level 2 preds: xgb\n","fold=0, auc=0.9442651110662778\n","fold=1, auc=0.9492149873037468\n","fold=2, auc=0.9422511105627777\n","fold=3, auc=0.9464564866141217\n","fold=4, auc=0.9409905659905661\n","\n","Level 3 preds: blender\n","fold=0, auc=0.9515952378988095\n","fold=1, auc=0.9534702383675596\n","fold=2, auc=0.9473962368490592\n","fold=3, auc=0.9519427379856844\n","fold=4, auc=0.9462506962506962\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.StackingClassifier at 0x7f318c54eb10>"]},"metadata":{},"execution_count":22}],"metadata":{"papermill":{"duration":285.794941,"end_time":"2021-08-25T05:38:50.6486","exception":false,"start_time":"2021-08-25T05:34:04.853659","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:22:37.982272Z","iopub.execute_input":"2021-08-28T04:22:37.982556Z","iopub.status.idle":"2021-08-28T04:25:42.122904Z","shell.execute_reply.started":"2021-08-28T04:22:37.982531Z","shell.execute_reply":"2021-08-28T04:25:42.122202Z"},"trusted":true}},{"cell_type":"code","execution_count":23,"source":["same_train_auc = metrics.roc_auc_score(y_train, stack.predict_proba(df_train)[:, 1])\n","same_test_auc = metrics.roc_auc_score(y_test, stack.predict_proba(df_test)[:, 1])\n","\n","print(f\"Train AUC (same):\", same_train_auc)\n","print(f\"Test AUC  (same):\", same_test_auc)\n","\n","pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train AUC (same): 0.9950402682144966\n","Test AUC  (same): 0.9452795248100628\n"]},{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1  rf_svd_1      lr_2  linreg_2     xgb_2  blender_3\n","mean  0.934775  0.944390  0.878923  0.948477  0.949965  0.944636   0.950131\n","std   0.002778  0.002634  0.006341  0.003611  0.002982  0.003294   0.003127"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>blender_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944390</td>\n","      <td>0.878923</td>\n","      <td>0.948477</td>\n","      <td>0.949965</td>\n","      <td>0.944636</td>\n","      <td>0.950131</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002634</td>\n","      <td>0.006341</td>\n","      <td>0.003611</td>\n","      <td>0.002982</td>\n","      <td>0.003294</td>\n","      <td>0.003127</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":23}],"metadata":{"papermill":{"duration":21.581825,"end_time":"2021-08-25T05:39:12.303618","exception":false,"start_time":"2021-08-25T05:38:50.721793","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:25:42.125868Z","iopub.execute_input":"2021-08-28T04:25:42.126140Z","iopub.status.idle":"2021-08-28T04:25:55.323024Z","shell.execute_reply.started":"2021-08-28T04:25:42.126115Z","shell.execute_reply":"2021-08-28T04:25:55.322096Z"},"trusted":true}},{"cell_type":"code","execution_count":24,"source":["experiment_results = {\n","    'same': {'train': same_train_auc, 'test': same_test_auc}\n","}"],"outputs":[],"metadata":{"papermill":{"duration":0.081404,"end_time":"2021-08-25T05:39:12.462006","exception":false,"start_time":"2021-08-25T05:39:12.380602","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:25:55.325295Z","iopub.execute_input":"2021-08-28T04:25:55.325915Z","iopub.status.idle":"2021-08-28T04:25:55.331102Z","shell.execute_reply.started":"2021-08-28T04:25:55.325875Z","shell.execute_reply":"2021-08-28T04:25:55.330415Z"},"trusted":true}},{"cell_type":"markdown","source":["### Different Folds"],"metadata":{"papermill":{"duration":0.075305,"end_time":"2021-08-25T05:39:12.612154","exception":false,"start_time":"2021-08-25T05:39:12.536849","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Now we train the same model except the folds are shuffled beyond training the level 1 models simulating the use of different cross-validation folds when training higher level models."],"metadata":{"papermill":{"duration":0.074858,"end_time":"2021-08-25T05:39:12.761762","exception":false,"start_time":"2021-08-25T05:39:12.686904","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":25,"source":["class StackingClassifierShuffledCV:\n","    \"\"\"Implements model stacking for classification.\"\"\"\n","    \n","    def __init__(self, model_dict_list):\n","        \"\"\"Initialize by passing `model_dict` which is a list of dictionaries \n","        of name-model pairs for each level.\"\"\"\n","        \n","        self.model_dict_list = model_dict_list\n","        self.cv_scores_ = {}\n","        self.metafeatures_ = None\n","        \n","    def fit(self, df):\n","        \"\"\"Fit classifier. This assumes `df` is a DataFrame with \"id\", \"kfold\", \n","        \"sentiment\" (target) columns, followed by features columns.\"\"\"\n","        \n","        df = df.copy()\n","        \n","        # Iterating over all stacking levels\n","        metafeatures = []\n","        for m in range(len(self.model_dict_list)):\n","            \n","            # Get models in current layer\n","            model_dict = self.model_dict_list[m]\n","            level = m + 1\n","            \n","            # Identify feature columns, i.e. preds of prev. layer\n","            if m == 0:\n","                feature_cols = ['review']\n","            else:\n","                prev_level_names = self.model_dict_list[m-1].keys()\n","                feature_cols = [f'{name}_{level-1}' for name in prev_level_names]\n","                \n","                # Shuffle folds for level 2 models and up <----------- SHUFFLE FOLDS HERE (!)\n","                df['kfold'] = random.sample(df.kfold.tolist(), len(df))\n","            \n","            # Iterate over models in the current layer\n","            for model_name in model_dict.keys():\n","                print(f'\\nLevel {level} preds: {model_name}')\n","                self.cv_scores_[f'{model_name}_{level}'] = []\n","                model = model_dict[model_name]\n","                \n","                # Generate feature for next layer models from OOF preds\n","                oof_preds = []\n","                for j in range(df.kfold.nunique()):\n","                    oof_pred, oof_auc = self._oof_pred(df, feature_cols, model, \n","                                                        model_name, fold=j, level=level)\n","                    oof_preds.append(oof_pred)\n","                    self.cv_scores_[f'{model_name}_{level}'].append(oof_auc)\n","                \n","                pred = pd.concat(oof_preds)\n","                df = df.merge(pred[['id', f'{model_name}_{level}']], on='id', how='left')   \n","                metafeatures.append(f'{model_name}_{level}')\n","        \n","                # Train models on entire feature columns for inference\n","                model.fit(df[feature_cols], df.sentiment.values)\n","        \n","        self.metafeatures_ = df[metafeatures]\n","        return self\n","        \n","    def predict_proba(self, test_df):\n","        \"\"\"Return classification probabilities.\"\"\"\n","        \n","        test_df = test_df.copy()\n","        \n","        # Iterate over layers to make predictions\n","        for m in range(len(self.model_dict_list)):\n","            \n","            # Get models for current layer\n","            model_dict = self.model_dict_list[m]\n","            level = m + 1\n","            \n","            # Get feature columns to use for prediction\n","            if m == 0:\n","                feature_cols = ['review']\n","            else:\n","                prev_names = self.model_dict_list[m-1].keys()\n","                feature_cols = [f\"{model_name}_{level-1}\" for model_name in prev_names]\n","\n","            # Append predictions to test DataFrame\n","            for model_name in model_dict.keys():\n","                model = model_dict[model_name]\n","                pred = model.predict_proba(test_df[feature_cols])[:, 1] \n","                test_df.loc[:, f\"{model_name}_{level}\"] = pred\n","                    \n","        # Return last predictions\n","        return np.c_[1 - pred, pred]\n","        \n","    def _oof_pred(self, df, feature_cols, model, model_name, fold, level):\n","        \"Train on K-1 folds, predict on fold K. Return OOF predictions with IDs.\"\n","\n","        # Get folds; include ID and target cols, and feature cols\n","        df_trn = df[df.kfold != fold][['id', 'sentiment']+feature_cols]\n","        df_oof = df[df.kfold == fold][['id', 'sentiment']+feature_cols]\n","        \n","        # Fit model. \n","        model.fit(df_trn[feature_cols], df_trn.sentiment.values)\n","        oof_pred = model.predict_proba(df_oof[feature_cols])[:, 1] \n","        auc = metrics.roc_auc_score(df_oof.sentiment.values, oof_pred)\n","        print(f\"fold={fold}, auc={auc}\")\n","\n","        # Return OOF predictions with ids\n","        df_oof.loc[:, f\"{model_name}_{level}\"] = oof_pred\n","        return df_oof[[\"id\", f\"{model_name}_{level}\"]], auc"],"outputs":[],"metadata":{"papermill":{"duration":0.100583,"end_time":"2021-08-25T05:39:12.938271","exception":false,"start_time":"2021-08-25T05:39:12.837688","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:25:55.333019Z","iopub.execute_input":"2021-08-28T04:25:55.333851Z","iopub.status.idle":"2021-08-28T04:25:55.354303Z","shell.execute_reply.started":"2021-08-28T04:25:55.333813Z","shell.execute_reply":"2021-08-28T04:25:55.353256Z"},"trusted":true}},{"cell_type":"markdown","source":[":::{danger}\n","The implementation of `StackingClassifier` has a side-effect: models inside the dictionaries are trained. Hence, if we train another model using the same model dictionaries (as we do here in defining `stack_shuffled`), then the models inside the dictionaries will be retrained using a different algorithm. This means calling `stack.predict_proba(df_test)` will yield **different results** before and after training `stack_shuffled`! As usual, the stateful approach is error prone. We can modify the `StackingClassifier` to instead save a list of model dictionaries that are *clones* of the models. This allows all state to be localized within the  stacked model.\n",":::"],"metadata":{"papermill":{"duration":0.075412,"end_time":"2021-08-25T05:39:13.090746","exception":false,"start_time":"2021-08-25T05:39:13.015334","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Start training the stacked model with shuffling of folds:"],"metadata":{"papermill":{"duration":0.079803,"end_time":"2021-08-25T05:39:13.245114","exception":false,"start_time":"2021-08-25T05:39:13.165311","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":26,"source":["stack_shuffled = StackingClassifierShuffledCV([level1, level2, level3])\n","stack_shuffled.fit(df_train)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 1 preds: rf_svd\n","fold=0, auc=0.8810043452510863\n","fold=1, auc=0.8794494698623676\n","fold=2, auc=0.8751435937858985\n","fold=3, auc=0.8883572220893055\n","fold=4, auc=0.8696557446557447\n","\n","Level 2 preds: lr\n","fold=0, auc=0.9494481405126081\n","fold=1, auc=0.946384953621176\n","fold=2, auc=0.9494623583315892\n","fold=3, auc=0.9512430457905252\n","fold=4, auc=0.9458207364551843\n","\n","Level 2 preds: linreg\n","fold=0, auc=0.9516165171734631\n","fold=1, auc=0.9483091588013435\n","fold=2, auc=0.9500184919426893\n","fold=3, auc=0.9522944794852852\n","fold=4, auc=0.9478199869549966\n","\n","Level 2 preds: xgb\n","fold=0, auc=0.9466299510558551\n","fold=1, auc=0.9435907154785806\n","fold=2, auc=0.9446388244775809\n","fold=3, auc=0.9480871186489015\n","fold=4, auc=0.9409969852492464\n","\n","Level 3 preds: blender\n","fold=0, auc=0.9525565056505652\n","fold=1, auc=0.9506891323900849\n","fold=2, auc=0.9515462886572165\n","fold=3, auc=0.94632028522822\n","fold=4, auc=0.9479927819350373\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.StackingClassifierShuffledCV at 0x7f318c5ea290>"]},"metadata":{},"execution_count":26}],"metadata":{"papermill":{"duration":284.057523,"end_time":"2021-08-25T05:43:57.396984","exception":false,"start_time":"2021-08-25T05:39:13.339461","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:25:55.355793Z","iopub.execute_input":"2021-08-28T04:25:55.356239Z","iopub.status.idle":"2021-08-28T04:29:00.028287Z","shell.execute_reply.started":"2021-08-28T04:25:55.356206Z","shell.execute_reply":"2021-08-28T04:29:00.027597Z"},"trusted":true}},{"cell_type":"code","execution_count":27,"source":["shuffled_train_auc = metrics.roc_auc_score(y_train, stack_shuffled.predict_proba(df_train)[:, 1])\n","shuffled_test_auc = metrics.roc_auc_score(y_test, stack_shuffled.predict_proba(df_test)[:, 1])\n","\n","print(f\"Train AUC (shuffled):\", shuffled_train_auc)\n","print(f\"Test AUC  (shuffled):\", shuffled_test_auc)\n","\n","experiment_results['shuffled'] = {'train': shuffled_train_auc, 'test': shuffled_test_auc}"],"outputs":[{"output_type":"stream","name":"stdout","text":["Train AUC (shuffled): 0.9960226985681715\n","Test AUC  (shuffled): 0.9452160044441854\n"]}],"metadata":{"papermill":{"duration":21.575819,"end_time":"2021-08-25T05:44:19.060272","exception":false,"start_time":"2021-08-25T05:43:57.484453","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:29:00.030078Z","iopub.execute_input":"2021-08-28T04:29:00.030432Z","iopub.status.idle":"2021-08-28T04:29:13.190980Z","shell.execute_reply.started":"2021-08-28T04:29:00.030395Z","shell.execute_reply":"2021-08-28T04:29:13.189730Z"},"trusted":true}},{"cell_type":"code","execution_count":28,"source":["pd.DataFrame(experiment_results)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          same  shuffled\n","train  0.99504  0.996023\n","test   0.94528  0.945216"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>same</th>\n","      <th>shuffled</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>train</th>\n","      <td>0.99504</td>\n","      <td>0.996023</td>\n","    </tr>\n","    <tr>\n","      <th>test</th>\n","      <td>0.94528</td>\n","      <td>0.945216</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":28}],"metadata":{"papermill":{"duration":0.102144,"end_time":"2021-08-25T05:44:19.267262","exception":false,"start_time":"2021-08-25T05:44:19.165118","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:29:13.196175Z","iopub.execute_input":"2021-08-28T04:29:13.196612Z","iopub.status.idle":"2021-08-28T04:29:13.219177Z","shell.execute_reply.started":"2021-08-28T04:29:13.196572Z","shell.execute_reply":"2021-08-28T04:29:13.218112Z"},"trusted":true}},{"cell_type":"markdown","source":["Observe that the train AUC increased while test score decreased when using different folds between layers which indicates overfitting. Moreover, if we look at CV scores we see significant decrease in performance for `linreg_2`, `xgb_2`, and `blender_3` $(\\sim 2 \\times 10^{-4})$. On the other hand, standard deviation is generally higher with shuffling which indicates worse fold stability."],"metadata":{"papermill":{"duration":0.086989,"end_time":"2021-08-25T05:44:19.441225","exception":false,"start_time":"2021-08-25T05:44:19.354236","status":"completed"},"tags":[]}},{"cell_type":"code","execution_count":29,"source":["# Shuffled CV scores\n","pd.DataFrame(stack_shuffled.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1  rf_svd_1      lr_2  linreg_2     xgb_2  blender_3\n","mean  0.934775  0.944390  0.878722  0.948472  0.950012  0.944789   0.949821\n","std   0.002778  0.002634  0.006957  0.002291  0.001968  0.002743   0.002589"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>blender_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944390</td>\n","      <td>0.878722</td>\n","      <td>0.948472</td>\n","      <td>0.950012</td>\n","      <td>0.944789</td>\n","      <td>0.949821</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002634</td>\n","      <td>0.006957</td>\n","      <td>0.002291</td>\n","      <td>0.001968</td>\n","      <td>0.002743</td>\n","      <td>0.002589</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":29}],"metadata":{"papermill":{"duration":0.122251,"end_time":"2021-08-25T05:44:19.650143","exception":false,"start_time":"2021-08-25T05:44:19.527892","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:29:13.220727Z","iopub.execute_input":"2021-08-28T04:29:13.221393Z","iopub.status.idle":"2021-08-28T04:29:13.267721Z","shell.execute_reply.started":"2021-08-28T04:29:13.221352Z","shell.execute_reply":"2021-08-28T04:29:13.266812Z"},"trusted":true}},{"cell_type":"code","execution_count":30,"source":["# Same CV scores\n","pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1  rf_svd_1      lr_2  linreg_2     xgb_2  blender_3\n","mean  0.934775  0.944390  0.878923  0.948477  0.949965  0.944636   0.950131\n","std   0.002778  0.002634  0.006341  0.003611  0.002982  0.003294   0.003127"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>rf_svd_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>blender_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944390</td>\n","      <td>0.878923</td>\n","      <td>0.948477</td>\n","      <td>0.949965</td>\n","      <td>0.944636</td>\n","      <td>0.950131</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002634</td>\n","      <td>0.006341</td>\n","      <td>0.003611</td>\n","      <td>0.002982</td>\n","      <td>0.003294</td>\n","      <td>0.003127</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":30}],"metadata":{"papermill":{"duration":0.123152,"end_time":"2021-08-25T05:44:19.861115","exception":false,"start_time":"2021-08-25T05:44:19.737963","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-28T04:29:13.269061Z","iopub.execute_input":"2021-08-28T04:29:13.269430Z","iopub.status.idle":"2021-08-28T04:29:13.301852Z","shell.execute_reply.started":"2021-08-28T04:29:13.269390Z","shell.execute_reply":"2021-08-28T04:29:13.301090Z"},"trusted":true}},{"cell_type":"markdown","source":["### Conclusion\n","\n","Empirical results above strongly indicate that we should use the **same folds** across levels of stacking. The following theoretical example shows that, when using different folds, overfitting can happen due to the second stage model taking advantage of a certain relationship between ground truth and first stage predictions, without this structure generalizing well to the test set.\n","\n","Consider a dataset $\\{(x_1, t_1), (x_2, t_2) \\ldots, (x_{10}, t_{10})\\}$ with five folds such that the first fold is $F_1 = \\{x_1, x_2\\}$. Let $x_1 {\\mapsto} y_1$ and $x_2 \\mapsto y_2$ where the mapping is trained on $F_{\\neg 1} = \\{x_3, \\ldots, x_{10}\\}.$ We can think of modelling on $F_{\\neg 1}$ as defining some rule or distribution that the points in $F_1$ are compared against. Suppose we reshuffle folds in the next level such that the first fold is $G_1 = \\{y_1, y_{10}\\}.$ Then, the model trained on $G_{\\neg 1} = \\{y_2, \\ldots y_9\\}$  overfits slightly since $y_2$ is modelled using the ground truths $(x_3, t_3), \\ldots, (x_{9}, t_9).$ Note that this asymmetry does not apply to the other values $y_3, \\ldots, y_9$ in $G_{\\neg 1}.$ Keeping the same cross-validation scores allow all instances in the train fold are equivalent and prevents any such asymmetry from occurring. \n","\n","Theoretically (as mentioned in the [Kaggle Guide to Model Stacking](https://datasciblog.github.io/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/)), there is always some leakage if you train a second level model on the same training set, which you used to derive the first stage predictions. This is because you used the ground truth to get those first stage predictions, and now you take those predictions as input, and try to predict the same ground truth. However, this leakage doesn't seem to be significant in practice."],"metadata":{"papermill":{"duration":0.089536,"end_time":"2021-08-25T05:44:20.039854","exception":false,"start_time":"2021-08-25T05:44:19.950318","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["## Parallelizing Model Training\n"],"metadata":{"papermill":{"duration":0.089412,"end_time":"2021-08-25T05:44:20.217637","exception":false,"start_time":"2021-08-25T05:44:20.128225","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["Generating features require training one model for each fold. This is very slow. Note that each training process is independent of the other (they only use static features from the previous level), so in principle can be easily parallelized. For this task, we parallelize only the training on cross-validation folds. During inference, parallelizing results in worse times, likely due to overhead. \n","\n","We implement parallelizing training on CV folds using `joblib.Parallel`. Some remarks:\n","\n","* Setting the `backend='loky'` is important. In my MacBook Air 2015 laptop with Mojave 10.14.6, setting `backend='multiprocessing'` with an `XGBClassifier` model causes training to hang. In a Kaggle kernel, `multiprocessing` doesn't seem to work at all, even without using `XGBClassifier`. Not good. Using the `loky` backend seems to work consistently across platforms. \n","\n","+++\n","\n","* Setting `nthread=1` for XGBClassifier decreases train trime from ~246s to ~100s with backend `loky` and `n_jobs=-1`. Note that the former time is way worse than sequential. \n","\n","+++\n","\n","* Joblib pickles every object used inside `Parallel`. Best to use stateless objects. Careful about shared memory.\n","\n","+++\n","\n","* Using `n_jobs=1` enables to turn off parallel computing for debugging.\n","\n","Note that we will start **cloning** models in the `model_dict_list` inside the `StackingCLassifierParallel` object to avoid leaking state outside the object instance. Results below show that there is significant speed up with parallelization using the `loky` backend. Consider this implementation the current stable version of our implementation of stacking."],"metadata":{}},{"cell_type":"code","execution_count":31,"source":["class StackingClassifierParallel(BaseEstimator, ClassifierMixin):\n","    \"\"\"Implements model stacking for classification.\"\"\"\n","    \n","    def __init__(self, model_dict_list, n_jobs=1, backend='loky'):\n","        \"\"\"Initialize by passing `model_dict` which is a list of dictionaries \n","        of name-model pairs for each level. Models should have inter-level\n","        unique names.\"\"\"\n","        \n","        self.model_dict_list = [\n","            { name: clone(model_dict[name]) for name in model_dict } \n","                                            for model_dict in model_dict_list]\n","        self.cv_scores_ = {}\n","        self.metafeatures_ = None\n","        self.n_jobs = n_jobs\n","        self.backend = backend\n","    \n","    def fit(self, df):\n","        \"\"\"Fit classifier. Assumes `df` is a DataFrame with 'id', 'kfold', and \n","        'sentiment' (target) columns, followed by features columns.\"\"\"\n","        \n","        # Iterating over all stacking levels\n","        df = df.copy()\n","        metafeatures = []\n","        for m in tqdm(range(len(self.model_dict_list)), leave=False):\n","            \n","            # Get models in current layer\n","            model_dict = self.model_dict_list[m]\n","            level = m + 1\n","            \n","            # Identify feature columns, i.e. preds of prev. layer\n","            if m == 0:\n","                feature_cols = ['review']\n","            else:\n","                prev_level_names = self.model_dict_list[m-1].keys()\n","                feature_cols = [f'{name}_{level-1}' for name in prev_level_names]\n","            \n","            # Parallel context manager. Prevents discarding of workers for each model\n","            with Parallel(n_jobs=self.n_jobs, backend=self.backend, verbose=1) as parallel:\n","                \n","                # Iterate over models in the current layer\n","                for model_name in tqdm(model_dict.keys(), leave=False):\n","                    \n","                    # Generate feature for next layer models from OOF preds\n","                    # Cloning the model here releases the weights from prev. fit.\n","                    model = model_dict[model_name]\n","                    out = parallel(delayed(self._predict_fold)(\n","                            df, feature_cols, fold,\n","                            model_name, clone(model),\n","                            level\n","                        ) for fold in df.kfold.unique()\n","                    )\n","\n","                    # Load all OOF predictions and AUCs\n","                    fold_preds, cv_scores = list(zip(*out))\n","                    \n","                    # Assign cv scores for model and append predictions to df\n","                    self.cv_scores_[f'{model_name}_{level}'] = cv_scores\n","                    pred_df = pd.concat(fold_preds)\n","                    df = df.merge(pred_df, how='left', on='id')\n","                    metafeatures.append(f'{model_name}_{level}')\n","                    \n","                    # Refit model on entire feature columns for inference\n","                    model.fit(df[feature_cols], df.sentiment)\n","                    \n","        # Save learned metafeatures\n","        self.metafeatures_ = df[metafeatures]\n","        return self\n","    \n","    def predict_proba(self, df):\n","        \"\"\"Return classification probabilities.\"\"\"\n","        \n","        # Iterate over layers to make predictions\n","        df = df.copy()\n","        for m in range(len(self.model_dict_list)):\n","            \n","            # Get models for current layer\n","            model_dict = self.model_dict_list[m]\n","            level = m + 1\n","            \n","            # Get feature columns to use for prediction\n","            if m == 0:\n","                feature_cols = ['review']\n","            else:\n","                prev_names = self.model_dict_list[m-1].keys()\n","                feature_cols = [f\"{model_name}_{level-1}\" for model_name in prev_names]\n","\n","            # Append predictions to test DataFrame\n","            for model_name in model_dict.keys():\n","                model = model_dict[model_name]\n","                pred = model.predict_proba(df[feature_cols])[:, 1] \n","                df.loc[:, f\"{model_name}_{level}\"] = pred\n","                    \n","        # Return last predictions\n","        return np.c_[1 - pred, pred]\n","\n","    def _predict_fold(self, df, feature_cols, fold, model_name, model, level):\n","        \"Make out-of-fold predictions. Return predict probas and AUC.\"\n","        \n","        X_train = df[df.kfold != fold][feature_cols]\n","        y_train = df[df.kfold != fold].sentiment.values\n","        \n","        X_valid = df[df.kfold == fold][feature_cols] \n","        y_valid = df[df.kfold == fold].sentiment.values\n","        pred_id = df[df.kfold == fold].id\n","\n","        # Fit model\n","        model.fit(X_train, y_train)\n","        \n","        # Return fold predictions along with fold AUC\n","        pred = model.predict_proba(X_valid)[:, 1] \n","        auc = metrics.roc_auc_score(y_valid, pred)\n","        return pd.DataFrame({\"id\": pred_id, f\"{model_name}_{level}\": pred}), auc"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:29:13.302883Z","iopub.execute_input":"2021-08-28T04:29:13.303145Z","iopub.status.idle":"2021-08-28T04:29:13.320039Z","shell.execute_reply.started":"2021-08-28T04:29:13.303120Z","shell.execute_reply":"2021-08-28T04:29:13.319130Z"},"trusted":true}},{"cell_type":"markdown","source":["Define the models that we will use at each level."],"metadata":{}},{"cell_type":"code","execution_count":32,"source":["# Base models\n","level1 = {\n","    'lr': make_pipeline(\n","        ReviewColumnExtractor(),\n","        TfidfVectorizer(max_features=1000),\n","        linear_model.LogisticRegression(random_state=42)\n","    ), \n","    \n","    'lr_cnt': make_pipeline(\n","        ReviewColumnExtractor(),\n","        CountVectorizer(), \n","        linear_model.LogisticRegression(solver='liblinear', random_state=42)\n","    ), \n","}\n","\n","# Meta models\n","level2 = {\n","    'lr': linear_model.LogisticRegression(),\n","    'linreg': make_pipeline(StandardScaler(), LinearRegressionClassifier()),\n","    'xgb': XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, nthread=1, random_state=42)\n","}\n","\n","# Meta models\n","level3 = {\n","    'linreg': make_pipeline(StandardScaler(), LinearRegressionClassifier()),\n","    'xgb': XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, nthread=1)\n","}\n","\n","# Blender head: rank true for linear reg.\n","level4 = {'blender': Blender(rank=True, random_state=42)}"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:29:13.321595Z","iopub.execute_input":"2021-08-28T04:29:13.322329Z","iopub.status.idle":"2021-08-28T04:29:13.333677Z","shell.execute_reply.started":"2021-08-28T04:29:13.322292Z","shell.execute_reply":"2021-08-28T04:29:13.332910Z"},"trusted":true}},{"cell_type":"markdown","source":[":::{caution}\n","Setting `nthread=1` for `XGBClassifier` decreases train time for the parallel stacker from ~250s to ~100s. This goes from worse to better than sequential. See also https://github.com/dmlc/xgboost/issues/2163.\n",":::"],"metadata":{}},{"cell_type":"markdown","source":["Start with timing experiments."],"metadata":{}},{"cell_type":"code","execution_count":33,"source":["model_dict_list = [level1, level2, level3, level4]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:29:13.334628Z","iopub.execute_input":"2021-08-28T04:29:13.334864Z","iopub.status.idle":"2021-08-28T04:29:13.346523Z","shell.execute_reply.started":"2021-08-28T04:29:13.334841Z","shell.execute_reply":"2021-08-28T04:29:13.345776Z"},"trusted":true}},{"cell_type":"code","execution_count":34,"source":["times = []\n","for i in range(3):\n","    start_time = time.time()\n","    stack_parallel = StackingClassifierParallel(model_dict_list, n_jobs=-1)\n","    stack_parallel.fit(df_train)\n","    times.append(time.time() - start_time)\n","    \n","times = np.array(times)\n","times.mean(), times.std()"],"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.0s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.3s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.0s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.7s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.0s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.6s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.2s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.0s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.0s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.8s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   23.2s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.4s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.0s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.5s finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.0s finished\n"]},{"output_type":"execute_result","data":{"text/plain":["(80.29500238100688, 2.2682731989272282)"]},"metadata":{},"execution_count":34}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:29:13.347669Z","iopub.execute_input":"2021-08-28T04:29:13.348229Z","iopub.status.idle":"2021-08-28T04:33:14.245185Z","shell.execute_reply.started":"2021-08-28T04:29:13.348188Z","shell.execute_reply":"2021-08-28T04:33:14.244155Z"},"trusted":true}},{"cell_type":"code","execution_count":35,"source":["times = []\n","for i in range(3):\n","    start_time = time.time()\n","    stack = StackingClassifier(model_dict_list)\n","    stack.fit(df_train)\n","    times.append(time.time() - start_time)\n","    \n","times = np.array(times)\n","times.mean(), times.std()"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 2 preds: lr\n","fold=0, auc=0.9508922377230595\n","fold=1, auc=0.9515819878954969\n","fold=2, auc=0.9454064863516216\n","fold=3, auc=0.9496467374116845\n","fold=4, auc=0.9443194443194443\n","\n","Level 2 preds: linreg\n","fold=0, auc=0.950668987667247\n","fold=1, auc=0.9531489882872469\n","fold=2, auc=0.9467019866754967\n","fold=3, auc=0.950918487729622\n","fold=4, auc=0.9466674466674467\n","\n","Level 2 preds: xgb\n","fold=0, auc=0.9467834866958718\n","fold=1, auc=0.9498002374500593\n","fold=2, auc=0.9415947353986839\n","fold=3, auc=0.9475146118786529\n","fold=4, auc=0.9414463164463163\n","\n","Level 3 preds: linreg\n","fold=0, auc=0.9515402378850595\n","fold=1, auc=0.9531754882938721\n","fold=2, auc=0.9466702366675591\n","fold=3, auc=0.951165487791372\n","fold=4, auc=0.9461456961456961\n","\n","Level 3 preds: xgb\n","fold=0, auc=0.9471329867832466\n","fold=1, auc=0.9486733621683405\n","fold=2, auc=0.9440786110196526\n","fold=3, auc=0.9485312371328093\n","fold=4, auc=0.9424353174353175\n","\n","Level 4 preds: blender\n","fold=0, auc=0.951522987880747\n","fold=1, auc=0.9531012382753095\n","fold=2, auc=0.9467809866952468\n","fold=3, auc=0.9512514878128718\n","fold=4, auc=0.9462511962511962\n","\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 2 preds: lr\n","fold=0, auc=0.9508922377230595\n","fold=1, auc=0.9515819878954969\n","fold=2, auc=0.9454064863516216\n","fold=3, auc=0.9496467374116845\n","fold=4, auc=0.9443194443194443\n","\n","Level 2 preds: linreg\n","fold=0, auc=0.950668987667247\n","fold=1, auc=0.9531489882872469\n","fold=2, auc=0.9467019866754967\n","fold=3, auc=0.950918487729622\n","fold=4, auc=0.9466674466674467\n","\n","Level 2 preds: xgb\n","fold=0, auc=0.9467834866958718\n","fold=1, auc=0.9498002374500593\n","fold=2, auc=0.9415947353986839\n","fold=3, auc=0.9475146118786529\n","fold=4, auc=0.9414463164463163\n","\n","Level 3 preds: linreg\n","fold=0, auc=0.9515402378850595\n","fold=1, auc=0.9531754882938721\n","fold=2, auc=0.9466702366675591\n","fold=3, auc=0.951165487791372\n","fold=4, auc=0.9461456961456961\n","\n","Level 3 preds: xgb\n","fold=0, auc=0.9471329867832466\n","fold=1, auc=0.9486733621683405\n","fold=2, auc=0.9440786110196526\n","fold=3, auc=0.9485312371328093\n","fold=4, auc=0.9424353174353175\n","\n","Level 4 preds: blender\n","fold=0, auc=0.951522987880747\n","fold=1, auc=0.9531012382753095\n","fold=2, auc=0.9467809866952468\n","fold=3, auc=0.9512514878128718\n","fold=4, auc=0.9462511962511962\n","\n","Level 1 preds: lr\n","fold=0, auc=0.9359574839893711\n","fold=1, auc=0.9374319843579961\n","fold=2, auc=0.9327744831936209\n","fold=3, auc=0.936746484186621\n","fold=4, auc=0.930962930962931\n","\n","Level 1 preds: lr_cnt\n","fold=0, auc=0.944461736115434\n","fold=1, auc=0.9481647370411844\n","fold=2, auc=0.9413639853409963\n","fold=3, auc=0.9453942363485591\n","fold=4, auc=0.9425671925671927\n","\n","Level 2 preds: lr\n","fold=0, auc=0.9508922377230595\n","fold=1, auc=0.9515819878954969\n","fold=2, auc=0.9454064863516216\n","fold=3, auc=0.9496467374116845\n","fold=4, auc=0.9443194443194443\n","\n","Level 2 preds: linreg\n","fold=0, auc=0.950668987667247\n","fold=1, auc=0.9531489882872469\n","fold=2, auc=0.9467019866754967\n","fold=3, auc=0.950918487729622\n","fold=4, auc=0.9466674466674467\n","\n","Level 2 preds: xgb\n","fold=0, auc=0.9467834866958718\n","fold=1, auc=0.9498002374500593\n","fold=2, auc=0.9415947353986839\n","fold=3, auc=0.9475146118786529\n","fold=4, auc=0.9414463164463163\n","\n","Level 3 preds: linreg\n","fold=0, auc=0.9515402378850595\n","fold=1, auc=0.9531754882938721\n","fold=2, auc=0.9466702366675591\n","fold=3, auc=0.951165487791372\n","fold=4, auc=0.9461456961456961\n","\n","Level 3 preds: xgb\n","fold=0, auc=0.9471329867832466\n","fold=1, auc=0.9486733621683405\n","fold=2, auc=0.9440786110196526\n","fold=3, auc=0.9485312371328093\n","fold=4, auc=0.9424353174353175\n","\n","Level 4 preds: blender\n","fold=0, auc=0.951522987880747\n","fold=1, auc=0.9531012382753095\n","fold=2, auc=0.9467809866952468\n","fold=3, auc=0.9512514878128718\n","fold=4, auc=0.9462511962511962\n"]},{"output_type":"execute_result","data":{"text/plain":["(97.44590123494466, 0.8955251835462358)"]},"metadata":{},"execution_count":35}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:33:14.246493Z","iopub.execute_input":"2021-08-28T04:33:14.246776Z","iopub.status.idle":"2021-08-28T04:38:06.590788Z","shell.execute_reply.started":"2021-08-28T04:33:14.246747Z","shell.execute_reply":"2021-08-28T04:38:06.589955Z"},"trusted":true}},{"cell_type":"markdown","source":["Notice that the parallelized version has a ~20% speed up over the sequential version!"],"metadata":{}},{"cell_type":"markdown","source":["Testing if predictions agree:"],"metadata":{}},{"cell_type":"code","execution_count":36,"source":["times = []\n","for i in range(3):\n","    start_time = time.time()\n","    parallel_pred = stack_parallel.predict_proba(df_test)[:, 1]\n","    times.append(time.time() - start_time)\n","    \n","times = np.array(times)\n","times.mean(), times.std()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.74370272954305, 0.05158894135175818)"]},"metadata":{},"execution_count":36}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:38:06.591784Z","iopub.execute_input":"2021-08-28T04:38:06.592036Z","iopub.status.idle":"2021-08-28T04:38:11.831536Z","shell.execute_reply.started":"2021-08-28T04:38:06.591998Z","shell.execute_reply":"2021-08-28T04:38:11.830467Z"},"trusted":true}},{"cell_type":"code","execution_count":37,"source":["times = []\n","for i in range(3):\n","    start_time = time.time()\n","    usual_pred = stack.predict_proba(df_test)[:, 1]\n","    times.append(time.time() - start_time)\n","    \n","times = np.array(times)\n","times.mean(), times.std()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.7447847525278728, 0.009084941568507832)"]},"metadata":{},"execution_count":37}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:38:11.833364Z","iopub.execute_input":"2021-08-28T04:38:11.834122Z","iopub.status.idle":"2021-08-28T04:38:17.080128Z","shell.execute_reply.started":"2021-08-28T04:38:11.834074Z","shell.execute_reply":"2021-08-28T04:38:17.079067Z"},"trusted":true}},{"cell_type":"code","execution_count":48,"source":["print('parallel AUC:', metrics.roc_auc_score(df_test.sentiment, parallel_pred))\n","print('usual AUC:   ', metrics.roc_auc_score(df_test.sentiment, usual_pred))"],"outputs":[{"output_type":"stream","name":"stdout","text":["parallel AUC: 0.9443420794103774\n","usual AUC:    0.9443182392730581\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:40:07.828699Z","iopub.execute_input":"2021-08-28T04:40:07.829053Z","iopub.status.idle":"2021-08-28T04:40:07.839808Z","shell.execute_reply.started":"2021-08-28T04:40:07.829024Z","shell.execute_reply":"2021-08-28T04:40:07.839024Z"},"trusted":true}},{"cell_type":"markdown","source":["Testing if the results agree at the fold level:"],"metadata":{}},{"cell_type":"code","execution_count":40,"source":["# parallel\n","pd.DataFrame(stack_parallel.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1      lr_2  linreg_2     xgb_2  linreg_3     xgb_3  \\\n","mean  0.934775  0.944388  0.948371  0.949621  0.945454  0.949733  0.946076   \n","std   0.002778  0.002632  0.003298  0.002848  0.003488  0.003085  0.002404   \n","\n","      blender_4  \n","mean   0.949811  \n","std    0.002969  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>linreg_3</th>\n","      <th>xgb_3</th>\n","      <th>blender_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944388</td>\n","      <td>0.948371</td>\n","      <td>0.949621</td>\n","      <td>0.945454</td>\n","      <td>0.949733</td>\n","      <td>0.946076</td>\n","      <td>0.949811</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002632</td>\n","      <td>0.003298</td>\n","      <td>0.002848</td>\n","      <td>0.003488</td>\n","      <td>0.003085</td>\n","      <td>0.002404</td>\n","      <td>0.002969</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":40}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:38:17.114711Z","iopub.execute_input":"2021-08-28T04:38:17.115411Z","iopub.status.idle":"2021-08-28T04:38:17.162505Z","shell.execute_reply.started":"2021-08-28T04:38:17.115367Z","shell.execute_reply":"2021-08-28T04:38:17.161570Z"},"trusted":true}},{"cell_type":"code","execution_count":41,"source":["# sequential\n","pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["          lr_1  lr_cnt_1      lr_2  linreg_2     xgb_2  linreg_3     xgb_3  \\\n","mean  0.934775  0.944390  0.948369  0.949621  0.945428  0.949739  0.946170   \n","std   0.002778  0.002634  0.003298  0.002849  0.003737  0.003139  0.002788   \n","\n","      blender_4  \n","mean   0.949782  \n","std    0.003069  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>linreg_3</th>\n","      <th>xgb_3</th>\n","      <th>blender_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.934775</td>\n","      <td>0.944390</td>\n","      <td>0.948369</td>\n","      <td>0.949621</td>\n","      <td>0.945428</td>\n","      <td>0.949739</td>\n","      <td>0.946170</td>\n","      <td>0.949782</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.002778</td>\n","      <td>0.002634</td>\n","      <td>0.003298</td>\n","      <td>0.002849</td>\n","      <td>0.003737</td>\n","      <td>0.003139</td>\n","      <td>0.002788</td>\n","      <td>0.003069</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":41}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:38:17.163566Z","iopub.execute_input":"2021-08-28T04:38:17.163826Z","iopub.status.idle":"2021-08-28T04:38:17.197156Z","shell.execute_reply.started":"2021-08-28T04:38:17.163800Z","shell.execute_reply":"2021-08-28T04:38:17.196177Z"},"trusted":true}},{"cell_type":"markdown","source":["Checking if the two learned different model weights (previously I forgot to clone the models in `model_dict_list` so the models learned the same weights):"],"metadata":{}},{"cell_type":"code","execution_count":51,"source":["print(stack_parallel.model_dict_list[3]['blender'].coef_)\n","print(stack.model_dict_list[3]['blender'].coef_)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[0.25063917 0.04577294]\n","[0.25660091 0.0306614 ]\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:42:47.350422Z","iopub.execute_input":"2021-08-28T04:42:47.350904Z","iopub.status.idle":"2021-08-28T04:42:47.357104Z","shell.execute_reply.started":"2021-08-28T04:42:47.350865Z","shell.execute_reply":"2021-08-28T04:42:47.356140Z"},"trusted":true}},{"cell_type":"code","execution_count":49,"source":["stack_parallel.metafeatures_.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       lr_1  lr_cnt_1      lr_2  linreg_2     xgb_2  linreg_3     xgb_3  \\\n","0  0.414118  0.761353  0.594294 -0.022445  0.613355 -0.006122  0.799250   \n","1  0.982611  0.999355  0.967132  0.114824  0.996484  0.139497  0.999487   \n","2  0.102193  0.000346  0.041160 -0.139775  0.017038 -0.124591  0.036391   \n","3  0.820037  0.999538  0.938649  0.083109  0.983069  0.091374  0.967702   \n","4  0.842690  0.965703  0.938076  0.047133  0.924960  0.064387  0.965395   \n","\n","     blender_4  \n","0   670.670587  \n","1  1203.771676  \n","2   228.818620  \n","3  1008.009810  \n","4   916.861444  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>linreg_3</th>\n","      <th>xgb_3</th>\n","      <th>blender_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.414118</td>\n","      <td>0.761353</td>\n","      <td>0.594294</td>\n","      <td>-0.022445</td>\n","      <td>0.613355</td>\n","      <td>-0.006122</td>\n","      <td>0.799250</td>\n","      <td>670.670587</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.982611</td>\n","      <td>0.999355</td>\n","      <td>0.967132</td>\n","      <td>0.114824</td>\n","      <td>0.996484</td>\n","      <td>0.139497</td>\n","      <td>0.999487</td>\n","      <td>1203.771676</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.102193</td>\n","      <td>0.000346</td>\n","      <td>0.041160</td>\n","      <td>-0.139775</td>\n","      <td>0.017038</td>\n","      <td>-0.124591</td>\n","      <td>0.036391</td>\n","      <td>228.818620</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.820037</td>\n","      <td>0.999538</td>\n","      <td>0.938649</td>\n","      <td>0.083109</td>\n","      <td>0.983069</td>\n","      <td>0.091374</td>\n","      <td>0.967702</td>\n","      <td>1008.009810</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.842690</td>\n","      <td>0.965703</td>\n","      <td>0.938076</td>\n","      <td>0.047133</td>\n","      <td>0.924960</td>\n","      <td>0.064387</td>\n","      <td>0.965395</td>\n","      <td>916.861444</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":49}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:41:56.490138Z","iopub.execute_input":"2021-08-28T04:41:56.490644Z","iopub.status.idle":"2021-08-28T04:41:56.506165Z","shell.execute_reply.started":"2021-08-28T04:41:56.490608Z","shell.execute_reply":"2021-08-28T04:41:56.505354Z"},"trusted":true}},{"cell_type":"code","execution_count":50,"source":["stack.metafeatures_.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       lr_1  lr_cnt_1      lr_2  linreg_2     xgb_2  linreg_3     xgb_3  \\\n","0  0.414118  0.761635  0.594502 -0.022393  0.576681 -0.006564  0.599075   \n","1  0.982611  0.999355  0.967132  0.114876  0.996751  0.139951  0.999550   \n","2  0.102193  0.000345  0.041160 -0.139774  0.016802 -0.124136  0.012842   \n","3  0.820037  0.999539  0.938650  0.083109  0.986579  0.092108  0.988499   \n","4  0.842690  0.965732  0.938082  0.047134  0.922320  0.064557  0.919907   \n","\n","     blender_4  \n","0   607.936054  \n","1  1124.234802  \n","2   204.159542  \n","3   954.836527  \n","4   842.078840  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_1</th>\n","      <th>lr_cnt_1</th>\n","      <th>lr_2</th>\n","      <th>linreg_2</th>\n","      <th>xgb_2</th>\n","      <th>linreg_3</th>\n","      <th>xgb_3</th>\n","      <th>blender_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.414118</td>\n","      <td>0.761635</td>\n","      <td>0.594502</td>\n","      <td>-0.022393</td>\n","      <td>0.576681</td>\n","      <td>-0.006564</td>\n","      <td>0.599075</td>\n","      <td>607.936054</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.982611</td>\n","      <td>0.999355</td>\n","      <td>0.967132</td>\n","      <td>0.114876</td>\n","      <td>0.996751</td>\n","      <td>0.139951</td>\n","      <td>0.999550</td>\n","      <td>1124.234802</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.102193</td>\n","      <td>0.000345</td>\n","      <td>0.041160</td>\n","      <td>-0.139774</td>\n","      <td>0.016802</td>\n","      <td>-0.124136</td>\n","      <td>0.012842</td>\n","      <td>204.159542</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.820037</td>\n","      <td>0.999539</td>\n","      <td>0.938650</td>\n","      <td>0.083109</td>\n","      <td>0.986579</td>\n","      <td>0.092108</td>\n","      <td>0.988499</td>\n","      <td>954.836527</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.842690</td>\n","      <td>0.965732</td>\n","      <td>0.938082</td>\n","      <td>0.047134</td>\n","      <td>0.922320</td>\n","      <td>0.064557</td>\n","      <td>0.919907</td>\n","      <td>842.078840</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":50}],"metadata":{"execution":{"iopub.status.busy":"2021-08-28T04:42:01.800587Z","iopub.execute_input":"2021-08-28T04:42:01.801070Z","iopub.status.idle":"2021-08-28T04:42:01.816488Z","shell.execute_reply.started":"2021-08-28T04:42:01.801029Z","shell.execute_reply":"2021-08-28T04:42:01.815628Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}