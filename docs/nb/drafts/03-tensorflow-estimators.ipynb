{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Attribution\n",
    "This notebook builds on Chapter 14: *Going Deeper â€“ The Mechanics of TensorFlow* of {cite}`RaschkaMirjalili2019`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will work with TensorFlow Estimators. The `tf.estimator` API encapsulates the underlying steps in machine learning tasks, such as training, prediction (inference), and evaluation. Estimators are more encapsulated but also more scalable when compared to the previous approaches that we have covered above. Also, the `tf.estimator` API adds support for running models on multiple platforms without requiring major code changes, which makes them more suitable for the so-called \"production phase\" in industry applications. \n",
    "\n",
    "TensorFlow comes with a selection of off-the-shelf estimators for common machine learning and deep learning architectures that are useful for comparison studies, for example, to quickly assess whether a certain approach is applicable to a particular dataset or problem. Besides using pre-made Estimators, we can also create an Estimator by converting a Keras model to an Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning and deep learning applications, we can encounter various\n",
    "different types of features: continuous, unordered categorical (nominal), and ordered categorical (ordinal). Note that while numeric data can be either continuous or discrete, in the context of the TensorFlow API, \"numeric\" data specifically refers to continuous data of the floating point type.\n",
    "\n",
    " Sometimes, feature sets are comprised of a mixture of different feature types. While TensorFlow Estimators were designed to handle all these different types of features, we must specify how each feature should be interpreted by the Estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto MPG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/feature_cols.png \n",
    "---\n",
    "width: 60em\n",
    "name: feature_cols\n",
    "---\n",
    "Assigning types to feature columns from the Auto MPG dataset.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the use of TF Estimators, we use the [Auto MPG dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg). We are going to treat five features from the Auto MPG dataset (*number of cylinders*, *displacement*, *horsepower*, *weight*, and *acceleration*) as numeric (i.e. continuous) features. The *model year* can be regarded as an ordered categorical feature. Lastly, the *manufacturing origin* can be regarded as an unordered categorical feature with three possible discrete values, 1, 2, and 3, which correspond to the US, Europe, and Japan, respectively. {numref}`feature_cols` above shows how we will treat these feature columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (398, 8)\n",
      "No. of missing values:\n",
      "MPG             0\n",
      "Cylinders       0\n",
      "Displacement    0\n",
      "Horsepower      6\n",
      "Weight          0\n",
      "Acceleration    0\n",
      "ModelYear       0\n",
      "Origin          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>ModelYear</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "387  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "388  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "389  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "390  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "391  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     ModelYear  Origin  \n",
       "387         82       1  \n",
       "388         82       2  \n",
       "389         82       1  \n",
       "390         82       1  \n",
       "391         82       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = tf.keras.utils.get_file(\n",
    "    \"auto-mpg.data\",\n",
    "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    ")\n",
    "\n",
    "column_names = [\n",
    "    \"MPG\", \"Cylinders\", \"Displacement\",\n",
    "    \"Horsepower\", \"Weight\", \"Acceleration\",\n",
    "    \"ModelYear\", \"Origin\"\n",
    "]\n",
    "\n",
    "# Load dataset; drop missing values\n",
    "df = pd.read_csv(dataset_path, \n",
    "    names=column_names, \n",
    "    na_values=\"?\", \n",
    "    comment=\"\\t\", \n",
    "    sep=\" \", \n",
    "    skipinitialspace=True)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"No. of missing values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# For simplicity drop rows with missing values.\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset and standardizing numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MPG</th>\n",
       "      <td>313.0</td>\n",
       "      <td>23.603834</td>\n",
       "      <td>7.863563</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cylinders</th>\n",
       "      <td>313.0</td>\n",
       "      <td>5.412141</td>\n",
       "      <td>1.696370</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Displacement</th>\n",
       "      <td>313.0</td>\n",
       "      <td>190.944089</td>\n",
       "      <td>103.351455</td>\n",
       "      <td>68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horsepower</th>\n",
       "      <td>313.0</td>\n",
       "      <td>103.099042</td>\n",
       "      <td>37.381433</td>\n",
       "      <td>46.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>313.0</td>\n",
       "      <td>2959.712460</td>\n",
       "      <td>859.175108</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>3574.0</td>\n",
       "      <td>4997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acceleration</th>\n",
       "      <td>313.0</td>\n",
       "      <td>15.704792</td>\n",
       "      <td>2.704675</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ModelYear</th>\n",
       "      <td>313.0</td>\n",
       "      <td>75.968051</td>\n",
       "      <td>3.660111</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origin</th>\n",
       "      <td>313.0</td>\n",
       "      <td>1.587859</td>\n",
       "      <td>0.812234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min     25%     50%     75%  \\\n",
       "MPG           313.0    23.603834    7.863563     9.0    17.5    23.0    29.0   \n",
       "Cylinders     313.0     5.412141    1.696370     3.0     4.0     4.0     8.0   \n",
       "Displacement  313.0   190.944089  103.351455    68.0    98.0   144.0   260.0   \n",
       "Horsepower    313.0   103.099042   37.381433    46.0    75.0    92.0   120.0   \n",
       "Weight        313.0  2959.712460  859.175108  1613.0  2205.0  2745.0  3574.0   \n",
       "Acceleration  313.0    15.704792    2.704675     8.0    14.0    15.5    17.4   \n",
       "ModelYear     313.0    75.968051    3.660111    70.0    73.0    76.0    79.0   \n",
       "Origin        313.0     1.587859    0.812234     1.0     1.0     1.0     2.0   \n",
       "\n",
       "                 max  \n",
       "MPG             46.6  \n",
       "Cylinders        8.0  \n",
       "Displacement   455.0  \n",
       "Horsepower     225.0  \n",
       "Weight        4997.0  \n",
       "Acceleration    24.8  \n",
       "ModelYear       82.0  \n",
       "Origin           3.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df, train_size=0.8)\n",
    "train_stats = df_train.describe().transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>ModelYear</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.832448</td>\n",
       "      <td>-0.899301</td>\n",
       "      <td>-0.938943</td>\n",
       "      <td>-0.936611</td>\n",
       "      <td>0.294012</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.525527</td>\n",
       "      <td>1.093898</td>\n",
       "      <td>1.254659</td>\n",
       "      <td>1.085096</td>\n",
       "      <td>-1.184909</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.832448</td>\n",
       "      <td>-1.025086</td>\n",
       "      <td>-0.885441</td>\n",
       "      <td>-1.128655</td>\n",
       "      <td>0.478877</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.525527</td>\n",
       "      <td>1.229358</td>\n",
       "      <td>1.254659</td>\n",
       "      <td>1.300419</td>\n",
       "      <td>-0.630313</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.346540</td>\n",
       "      <td>0.329516</td>\n",
       "      <td>-0.082903</td>\n",
       "      <td>0.318081</td>\n",
       "      <td>-0.112691</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower    Weight  Acceleration  \\\n",
       "264  30.0  -0.832448     -0.899301   -0.938943 -0.936611      0.294012   \n",
       "71   15.0   1.525527      1.093898    1.254659  1.085096     -1.184909   \n",
       "202  32.0  -0.832448     -1.025086   -0.885441 -1.128655      0.478877   \n",
       "74   14.0   1.525527      1.229358    1.254659  1.300419     -0.630313   \n",
       "189  22.0   0.346540      0.329516   -0.082903  0.318081     -0.112691   \n",
       "\n",
       "     ModelYear  Origin  \n",
       "264         78       1  \n",
       "71          72       1  \n",
       "202         76       3  \n",
       "74          72       1  \n",
       "189         76       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_column_names = [\n",
    "    'Cylinders', \n",
    "    'Displacement', \n",
    "    'Horsepower', \n",
    "    'Weight', \n",
    "    'Acceleration'\n",
    "]\n",
    "\n",
    "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
    "for col_name in numeric_column_names:\n",
    "    train_mean = train_stats.loc[col_name, 'mean']\n",
    "    train_std  = train_stats.loc[col_name, 'std']\n",
    "    df_train_norm.loc[:, col_name] = (df_train_norm.loc[:, col_name] - train_mean) / train_std\n",
    "    df_test_norm.loc[:, col_name] = (df_test_norm.loc[:, col_name] - train_mean) / train_std\n",
    "    \n",
    "df_train_norm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we will use TensorFlow's `feature_column` function\n",
    "to transform the 5 continuous features into the feature column data structure that\n",
    "TensorFlow Estimators can work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='Cylinders', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Displacement', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Horsepower', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Weight', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Acceleration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "numeric_features = []\n",
    "for col_name in numeric_column_names:\n",
    "    feature_column = tf.feature_column.numeric_column(key=col_name)\n",
    "    numeric_features.append(feature_column)\n",
    "\n",
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's group the rather fine-grained model year information into buckets to\n",
    "simplify the learning task for the model that we are going to train later. Note that we assign `boundaries=[73, 76, 79]` which results in left-closed partitioning of the real line into 4 intervals `(-âˆž, 73)`, `[73, 76)`, `[76, 79)`, and `[79, +âˆž)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BucketizedColumn(source_column=NumericColumn(key='ModelYear', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(73, 76, 79))]\n"
     ]
    }
   ],
   "source": [
    "feature_year = tf.feature_column.numeric_column(key=\"ModelYear\")\n",
    "bucketized_column = tf.feature_column.bucketized_column(\n",
    "    source_column=feature_year,\n",
    "    boundaries=[73, 76, 79]\n",
    ")\n",
    "\n",
    "# For consistency, we create list of bucketized features\n",
    "bucketized_features = [] \n",
    "bucketized_features.append(bucketized_column)\n",
    "print(bucketized_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical indicator features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will proceed with defining a list for the unordered categorical feature,\n",
    "`Origin`. Here we use `categorical_column_with_vocabulary_list` in `tf.feature_column` and provide a list of all possible category names as input. \n",
    "\n",
    "```{tip}\n",
    "If the list of possible categories is too large, we can use `categorical_column_with_vocabulary_list` and provide a file that contains all the categories/words so that we do not have to store a list of all possible words in memory.  If the features are already associated\n",
    "with an index of categories in the range `[0, num_categories)`, then we can use the\n",
    "`categorical_column_with_identity` function. However,\n",
    "in this case, the feature `Origin` is given as integer values `1`, `2`, `3` (as opposed to `0`, `1`, `2`), which does not match the requirement for categorical indexing.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(df.Origin.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_origin = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key='Origin',\n",
    "    vocabulary_list=[1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "Refer to the [official TensorFlow docs](https://www.tensorflow.org/api_docs/python/tf/feature_column) for other implemented feature columns such as hashed columns and crossed columns.\n",
    "```\n",
    "\n",
    "Certain Estimators, such as `DNNClassifier` and `DNNRegressor`, only accept so-called\n",
    "\"dense columns.\" Therefore, the next step is to convert the existing categorical feature column to such a dense column. There are two ways to do this: using an embedding column via `embedding_column` or an indicator column via `indicator_column`. We use the latter which converts the categorical indices to one-hot encoded vectors to convert the categorical column to a dense format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Origin', vocabulary_list=(1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0))]\n"
     ]
    }
   ],
   "source": [
    "indicator_column = tf.feature_column.indicator_column(feature_origin)\n",
    "\n",
    "# For consistency, we create list of nominal features\n",
    "categorical_indicator_features = []\n",
    "categorical_indicator_features.append(indicator_column)\n",
    "print(categorical_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning with pre-made estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions\n",
    "\n",
    "We have to define an **input function** that \n",
    "processes the data and returns a TensorFlow dataset consisting of a tuple \n",
    "that contains the input features and the targets. Note that the features \n",
    "must be a dictionary format such that the keys match \n",
    "the names (or keys) of feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'ModelYear', 'Origin'])\n",
      "Batch Model Years: tf.Tensor([71 74 78 76 72 74 72 75], shape=(8,), dtype=int64)\n",
      "Batch MPGs (targets): [19.  16.  17.7 26.  13.  14.  12.  16. ]\n"
     ]
    }
   ],
   "source": [
    "def train_input_fn(df_train, batch_size=8):\n",
    "    df = df_train.copy()\n",
    "    x_train, y_train = df, df.pop('MPG')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x_train), y_train))\n",
    "\n",
    "    # Shuffle, batch, and repeat the examples\n",
    "    return dataset.shuffle(1000).batch(batch_size).repeat()\n",
    "\n",
    "# Inspection\n",
    "ds = train_input_fn(df_train_norm)\n",
    "batch = next(iter(ds))\n",
    "print('Keys:', batch[0].keys())\n",
    "print('Batch Model Years:', batch[0]['ModelYear'])\n",
    "print('Batch MPGs (targets):', batch[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input function for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'ModelYear', 'Origin'])\n",
      "Batch Model Years: tf.Tensor([80 78 76 81 72 73 70 71], shape=(8,), dtype=int64)\n",
      "Batch MPGs (targets): [41.5 21.6 29.  32.4 14.  12.  22.  23. ]\n"
     ]
    }
   ],
   "source": [
    "def eval_input_fn(df_eval, batch_size=8):\n",
    "    df = df_eval.copy()\n",
    "    x_eval, y_eval = df, df.pop('MPG')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x_eval), y_eval))\n",
    "\n",
    "    # Shuffle, batch, and repeat the examples\n",
    "    return dataset.shuffle(1000).batch(batch_size).repeat()\n",
    "\n",
    "# Inspection\n",
    "ds = eval_input_fn(df_test_norm)\n",
    "batch = next(iter(ds))\n",
    "print('Keys:', batch[0].keys())\n",
    "print('Batch Model Years:', batch[0]['ModelYear'])\n",
    "print('Batch MPGs (targets):', batch[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since predicting MPG values\n",
    "is a typical regression problem, we will use `tf.estimator.DNNRegressor`. When\n",
    "instantiating the regression Estimator, we will provide the list of feature columns\n",
    "and specify the number of hidden units that we want to have in each hidden layer\n",
    "using the argument `hidden_units`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'models/autompg-dnnregressor/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(\n",
    "    feature_columns=(\n",
    "        numeric_features + \n",
    "        bucketized_features + \n",
    "        categorical_indicator_features\n",
    "    ),\n",
    "    hidden_units=[32, 10],\n",
    "    model_dir='models/autompg-dnnregressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other argument, `model_dir`, that we have provided specifies the directory\n",
    "for saving model parameters. One of the advantages of Estimators is that they\n",
    "automatically checkpoint the model during training, so that in case the training of\n",
    "the model crashes for an unexpected reason, we can easily load\n",
    "the last saved checkpoint and continue training from there. The checkpoints will also\n",
    "be saved in the directory specified by `model_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The `.train()` method expects two arguments. The argument `input_fn` expects a callable that returns a batch of training examples. The `steps` which is the total number of SGD updates (or calls to the input function) is calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Steps: 1200\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 11:42:32.791662: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-07 11:42:32.791686: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-02-07 11:42:32.800969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:32.897032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:32.905102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:32.909710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:32.916762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models/autompg-dnnregressor/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 572.394, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 11:42:33.006831: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:33.032947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:33.038938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:42:33.147668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 130.477\n",
      "INFO:tensorflow:loss = 648.3938, step = 100 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.294\n",
      "INFO:tensorflow:loss = 560.362, step = 200 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.645\n",
      "INFO:tensorflow:loss = 762.4479, step = 300 (0.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.88\n",
      "INFO:tensorflow:loss = 473.31888, step = 400 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.36\n",
      "INFO:tensorflow:loss = 530.813, step = 500 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.483\n",
      "INFO:tensorflow:loss = 530.0683, step = 600 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.863\n",
      "INFO:tensorflow:loss = 735.958, step = 700 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.441\n",
      "INFO:tensorflow:loss = 643.9301, step = 800 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.189\n",
      "INFO:tensorflow:loss = 615.75024, step = 900 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.958\n",
      "INFO:tensorflow:loss = 491.15604, step = 1000 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.166\n",
      "INFO:tensorflow:loss = 698.7927, step = 1100 (0.644 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1200...\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into models/autompg-dnnregressor/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1200...\n",
      "INFO:tensorflow:Loss for final step: 137.3717.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x17e9fb430>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 8\n",
    "total_steps = EPOCHS * int(np.ceil(len(df_train) / BATCH_SIZE))\n",
    "print('Training Steps:', total_steps)\n",
    "\n",
    "regressor.train(\n",
    "    input_fn=lambda: train_input_fn(df_train_norm, batch_size=BATCH_SIZE),\n",
    "    steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "Recall that `model_dir` saves the checkpoints of the model during training. The last model can be loaded using the `warm_start_from` argument as follows:\n",
    "\n",
    "```python\n",
    "reloaded_regressor = tf.estimator.DNNRegressor(\n",
    "    feature_columns=all_feature_columns,\n",
    "    hidden_units=[32, 10],\n",
    "    warm_start_from='models/autompg-dnnregressor/',\n",
    "    model_dir='models/autompg-dnnregressor/'\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate performance, we use the `.evaluate` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-02-07T11:49:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/autompg-dnnregressor/model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 11:49:42.384064: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-07 11:49:42.384087: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-02-07 11:49:42.399882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:49:42.407763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:49:42.414157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:49:42.429429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:49:42.441276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-07 11:49:42.448100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jq/9vsvd9252_349lsng_5gc_jw0000gn/T/ipykernel_45776/1074844759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m eval_results = regressor.evaluate(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m       return self._actual_eval(\n\u001b[0m\u001b[1;32m    473\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_distribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[0;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    502\u001b[0m         (scaffold, update_op, eval_dict, all_hooks) = (\n\u001b[1;32m    503\u001b[0m             self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n\u001b[0;32m--> 504\u001b[0;31m         return self._evaluate_run(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mscaffold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[0;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     all_hooks, output_dir):\n\u001b[1;32m   1657\u001b[0m     \u001b[0;34m\"\"\"Run evaluation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m     eval_results = evaluation._evaluate_once(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   1659\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inference Time : {:0.5f}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m       \u001b[0mSame\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \"\"\"\n\u001b[0;32m--> 786\u001b[0;31m     return self._sess.run(\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         return self._sess.run(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0;31m# Do session run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0mrun_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m     outputs = _WrappedSession.run(\n\u001b[0m\u001b[1;32m   1474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactual_fetches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                            run_metadata)\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1378\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1454\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1455\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1456\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_results = regressor.evaluate(\n",
    "    input_fn=lambda: eval_input_fn(df_test_norm, batch_size=8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/autompg-dnnregressor/model.ckpt-80000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([4.7905107], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "pred_res = regressor.predict(input_fn=lambda: eval_input_fn(df_test_norm, batch_size=8))\n",
    "\n",
    "print(next(iter(pred_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_loss': 7.3268905, 'label/mean': 22.655697, 'loss': 7.2563562, 'prediction/mean': 22.736225, 'global_step': 24000}\n",
      "Average-Loss 7.3269\n"
     ]
    }
   ],
   "source": [
    "boosted_tree = tf.estimator.BoostedTreesRegressor(\n",
    "    feature_columns=all_feature_columns,\n",
    "    n_batches_per_layer=20,\n",
    "    n_trees=200)\n",
    "\n",
    "boosted_tree.train(\n",
    "    input_fn=lambda:train_input_fn(df_train_norm, batch_size=BATCH_SIZE))\n",
    "\n",
    "eval_results = boosted_tree.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(df_test_norm, batch_size=8))\n",
    "\n",
    "print(eval_results)\n",
    "\n",
    "print('Average-Loss {:.4f}'.format(eval_results['average_loss']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
