{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=brightgreen)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/ok-transformer/blob/master/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/ok-transformer?style=social)](https://github.com/particle1331/ok-transformer)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that for MLPs and CNNs we pass inputs $\\boldsymbol{\\mathsf x} \\in \\mathbb R^d$ that is transformed sequentially by a stack of layers. These networks are designed to capture heirarchical features in input data. Observe that data for tasks that use these networks have fixed length. However, many tasks have data that cannot be represented as fixed length vectors, i.e. inputs consist of variable-length sequential data, such as video or natural language. A key insight is that while these data have variable length, we can model the input as having an evolving state which is a fixed-length vector $(\\boldsymbol{\\mathsf{\\mathsf x}}_1, \\ldots, \\boldsymbol{\\mathsf{\\mathsf x}}_T)$ such that $\\boldsymbol{\\mathsf x}_i \\in \\mathbb R^d.$ For example, videos can be modeled as sequences of images of fixed shape.\n",
    "\n",
    "In this notebook, we will look at **recurrent connections** which uses a hidden state $\\boldsymbol{\\mathsf{h}}_{t-1}$ to captures information up to time step $t-1.$ It turns out that this framework allows inputs to be processed in a feed-forward manner with layer weights shared across time steps. Moreover, we can backpropagate through the recurrent units by tracking dependencies of the hidden state to all previous time steps. This introduces difficulties in training, motivating modern recurrent architectures that we will discuss in the later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "DATASET_DIR = Path(\"../input\").absolute()\n",
    "RANDOM_SEED = 42\n",
    "GENERATOR = torch.Generator().manual_seed(RANDOM_SEED)\n",
    "\n",
    "warnings.simplefilter(action=\"once\")\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-based language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLMScratch(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.sigma = sigma\n",
    "\n",
    "        self.Wx = nn.Parameter(torch.randn(num_inputs, num_hidden) * sigma)\n",
    "        self.Wh = nn.Parameter(torch.randn(num_hidden, num_hidden) * sigma)\n",
    "        self.b  = nn.Parameter(torch.zeros(num_hidden))\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        h = torch.zeros(self.num_hidden) if h is None else h\n",
    "        return torch.tanh(x @ self.Wx + h @ self.Wh + self.b)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bf457f4026a6353447ea08cc5de431bf2d4a57657f54daac3cf4f903fa850ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
