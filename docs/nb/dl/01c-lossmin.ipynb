{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each choice of parameters $\\boldsymbol{\\Theta}$, we defined the empirical risk  $\\mathcal{L}_\\mathcal{D}(\\boldsymbol{\\Theta})$ as an unbiased estimate of the true risk $\\mathcal{L}(\\boldsymbol{\\Theta})$ defined as the expected loss on the underlying distribution given the model $f_{\\boldsymbol{\\Theta}}$. It is natural to ask whether this is an accurate estimate. There are two things to watch out for when training our models:\n",
    "\n",
    "* **Overfitting.** This is characterized by having low empirical risk, but high true risk. This can happen if the dataset is too small to be representative of the true distribution. Or if the model is too complex. In the latter case, the model will interpolate the sample, but will have arbitrary behavior between datapoints.\n",
    "\n",
    "+++\n",
    "\n",
    "* **Underfitting.** Here the empirical risk, and thereby the true risk, is high. This can happen if the model is too weak (low capacity, or too few parameters) &mdash; e.g. too strong regularization. Or if the optimizer is not configured well (e.g. wrong learning rate), so that the parameters $\\boldsymbol{\\Theta}$ found are inadequate even on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that MLE is by definition prone to overfitting. We rely on smoothness between data points for the model to generalize to test data. It is important to analyze the error between different **training samples**. A well-trained model should not look too different between samples. But we also don't want it to have the same errors with different data! ({numref}`01-overfitting-underfitting`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "```{figure} ../../img/nn/01-overfitting-underfitting.png\n",
    "---\n",
    "name: 01-overfitting-underfitting\n",
    "width: 100%\n",
    "---\n",
    "Drawing of a model that overfits and underfits the distribution. [Source](https://cs182sp21.github.io/static/slides/lec-3.pdf)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
