{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4f3e6d",
   "metadata": {
    "papermill": {
     "duration": 0.006085,
     "end_time": "2024-12-31T05:32:09.597967",
     "exception": false,
     "start_time": "2024-12-31T05:32:09.591882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120fc610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:09.602164Z",
     "iopub.status.busy": "2024-12-31T05:32:09.601882Z",
     "iopub.status.idle": "2024-12-31T05:32:10.367440Z",
     "shell.execute_reply": "2024-12-31T05:32:10.367043Z"
    },
    "papermill": {
     "duration": 0.768843,
     "end_time": "2024-12-31T05:32:10.368552",
     "exception": false,
     "start_time": "2024-12-31T05:32:09.599709",
     "status": "completed"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from chapter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5f01c",
   "metadata": {
    "papermill": {
     "duration": 0.001265,
     "end_time": "2024-12-31T05:32:10.371365",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.370100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our goal in this section is to train a character-level RNN language model to predict the next token at *each* step with varying-length context. Hence, during training, our model predicts on each time-step ({numref}`04-char-rnn`). The language model below is simply an RNN cell with an attached **logits layer** applied at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a2576",
   "metadata": {
    "papermill": {
     "duration": 0.00125,
     "end_time": "2024-12-31T05:32:10.373942",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.372692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "```{figure} ../../../img/nn/04-char-rnn.svg\n",
    "---\n",
    "width: 550px\n",
    "name: 04-char-rnn\n",
    "align: center\n",
    "---\n",
    "Character-level RNN language model for predicting the next character at each step.  [Source](https://www.d2l.ai/chapter_recurrent-neural-networks/rnn.html)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02139545",
   "metadata": {
    "papermill": {
     "duration": 0.001199,
     "end_time": "2024-12-31T05:32:10.376378",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.375179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To implement a language model, we simply attach a linear layer on the RNN unit to compute logits. \n",
    "The linear layer performs matrix multiplication on the rightmost dimension of `outs` which contains the value of the state vector at each time step. Thus, as shown in {numref}`04-char-rnn` we have $T$ predictions with increasing context size[^1] $1, 2, \\ldots, T.$\n",
    "\n",
    "[^1]: Consequently, the model gets corrected at each time step, with variable-length dependency, during backward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33053e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.379618Z",
     "iopub.status.busy": "2024-12-31T05:32:10.379439Z",
     "iopub.status.idle": "2024-12-31T05:32:10.404579Z",
     "shell.execute_reply": "2024-12-31T05:32:10.404304Z"
    },
    "papermill": {
     "duration": 0.027832,
     "end_time": "2024-12-31T05:32:10.405534",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.377702",
     "status": "completed"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">Type</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">functools</span> <span class=\"kn\">import</span> <span class=\"n\">partial</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">RNNLanguageModel</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> \n",
       "        <span class=\"n\">cell</span><span class=\"p\">:</span> <span class=\"n\">Type</span><span class=\"p\">[</span><span class=\"n\">RNNBase</span><span class=\"p\">],</span>\n",
       "        <span class=\"n\">inputs_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">hidden_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span>\n",
       "        <span class=\"o\">**</span><span class=\"n\">kwargs</span>\n",
       "    <span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cell</span> <span class=\"o\">=</span> <span class=\"n\">cell</span><span class=\"p\">(</span><span class=\"n\">inputs_dim</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">hidden_dim</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">return_state</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">outs</span><span class=\"p\">,</span> <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">cell</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">outs</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear</span><span class=\"p\">(</span><span class=\"n\">outs</span><span class=\"p\">)</span>    <span class=\"c1\"># (T, B, H) -&gt; (T, B, C)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">outs</span> <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">return_state</span> <span class=\"k\">else</span> <span class=\"p\">(</span><span class=\"n\">outs</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"n\">LanguageModel</span> <span class=\"o\">=</span> <span class=\"k\">lambda</span> <span class=\"n\">cell</span><span class=\"p\">:</span> <span class=\"n\">partial</span><span class=\"p\">(</span><span class=\"n\">RNNLanguageModel</span><span class=\"p\">,</span> <span class=\"n\">cell</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn} \\PY{k}{as} \\PY{n+nn}{nn}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{typing} \\PY{k+kn}{import} \\PY{n}{Type}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{functools} \\PY{k+kn}{import} \\PY{n}{partial}\n",
       "\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{RNNLanguageModel}\\PY{p}{(}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \n",
       "        \\PY{n}{cell}\\PY{p}{:} \\PY{n}{Type}\\PY{p}{[}\\PY{n}{RNNBase}\\PY{p}{]}\\PY{p}{,}\n",
       "        \\PY{n}{inputs\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,}\n",
       "        \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,}\n",
       "        \\PY{n}{vocab\\PYZus{}size}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,}\n",
       "        \\PY{o}{*}\\PY{o}{*}\\PY{n}{kwargs}\n",
       "    \\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{cell} \\PY{o}{=} \\PY{n}{cell}\\PY{p}{(}\\PY{n}{inputs\\PYZus{}dim}\\PY{p}{,} \\PY{n}{hidden\\PYZus{}dim}\\PY{p}{,} \\PY{o}{*}\\PY{o}{*}\\PY{n}{kwargs}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{linear} \\PY{o}{=} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{n}{hidden\\PYZus{}dim}\\PY{p}{,} \\PY{n}{vocab\\PYZus{}size}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{,} \\PY{n}{state}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{return\\PYZus{}state}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{outs}\\PY{p}{,} \\PY{n}{state} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{cell}\\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{state}\\PY{p}{)}\n",
       "        \\PY{n}{outs} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{linear}\\PY{p}{(}\\PY{n}{outs}\\PY{p}{)}    \\PY{c+c1}{\\PYZsh{} (T, B, H) \\PYZhy{}\\PYZgt{} (T, B, C)}\n",
       "        \\PY{k}{return} \\PY{n}{outs} \\PY{k}{if} \\PY{o+ow}{not} \\PY{n}{return\\PYZus{}state} \\PY{k}{else} \\PY{p}{(}\\PY{n}{outs}\\PY{p}{,} \\PY{n}{state}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{n}{LanguageModel} \\PY{o}{=} \\PY{k}{lambda} \\PY{n}{cell}\\PY{p}{:} \\PY{n}{partial}\\PY{p}{(}\\PY{n}{RNNLanguageModel}\\PY{p}{,} \\PY{n}{cell}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch\n",
       "import torch.nn as nn\n",
       "from typing import Type\n",
       "from functools import partial\n",
       "\n",
       "\n",
       "class RNNLanguageModel(nn.Module):\n",
       "    def __init__(self, \n",
       "        cell: Type[RNNBase],\n",
       "        inputs_dim: int,\n",
       "        hidden_dim: int,\n",
       "        vocab_size: int,\n",
       "        **kwargs\n",
       "    ):\n",
       "        super().__init__()\n",
       "        self.cell = cell(inputs_dim, hidden_dim, **kwargs)\n",
       "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
       "\n",
       "    def forward(self, x, state=None, return_state=False):\n",
       "        outs, state = self.cell(x, state)\n",
       "        outs = self.linear(outs)    # (T, B, H) -> (T, B, C)\n",
       "        return outs if not return_state else (outs, state)\n",
       "\n",
       "\n",
       "LanguageModel = lambda cell: partial(RNNLanguageModel, cell)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%save\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Type\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, \n",
    "        cell: Type[RNNBase],\n",
    "        inputs_dim: int,\n",
    "        hidden_dim: int,\n",
    "        vocab_size: int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cell = cell(inputs_dim, hidden_dim, **kwargs)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, state=None, return_state=False):\n",
    "        outs, state = self.cell(x, state)\n",
    "        outs = self.linear(outs)    # (T, B, H) -> (T, B, C)\n",
    "        return outs if not return_state else (outs, state)\n",
    "\n",
    "\n",
    "LanguageModel = lambda cell: partial(RNNLanguageModel, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93725f",
   "metadata": {
    "papermill": {
     "duration": 0.00145,
     "end_time": "2024-12-31T05:32:10.408508",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.407058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "## Character sequences dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349b7b9",
   "metadata": {
    "papermill": {
     "duration": 0.001406,
     "end_time": "2024-12-31T05:32:10.411183",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.409777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our dataset consists of $T$ input-output pairs of characters **shifted** one time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ec7cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.414356Z",
     "iopub.status.busy": "2024-12-31T05:32:10.414230Z",
     "iopub.status.idle": "2024-12-31T05:32:10.419843Z",
     "shell.execute_reply": "2024-12-31T05:32:10.419601Z"
    },
    "papermill": {
     "duration": 0.008174,
     "end_time": "2024-12-31T05:32:10.420688",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.412514",
     "status": "completed"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"k\">as</span> <span class=\"nn\">F</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">Dataset</span><span class=\"p\">,</span> <span class=\"n\">DataLoader</span>\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">SequenceDataset</span><span class=\"p\">(</span><span class=\"n\">Dataset</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">corpus</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"n\">seq_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"n\">corpus</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">seq_len</span> <span class=\"o\">=</span> <span class=\"n\">seq_len</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab_size</span> <span class=\"o\">=</span> <span class=\"n\">vocab_size</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">corpus</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">:</span> <span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">seq_len</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">])</span>\n",
       "        <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"p\">[:</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">c</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">:]</span>\n",
       "        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">one_hot</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">vocab_size</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">()</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span>\n",
       "    \n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__len__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">corpus</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">seq_len</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn}\\PY{n+nn}{.}\\PY{n+nn}{functional} \\PY{k}{as} \\PY{n+nn}{F}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{utils}\\PY{n+nn}{.}\\PY{n+nn}{data} \\PY{k+kn}{import} \\PY{n}{Dataset}\\PY{p}{,} \\PY{n}{DataLoader}\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{SequenceDataset}\\PY{p}{(}\\PY{n}{Dataset}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{corpus}\\PY{p}{:} \\PY{n+nb}{list}\\PY{p}{,} \\PY{n}{seq\\PYZus{}len}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,} \\PY{n}{vocab\\PYZus{}size}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{corpus} \\PY{o}{=} \\PY{n}{corpus}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{seq\\PYZus{}len} \\PY{o}{=} \\PY{n}{seq\\PYZus{}len}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab\\PYZus{}size} \\PY{o}{=} \\PY{n}{vocab\\PYZus{}size}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}getitem\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{i}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{c} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{tensor}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{corpus}\\PY{p}{[}\\PY{n}{i}\\PY{p}{:} \\PY{n}{i} \\PY{o}{+} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{seq\\PYZus{}len} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n}{x}\\PY{p}{,} \\PY{n}{y} \\PY{o}{=} \\PY{n}{c}\\PY{p}{[}\\PY{p}{:}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{,} \\PY{n}{c}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{:}\\PY{p}{]}\n",
       "        \\PY{n}{x} \\PY{o}{=} \\PY{n}{F}\\PY{o}{.}\\PY{n}{one\\PYZus{}hot}\\PY{p}{(}\\PY{n}{x}\\PY{p}{,} \\PY{n}{num\\PYZus{}classes}\\PY{o}{=}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{vocab\\PYZus{}size}\\PY{p}{)}\\PY{o}{.}\\PY{n}{float}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{x}\\PY{p}{,} \\PY{n}{y}\n",
       "    \n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}len\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{return} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{corpus}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{seq\\PYZus{}len}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch.nn.functional as F\n",
       "from torch.utils.data import Dataset, DataLoader\n",
       "\n",
       "class SequenceDataset(Dataset):\n",
       "    def __init__(self, corpus: list, seq_len: int, vocab_size: int):\n",
       "        super().__init__()\n",
       "        self.corpus = corpus\n",
       "        self.seq_len = seq_len\n",
       "        self.vocab_size = vocab_size\n",
       "\n",
       "    def __getitem__(self, i):\n",
       "        c = torch.tensor(self.corpus[i: i + self.seq_len + 1])\n",
       "        x, y = c[:-1], c[1:]\n",
       "        x = F.one_hot(x, num_classes=self.vocab_size).float()\n",
       "        return x, y\n",
       "    \n",
       "    def __len__(self):\n",
       "        return len(self.corpus) - self.seq_len"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%save\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, corpus: list, seq_len: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.corpus = corpus\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        c = torch.tensor(self.corpus[i: i + self.seq_len + 1])\n",
    "        x, y = c[:-1], c[1:]\n",
    "        x = F.one_hot(x, num_classes=self.vocab_size).float()\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.corpus) - self.seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6937a18",
   "metadata": {
    "papermill": {
     "duration": 0.001521,
     "end_time": "2024-12-31T05:32:10.423761",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.422240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training on the *Time Machine* text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b73f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.428067Z",
     "iopub.status.busy": "2024-12-31T05:32:10.427926Z",
     "iopub.status.idle": "2024-12-31T05:32:10.462301Z",
     "shell.execute_reply": "2024-12-31T05:32:10.462031Z"
    },
    "papermill": {
     "duration": 0.037156,
     "end_time": "2024-12-31T05:32:10.463178",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.426022",
     "status": "completed"
    },
    "tags": [
     "hide-output",
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">re</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">collections</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">pathlib</span> <span class=\"kn\">import</span> <span class=\"n\">Path</span>\n",
       "\n",
       "<span class=\"n\">DATA_DIR</span> <span class=\"o\">=</span> <span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s2\">&quot;./data&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">DATA_DIR</span><span class=\"o\">.</span><span class=\"n\">mkdir</span><span class=\"p\">(</span><span class=\"n\">exist_ok</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Vocab</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">tokens</span><span class=\"o\">=</span><span class=\"p\">[],</span> <span class=\"n\">min_freq</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">reserved_tokens</span><span class=\"o\">=</span><span class=\"p\">[]):</span>\n",
       "        <span class=\"n\">counter</span> <span class=\"o\">=</span> <span class=\"n\">collections</span><span class=\"o\">.</span><span class=\"n\">Counter</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">token_freqs</span> <span class=\"o\">=</span> <span class=\"nb\">sorted</span><span class=\"p\">(</span><span class=\"n\">counter</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">(),</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">reverse</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itot</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">&quot;&lt;unk&gt;&quot;</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">sorted</span><span class=\"p\">(</span><span class=\"nb\">set</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">reserved_tokens</span> <span class=\"o\">+</span>   <span class=\"c1\"># i.e. not subject to min_freq</span>\n",
       "            <span class=\"p\">[</span><span class=\"n\">token</span> <span class=\"k\">for</span> <span class=\"n\">token</span><span class=\"p\">,</span> <span class=\"n\">freq</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">token_freqs</span> <span class=\"k\">if</span> <span class=\"n\">freq</span> <span class=\"o\">&gt;=</span> <span class=\"n\">min_freq</span><span class=\"p\">]</span>\n",
       "        <span class=\"p\">)))</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ttoi</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">tok</span><span class=\"p\">:</span> <span class=\"n\">idx</span> <span class=\"k\">for</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">tok</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itot</span><span class=\"p\">)}</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__len__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itot</span><span class=\"p\">)</span>\n",
       "    \n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">tokens</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">])</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]:</span>\n",
       "        <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"nb\">tuple</span><span class=\"p\">)):</span>\n",
       "            <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"n\">tok</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">tok</span> <span class=\"ow\">in</span> <span class=\"n\">tokens</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "            <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ttoi</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">unk</span><span class=\"p\">)</span>\n",
       "            \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">to_tokens</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">indices</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]:</span>\n",
       "        <span class=\"k\">if</span> <span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">indices</span><span class=\"p\">,</span> <span class=\"s2\">&quot;__len__&quot;</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itot</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">)]</span> <span class=\"k\">for</span> <span class=\"n\">index</span> <span class=\"ow\">in</span> <span class=\"n\">indices</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "            <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">itot</span><span class=\"p\">[</span><span class=\"n\">indices</span><span class=\"p\">]</span>\n",
       "\n",
       "    <span class=\"nd\">@property</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">unk</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">int</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ttoi</span><span class=\"p\">[</span><span class=\"s2\">&quot;&lt;unk&gt;&quot;</span><span class=\"p\">]</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">TimeMachine</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">token_level</span><span class=\"o\">=</span><span class=\"s2\">&quot;char&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">DEFAULT_PATH</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">((</span><span class=\"n\">DATA_DIR</span> <span class=\"o\">/</span> <span class=\"s2\">&quot;time_machine.txt&quot;</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">absolute</span><span class=\"p\">())</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">token_level</span> <span class=\"o\">=</span> <span class=\"n\">token_level</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">filepath</span> <span class=\"o\">=</span> <span class=\"n\">path</span> <span class=\"ow\">or</span> <span class=\"n\">DEFAULT_PATH</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">download</span> <span class=\"ow\">or</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">filepath</span><span class=\"p\">):</span>\n",
       "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_download</span><span class=\"p\">()</span>\n",
       "        \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">_download</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;https://www.gutenberg.org/cache/epub/35/pg35.txt&quot;</span>\n",
       "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Downloading text from </span><span class=\"si\">{</span><span class=\"n\">url</span><span class=\"si\">}</span><span class=\"s2\"> ...&quot;</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s2\">&quot; &quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">stream</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">raise_for_status</span><span class=\"p\">()</span>\n",
       "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;OK!&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">filepath</span><span class=\"p\">,</span> <span class=\"s2\">&quot;wb&quot;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">output</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">output</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">content</span><span class=\"p\">)</span>\n",
       "        \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">_preprocess</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;*** START OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***&quot;</span>\n",
       "        <span class=\"n\">e</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;*** END OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***&quot;</span>\n",
       "        <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">text</span><span class=\"p\">[</span><span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">):</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">)]</span>\n",
       "        <span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"s1\">&#39;[^A-Za-z]+&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39; &#39;</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">lower</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">text</span>\n",
       "    \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">tokenize</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">return</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">token_level</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;char&quot;</span> <span class=\"k\">else</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">()</span>\n",
       "        \n",
       "    <span class=\"k\">def</span> <span class=\"nf\">build</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">vocab</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">filepath</span><span class=\"p\">,</span> <span class=\"s2\">&quot;r&quot;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">raw_text</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n",
       "        \n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_preprocess</span><span class=\"p\">(</span><span class=\"n\">raw_text</span><span class=\"p\">)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span> \n",
       "        \n",
       "        <span class=\"n\">vocab</span> <span class=\"o\">=</span> <span class=\"n\">Vocab</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">vocab</span> <span class=\"ow\">is</span> <span class=\"kc\">None</span> <span class=\"k\">else</span> <span class=\"n\">vocab</span>\n",
       "        <span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"n\">vocab</span><span class=\"p\">[</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">corpus</span><span class=\"p\">,</span> <span class=\"n\">vocab</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{re}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{os}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{requests}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{collections}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{pathlib} \\PY{k+kn}{import} \\PY{n}{Path}\n",
       "\n",
       "\\PY{n}{DATA\\PYZus{}DIR} \\PY{o}{=} \\PY{n}{Path}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{./data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{DATA\\PYZus{}DIR}\\PY{o}{.}\\PY{n}{mkdir}\\PY{p}{(}\\PY{n}{exist\\PYZus{}ok}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{Vocab}\\PY{p}{:}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{tokens}\\PY{o}{=}\\PY{p}{[}\\PY{p}{]}\\PY{p}{,} \\PY{n}{min\\PYZus{}freq}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{reserved\\PYZus{}tokens}\\PY{o}{=}\\PY{p}{[}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{counter} \\PY{o}{=} \\PY{n}{collections}\\PY{o}{.}\\PY{n}{Counter}\\PY{p}{(}\\PY{n}{tokens}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{token\\PYZus{}freqs} \\PY{o}{=} \\PY{n+nb}{sorted}\\PY{p}{(}\\PY{n}{counter}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{key}\\PY{o}{=}\\PY{k}{lambda} \\PY{n}{x}\\PY{p}{:} \\PY{n}{x}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{,} \\PY{n}{reverse}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{itot} \\PY{o}{=} \\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZlt{}unk\\PYZgt{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]} \\PY{o}{+} \\PY{n+nb}{list}\\PY{p}{(}\\PY{n+nb}{sorted}\\PY{p}{(}\\PY{n+nb}{set}\\PY{p}{(}\n",
       "            \\PY{n}{reserved\\PYZus{}tokens} \\PY{o}{+}   \\PY{c+c1}{\\PYZsh{} i.e. not subject to min\\PYZus{}freq}\n",
       "            \\PY{p}{[}\\PY{n}{token} \\PY{k}{for} \\PY{n}{token}\\PY{p}{,} \\PY{n}{freq} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{token\\PYZus{}freqs} \\PY{k}{if} \\PY{n}{freq} \\PY{o}{\\PYZgt{}}\\PY{o}{=} \\PY{n}{min\\PYZus{}freq}\\PY{p}{]}\n",
       "        \\PY{p}{)}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{ttoi} \\PY{o}{=} \\PY{p}{\\PYZob{}}\\PY{n}{tok}\\PY{p}{:} \\PY{n}{idx} \\PY{k}{for} \\PY{n}{idx}\\PY{p}{,} \\PY{n}{tok} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{itot}\\PY{p}{)}\\PY{p}{\\PYZcb{}}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}len\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{return} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{itot}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}getitem\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{tokens}\\PY{p}{:} \\PY{n+nb}{list}\\PY{p}{[}\\PY{n+nb}{str}\\PY{p}{]}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{list}\\PY{p}{[}\\PY{n+nb}{int}\\PY{p}{]}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n}{tokens}\\PY{p}{,} \\PY{p}{(}\\PY{n+nb}{list}\\PY{p}{,} \\PY{n+nb}{tuple}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{return} \\PY{p}{[}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}getitem\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n}{tok}\\PY{p}{)} \\PY{k}{for} \\PY{n}{tok} \\PY{o+ow}{in} \\PY{n}{tokens}\\PY{p}{]}\n",
       "        \\PY{k}{else}\\PY{p}{:}\n",
       "            \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{ttoi}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{n}{tokens}\\PY{p}{,} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{unk}\\PY{p}{)}\n",
       "            \n",
       "    \\PY{k}{def} \\PY{n+nf}{to\\PYZus{}tokens}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{indices}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{list}\\PY{p}{[}\\PY{n+nb}{str}\\PY{p}{]}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n+nb}{hasattr}\\PY{p}{(}\\PY{n}{indices}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZus{}\\PYZus{}len\\PYZus{}\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{return} \\PY{p}{[}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{itot}\\PY{p}{[}\\PY{n+nb}{int}\\PY{p}{(}\\PY{n}{index}\\PY{p}{)}\\PY{p}{]} \\PY{k}{for} \\PY{n}{index} \\PY{o+ow}{in} \\PY{n}{indices}\\PY{p}{]}\n",
       "        \\PY{k}{else}\\PY{p}{:}\n",
       "            \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{itot}\\PY{p}{[}\\PY{n}{indices}\\PY{p}{]}\n",
       "\n",
       "    \\PY{n+nd}{@property}\n",
       "    \\PY{k}{def} \\PY{n+nf}{unk}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{int}\\PY{p}{:}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{ttoi}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZlt{}unk\\PYZgt{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\n",
       "\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{TimeMachine}\\PY{p}{:}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{download}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{,} \\PY{n}{path}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{n}{token\\PYZus{}level}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{char}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{DEFAULT\\PYZus{}PATH} \\PY{o}{=} \\PY{n+nb}{str}\\PY{p}{(}\\PY{p}{(}\\PY{n}{DATA\\PYZus{}DIR} \\PY{o}{/} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{time\\PYZus{}machine.txt}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{o}{.}\\PY{n}{absolute}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{token\\PYZus{}level} \\PY{o}{=} \\PY{n}{token\\PYZus{}level}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{filepath} \\PY{o}{=} \\PY{n}{path} \\PY{o+ow}{or} \\PY{n}{DEFAULT\\PYZus{}PATH}\n",
       "        \\PY{k}{if} \\PY{n}{download} \\PY{o+ow}{or} \\PY{o+ow}{not} \\PY{n}{os}\\PY{o}{.}\\PY{n}{path}\\PY{o}{.}\\PY{n}{exists}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{filepath}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{\\PYZus{}download}\\PY{p}{(}\\PY{p}{)}\n",
       "        \n",
       "    \\PY{k}{def} \\PY{n+nf}{\\PYZus{}download}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{url} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{https://www.gutenberg.org/cache/epub/35/pg35.txt}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Downloading text from }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{url}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{ ...}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{end}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ }\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{n}{response} \\PY{o}{=} \\PY{n}{requests}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{n}{url}\\PY{p}{,} \\PY{n}{stream}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "        \\PY{n}{response}\\PY{o}{.}\\PY{n}{raise\\PYZus{}for\\PYZus{}status}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{OK!}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{with} \\PY{n+nb}{open}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{filepath}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{wb}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)} \\PY{k}{as} \\PY{n}{output}\\PY{p}{:}\n",
       "            \\PY{n}{output}\\PY{o}{.}\\PY{n}{write}\\PY{p}{(}\\PY{n}{response}\\PY{o}{.}\\PY{n}{content}\\PY{p}{)}\n",
       "        \n",
       "    \\PY{k}{def} \\PY{n+nf}{\\PYZus{}preprocess}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{s} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{*** START OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "        \\PY{n}{e} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{*** END OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "        \\PY{n}{text} \\PY{o}{=} \\PY{n}{text}\\PY{p}{[}\\PY{n}{text}\\PY{o}{.}\\PY{n}{find}\\PY{p}{(}\\PY{n}{s}\\PY{p}{)} \\PY{o}{+} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{s}\\PY{p}{)}\\PY{p}{:} \\PY{n}{text}\\PY{o}{.}\\PY{n}{find}\\PY{p}{(}\\PY{n}{e}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{n}{text} \\PY{o}{=} \\PY{n}{re}\\PY{o}{.}\\PY{n}{sub}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{[\\PYZca{}A\\PYZhy{}Za\\PYZhy{}z]+}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ }\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{text}\\PY{p}{)}\\PY{o}{.}\\PY{n}{lower}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{strip}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{text}\n",
       "    \n",
       "    \\PY{k}{def} \\PY{n+nf}{tokenize}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{return} \\PY{n+nb}{list}\\PY{p}{(}\\PY{n}{text}\\PY{p}{)} \\PY{k}{if} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{token\\PYZus{}level} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{char}\\PY{l+s+s2}{\\PYZdq{}} \\PY{k}{else} \\PY{n}{text}\\PY{o}{.}\\PY{n}{split}\\PY{p}{(}\\PY{p}{)}\n",
       "        \n",
       "    \\PY{k}{def} \\PY{n+nf}{build}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{vocab}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{with} \\PY{n+nb}{open}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{filepath}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{r}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)} \\PY{k}{as} \\PY{n}{f}\\PY{p}{:}\n",
       "            \\PY{n}{raw\\PYZus{}text} \\PY{o}{=} \\PY{n}{f}\\PY{o}{.}\\PY{n}{read}\\PY{p}{(}\\PY{p}{)}\n",
       "        \n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{text} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{\\PYZus{}preprocess}\\PY{p}{(}\\PY{n}{raw\\PYZus{}text}\\PY{p}{)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{tokens} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{tokenize}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{text}\\PY{p}{)} \n",
       "        \n",
       "        \\PY{n}{vocab} \\PY{o}{=} \\PY{n}{Vocab}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{tokens}\\PY{p}{)} \\PY{k}{if} \\PY{n}{vocab} \\PY{o+ow}{is} \\PY{k+kc}{None} \\PY{k}{else} \\PY{n}{vocab}\n",
       "        \\PY{n}{corpus} \\PY{o}{=} \\PY{n}{vocab}\\PY{p}{[}\\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{tokens}\\PY{p}{]}\n",
       "        \\PY{k}{return} \\PY{n}{corpus}\\PY{p}{,} \\PY{n}{vocab}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import re\n",
       "import os\n",
       "import requests\n",
       "import collections\n",
       "from pathlib import Path\n",
       "\n",
       "DATA_DIR = Path(\"./data\")\n",
       "DATA_DIR.mkdir(exist_ok=True)\n",
       "\n",
       "\n",
       "class Vocab:\n",
       "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
       "        counter = collections.Counter(tokens)\n",
       "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
       "        self.itot = [\"<unk>\"] + list(sorted(set(\n",
       "            reserved_tokens +   # i.e. not subject to min_freq\n",
       "            [token for token, freq in self.token_freqs if freq >= min_freq]\n",
       "        )))\n",
       "        self.ttoi = {tok: idx for idx, tok in enumerate(self.itot)}\n",
       "\n",
       "    def __len__(self):\n",
       "        return len(self.itot)\n",
       "    \n",
       "    def __getitem__(self, tokens: list[str]) -> list[int]:\n",
       "        if isinstance(tokens, (list, tuple)):\n",
       "            return [self.__getitem__(tok) for tok in tokens]\n",
       "        else:\n",
       "            return self.ttoi.get(tokens, self.unk)\n",
       "            \n",
       "    def to_tokens(self, indices) -> list[str]:\n",
       "        if hasattr(indices, \"__len__\"):\n",
       "            return [self.itot[int(index)] for index in indices]\n",
       "        else:\n",
       "            return self.itot[indices]\n",
       "\n",
       "    @property\n",
       "    def unk(self) -> int:\n",
       "        return self.ttoi[\"<unk>\"]\n",
       "\n",
       "\n",
       "class TimeMachine:\n",
       "    def __init__(self, download=False, path=None, token_level=\"char\"):\n",
       "        DEFAULT_PATH = str((DATA_DIR / \"time_machine.txt\").absolute())\n",
       "        self.token_level = token_level\n",
       "        self.filepath = path or DEFAULT_PATH\n",
       "        if download or not os.path.exists(self.filepath):\n",
       "            self._download()\n",
       "        \n",
       "    def _download(self):\n",
       "        url = \"https://www.gutenberg.org/cache/epub/35/pg35.txt\"\n",
       "        print(f\"Downloading text from {url} ...\", end=\" \")\n",
       "        response = requests.get(url, stream=True)\n",
       "        response.raise_for_status()\n",
       "        print(\"OK!\")\n",
       "        with open(self.filepath, \"wb\") as output:\n",
       "            output.write(response.content)\n",
       "        \n",
       "    def _preprocess(self, text: str):\n",
       "        s = \"*** START OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***\"\n",
       "        e = \"*** END OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***\"\n",
       "        text = text[text.find(s) + len(s): text.find(e)]\n",
       "        text = re.sub('[^A-Za-z]+', ' ', text).lower().strip()\n",
       "        return text\n",
       "    \n",
       "    def tokenize(self, text: str):\n",
       "        return list(text) if self.token_level == \"char\" else text.split()\n",
       "        \n",
       "    def build(self, vocab=None):\n",
       "        with open(self.filepath, \"r\") as f:\n",
       "            raw_text = f.read()\n",
       "        \n",
       "        self.text = self._preprocess(raw_text)\n",
       "        self.tokens = self.tokenize(self.text) \n",
       "        \n",
       "        vocab = Vocab(self.tokens) if vocab is None else vocab\n",
       "        corpus = vocab[self.tokens]\n",
       "        return corpus, vocab"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%save\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.itot = [\"<unk>\"] + list(sorted(set(\n",
    "            reserved_tokens +   # i.e. not subject to min_freq\n",
    "            [token for token, freq in self.token_freqs if freq >= min_freq]\n",
    "        )))\n",
    "        self.ttoi = {tok: idx for idx, tok in enumerate(self.itot)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itot)\n",
    "    \n",
    "    def __getitem__(self, tokens: list[str]) -> list[int]:\n",
    "        if isinstance(tokens, (list, tuple)):\n",
    "            return [self.__getitem__(tok) for tok in tokens]\n",
    "        else:\n",
    "            return self.ttoi.get(tokens, self.unk)\n",
    "            \n",
    "    def to_tokens(self, indices) -> list[str]:\n",
    "        if hasattr(indices, \"__len__\"):\n",
    "            return [self.itot[int(index)] for index in indices]\n",
    "        else:\n",
    "            return self.itot[indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self) -> int:\n",
    "        return self.ttoi[\"<unk>\"]\n",
    "\n",
    "\n",
    "class TimeMachine:\n",
    "    def __init__(self, download=False, path=None, token_level=\"char\"):\n",
    "        DEFAULT_PATH = str((DATA_DIR / \"time_machine.txt\").absolute())\n",
    "        self.token_level = token_level\n",
    "        self.filepath = path or DEFAULT_PATH\n",
    "        if download or not os.path.exists(self.filepath):\n",
    "            self._download()\n",
    "        \n",
    "    def _download(self):\n",
    "        url = \"https://www.gutenberg.org/cache/epub/35/pg35.txt\"\n",
    "        print(f\"Downloading text from {url} ...\", end=\" \")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        print(\"OK!\")\n",
    "        with open(self.filepath, \"wb\") as output:\n",
    "            output.write(response.content)\n",
    "        \n",
    "    def _preprocess(self, text: str):\n",
    "        s = \"*** START OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***\"\n",
    "        e = \"*** END OF THE PROJECT GUTENBERG EBOOK THE TIME MACHINE ***\"\n",
    "        text = text[text.find(s) + len(s): text.find(e)]\n",
    "        text = re.sub('[^A-Za-z]+', ' ', text).lower().strip()\n",
    "        return text\n",
    "    \n",
    "    def tokenize(self, text: str):\n",
    "        return list(text) if self.token_level == \"char\" else text.split()\n",
    "        \n",
    "    def build(self, vocab=None):\n",
    "        with open(self.filepath, \"r\") as f:\n",
    "            raw_text = f.read()\n",
    "        \n",
    "        self.text = self._preprocess(raw_text)\n",
    "        self.tokens = self.tokenize(self.text) \n",
    "        \n",
    "        vocab = Vocab(self.tokens) if vocab is None else vocab\n",
    "        corpus = vocab[self.tokens]\n",
    "        return corpus, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a0c089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.469525Z",
     "iopub.status.busy": "2024-12-31T05:32:10.469355Z",
     "iopub.status.idle": "2024-12-31T05:32:10.583804Z",
     "shell.execute_reply": "2024-12-31T05:32:10.580836Z"
    },
    "papermill": {
     "duration": 0.121652,
     "end_time": "2024-12-31T05:32:10.588050",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.466398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Transforming the data to sequence-first format.\"\"\"\n",
    "    x, y = zip(*batch)\n",
    "    x = torch.stack(x, 1)      # (T, B, vocab_size)\n",
    "    y = torch.stack(y, 1)      # (T, B)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "tm = TimeMachine()\n",
    "corpus, vocab = tm.build()\n",
    "dataset = SequenceDataset(corpus, seq_len=10, vocab_size=len(vocab))\n",
    "train_dataset, valid_dataset = random_split(dataset, [0.80, 0.20])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a0756",
   "metadata": {
    "papermill": {
     "duration": 0.00477,
     "end_time": "2024-12-31T05:32:10.598643",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.593873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The batch index (i.e. starting point) is shuffled, but the ordering in each sequence is intact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117304f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.612722Z",
     "iopub.status.busy": "2024-12-31T05:32:10.611993Z",
     "iopub.status.idle": "2024-12-31T05:32:10.639427Z",
     "shell.execute_reply": "2024-12-31T05:32:10.638503Z"
    },
    "papermill": {
     "duration": 0.049735,
     "end_time": "2024-12-31T05:32:10.651366",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.601631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y -->  \n",
      "  --> o\n",
      "o --> w\n",
      "w --> n\n",
      "n -->  \n",
      "  --> e\n",
      "e --> x\n",
      "x --> p\n",
      "p --> e\n",
      "e --> n\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "\n",
    "a, T = 1, dataset.seq_len\n",
    "x_chars = vocab.to_tokens(torch.argmax(x[:, a], dim=1))     # inputs are one-hot\n",
    "y_chars = vocab.to_tokens(y[:, a])\n",
    "for i in range(T):\n",
    "    print(f\"{x_chars[i]} --> {y_chars[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2d90b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.659703Z",
     "iopub.status.busy": "2024-12-31T05:32:10.659510Z",
     "iopub.status.idle": "2024-12-31T05:32:10.663392Z",
     "shell.execute_reply": "2024-12-31T05:32:10.662940Z"
    },
    "papermill": {
     "duration": 0.008558,
     "end_time": "2024-12-31T05:32:10.664658",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.656100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 28]) torch.Size([10, 32])\n",
      "inputs: tensor([ 2, 15,  5,  1, 24,  9,  6, 15,  1, 10])\n",
      "target: tensor([15,  5,  1, 24,  9,  6, 15,  1, 10,  1])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)\n",
    "print(\"inputs:\", torch.argmax(x[:, 0], dim=-1))\n",
    "print(\"target:\", y[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c96a8f",
   "metadata": {
    "papermill": {
     "duration": 0.003886,
     "end_time": "2024-12-31T05:32:10.671775",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.667889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "PyTorch `F.cross_entropy` expects input `(B, C, T)` and target `(B, T)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f888413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T05:32:10.678521Z",
     "iopub.status.busy": "2024-12-31T05:32:10.678341Z",
     "iopub.status.idle": "2024-12-31T05:32:10.697188Z",
     "shell.execute_reply": "2024-12-31T05:32:10.696751Z"
    },
    "papermill": {
     "duration": 0.023298,
     "end_time": "2024-12-31T05:32:10.698456",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.675158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3582, grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "model = LanguageModel(RNN)(28, 5, len(vocab))\n",
    "loss = F.cross_entropy(model(x).permute(1, 2, 0), y.transpose(0, 1))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889eba7e",
   "metadata": {
    "papermill": {
     "duration": 0.002111,
     "end_time": "2024-12-31T05:32:10.703208",
     "exception": false,
     "start_time": "2024-12-31T05:32:10.701097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.207288,
   "end_time": "2024-12-31T05:32:11.231598",
   "environment_variables": {},
   "exception": null,
   "input_path": "05b-rnn-lm.ipynb",
   "output_path": "05b-rnn-lm.ipynb",
   "parameters": {},
   "start_time": "2024-12-31T05:32:08.024310",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}