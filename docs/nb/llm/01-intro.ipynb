{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week 1: First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build first LLM product, explore top models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ollama run smollm:360m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"chat teach me french\"\"\" cant\n",
    "\n",
    "switch to qwen2.5 (ollama run qwen2.5:0.5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"store\": True,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(URL, headers=headers, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'Lines of code entwined,  \\n'\n",
      "                                     'Thoughts of silicon ariseâ€”  \\n'\n",
      "                                     'Dreams of minds defined.',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1736066851,\n",
      " 'id': 'chatcmpl-AmGaB2cQI92cB6dENTJO4bTIibth0',\n",
      " 'model': 'gpt-4o-mini-2024-07-18',\n",
      " 'object': 'chat.completion',\n",
      " 'system_fingerprint': 'fp_0aa8d3e20b',\n",
      " 'usage': {'completion_tokens': 21,\n",
      "           'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                         'audio_tokens': 0,\n",
      "                                         'reasoning_tokens': 0,\n",
      "                                         'rejected_prediction_tokens': 0},\n",
      "           'prompt_tokens': 13,\n",
      "           'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0},\n",
      "           'total_tokens': 34}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run ollama\n",
    "- call openai api\n",
    "- system vs user prompt\n",
    "- summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 dims of llm engg\n",
    "\n",
    "- models\n",
    "    - open\n",
    "    - closed\n",
    "    - mutli-model\n",
    "    - architectures\n",
    "    - selection criteria\n",
    "\n",
    "- tools\n",
    "    - hf\n",
    "    - langchain, etc\n",
    "    - gradio / streamlit\n",
    "    - w&b\n",
    "    - modal\n",
    "\n",
    "- techniques\n",
    "    - apis\n",
    "    - multi-shot prompting\n",
    "    - rag\n",
    "    - fine-tuning\n",
    "    - agentization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "closed:\n",
    "- claude (antrhopic), gemini (google), command R (cohere), perplexity search engine\n",
    "\n",
    "open:\n",
    "- llama (meta)\n",
    "- mixtral (moe)\n",
    "- qwen (alibaba)\n",
    "- gemma (google)\n",
    "- phi (msft)\n",
    "\n",
    "3 ways to use models\n",
    "- apis (e.g. cloud apis)\n",
    "- chat UI (e.g chat gpt)\n",
    "- **direct inference** (ollama, HF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exercise.** ollama for direct inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
